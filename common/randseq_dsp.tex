%============================================================================
% LaTeX File
% Daniel J. Greenhoe
%============================================================================
%=======================================
\chapter{Operators on Discrete Random Sequences}
%=======================================
%=======================================
\section{LTI operators on random sequences}
%=======================================
%---------------------------------------
\begin{minipage}{\tw-50mm}
\begin{theorem}
\footnotemark
\label{thm:Rxyh}
%---------------------------------------
Let $\rvx(n)$ be a \fncte{random sequence} with \fncte{mean} $\pmeanx$
and $\rvy(n)$    a \fncte{random sequence} with \fncte{mean} $\pmeany$.
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\end{theorem}
\end{minipage}
\hfill\tbox{\includegraphics{graphics/sysH_xy.pdf}}
\footnotetext{
  \citerp{papoulis}{310}
  }
\\
\thmbox{
   \brb{\begin{array}{M}
      $\opS$ is
   %\\\prope{linear time invariant}
    (\prope{LTI})
  \end{array}}
  \implies
  \brb{\begin{array}{Frc>{\ds}l>{\ds}lD}
       (1).&\pmeany(n)&=& \sum_{k\in\Z} \fh(k)      \pmeanx(n-k)  &\eqd \fh(n)\convd \pmeanx(n) & and
     \\(2).&\Rxy(n,m) &=& \sum_{k\in\Z} \fh^\ast(k) \Rxx(n-k,m+k) &                            & and 
     \\(3).&\Ryy(n,m) &=& \sum_{k\in\Z} \fh^\ast(k) \Ryx(n-k,m+k)
  \end{array}} 
  }
\\
\begin{proof}
\begin{align*}
   \pmeany(n)
     &\eqd \pE\brs{\rvy(n)}
     && \text{by definition of $\pmeany$}
     && \text{\xref{def:pmeanxn}}
   \\&= \pE\brs{\sum_{k\in\Z} \fh(k) \rvx(n-k)}
     && \text{by \prope{LTI} hypothesis}
   \\&= \sum_{k\in\Z} \fh(k) \pE\brs{\rvx(n-k)}
     && \text{by \prope{linear} property}
   \\&= \sum_{k\in\Z} \fh(k) \pmeanx(n-k)
     && \text{by definition of $\pmeanx$}
     && \text{\xref{def:pmeanxn}}
   \\&\eqd \fh(n)\convd \pmeanx(n) 
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Rxy(n,m)
     &\eqd \pE\brs{\rvx(n+m) \rvy^\ast(n) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvx(n+m) \brp{\fh(n)\convd\rvx(n)}^\ast}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvx(n+m) \brp{ \sum_{k\in\Z} h(k) \rvx(n-k) }^\ast }
     && \text{by definition of \ope{convolution} $\conv$}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvx(n+m) \sum_{k\in\Z} \fh^\ast(k) \rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvx(n+m)\rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(n-k+k+m) \rvx^\ast(n-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(n-k,m+k)
     && \text{by definition of $\Rxx(n,m)$}
     && \text{\xref{def:Rxxnm}}
   %\\&\eqd \sum_{k'\in\Z} \fh^\ast(-k') \Rxx(n+k',m-k')
   %  && \text{where $k'\eqd -k$}
   %\\&\eqd \sum_{k\in\Z} \fh^\ast(-k) \Rxx(n+k,m-k)
   %  && \text{where $k\eqd k'$}
   %\\&= \Rxx(n+k,m) \convd \fh^\ast(-m)
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Ryy(n,m)
     &\eqd \pE\brs{\rvy(n+m) \rvy^\ast(n) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvy(n+m) \brp{\fh(n)\convd\rvx(n)}^\ast}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvy(n+m) \brp{ \sum_{k\in\Z} \fh(k) \rvx(n-k) }^\ast }
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvy(n+m) \sum_{k\in\Z} \fh^\ast(k) \rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvy(n+m)\rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&=    \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvy(n-k+k+m) \rvx^\ast(n-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Ryx(n-k,m+k)
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Ryynm}}
   %\\&= \sum_{k'\in\Z} \fh^\ast(-k') \Ryx(n+k',m-k')
   %  && \text{where $k'\eqd-k$}
   %\\&= \sum_{k\in\Z} \fh^\ast(-k) \Ryx(n+k,m-k)
   %  && \text{where $k\eqd k'$}
   %\\&\eqd \Ryx(n+k,m) \convd \fh^\ast(-m)
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   %\\
   %\\
   %\Ryy(n,m)
   %  &= \Rxy(n,m)\convd \fh(m)
   %  && \text{by previous result}
   %\\&= \brs{\Rxx(n,m) \convd \fh^\ast(-m)}\convd \fh(-m)
   %  && \text{by previous result}
   %\\&= \Rxx(n,m) \convd \fh(-m) \convd \fh^\ast(-m)
   %  && \text{by previous result}
   %\\
   %\\
   %\Ryy(n,m)
   %  &= \Rxx(n,m)\convd\fh(-m) \convd \fh^\ast(-m)
   %  && \text{by previous result}
   %\\&\eqd \sum_{p\in\Z}\fh^\ast(-p) \brs{\Rxx(n,m-p)\convd\fh(-m)}
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   %\\&= \sum_{p\in\Z}\fh^\ast(-p) \sum_{k\in\Z}\fh(-k) \Rxx(n,m-p-k)
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   %\\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(-k) \fh^\ast(-p) \Rxx(n,m-p-k)
   %  && \text{by \prope{distributive} property of $\fieldC$}
   %  && \text{\xref{def:field}}
\end{align*}
\end{proof}

%=======================================
\section{LTI operators on WSS random sequences}
%=======================================
%---------------------------------------
\begin{corollary}
\footnotetext{
  \citerp{papoulis}{323}
  }
\label{cor:Rxyh}
%---------------------------------------
Let $\opS$ be the system defined in \prefpp{thm:Rxyh}.
\corbox{
  \brbr{\begin{array}{FMD}
      (A). & $\opS$    is \prope{LTI} & and
    \\(B). & $\rvx(n)$ is \prope{WSS} &
  \end{array}}
  \implies
  \brbl{\begin{array}{Frc>{\ds}lc>{\ds}lD}
       (1).&\pmeany &=& \pmeanx\sum_{n\in\Z} \fh(k)          &    &                                      & and
     \\(2).&\Rxy(m) &=& \Rxx(m)\convd \fh^\ast(-m)           &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxx(m+k)  & and
     \\(3).&\Ryy(m) &=& \Ryx(m)\convd \fh^\ast(-m)           &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxy(m+k)  & and
     \\(4).&\Ryy(m) &=& \mc{4}{l}{\ds\Rxx^\ast(m)\convd \fh(-m)\convd\fh^\ast(-m)} %&\eqd& \mc{2}{l}{\ds\sum_{p\in\Z}\sum_{k\in\Z}\fh(k)h^\ast(p) \Rxx(m-p-k)}
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{align*}
  \pmeany 
     &= \pmeany(n)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \sum_{n\in\Z} \fh(k) \pmeanx(n-k)
     && \text{by \prefp{thm:Rxynm}}
     && \text{and hypothesis (B)}
   \\&= \sum_{n\in\Z} \fh(k) \pmeanx(0)
     && \text{by \prefp{def:wss}}
     && \text{and hypothesis (B)}
   \\&= \pmeanx(0) \sum_{n\in\Z} \fh(k) 
     && \text{by \prope{linear} property of $\sum$}
   \\&= \pmeanx \sum_{n\in\Z} \fh(k) 
     && \text{by \prefp{prop:Rxynmm}}
   \\
  \Rxy(m)
     &\eqd \Rxy(0,m)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Rxx(0-k,m+k)
     && \text{by \prefp{thm:Rxyh}}
     && \text{and hypothesis (B)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Rxx(m+k)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \fh^\ast(-m) \convd\Rxx(m)
     && \text{by \prefp{prop:conv_knk}}
\\
  \Ryy(m)
     &\eqd \Ryy(0,m)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Ryx(n-k,m+k)
     && \text{by \prefp{thm:Rxyh}}
     && \text{and hypothesis (B)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Ryx(m+k)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \fh^\ast(-m) \convd\Ryx(m)
     && \text{by \prefp{prop:conv_knk}}
\\
  \Ryy(m)
     &= \fh^\ast(-m) \convd\Ryx(m)
     && \text{by result (2)}
   \\&= \fh^\ast(-m) \convd\Rxy^\ast(m)
     && \text{by \prefp{cor:Rxym}}
   \\&= \fh^\ast(-m) \convd\brs{\fh^\ast(-m) \convd\Rxx(m)}^\ast
     && \text{by result (1)}
   \\&= \fh^\ast(-m) \convd\fh(-m) \convd\Rxx^\ast(m)
      && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
      && \text{\xref{def:staralg}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\footnote{
  \citerp{papoulis}{323}
  }
\label{cor:ZSxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{F>{\ds}rc>{\ds}lD}
       (1).&\ZSxy(z) &=& \ZSxx(z) \ZH^\ast\brp{\frac{1}{z^\ast}}      & and
     \\(2).&\ZSyy(z) &=& \ZSyx(z) \ZH^\ast\brp{\frac{1}{z^\ast}}      & and
     \\(3).&\ZSyy(z) &=& \ZSxx(z) \ZH\brp{z} \ZH^\ast\brp{\frac{1}{z^\ast}}
  \end{array}}
  }
\end{corollary}
\begin{proof}
The proof is given in \prefpp{prop:RxySzxy} (1).
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:Swxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMMD}
      (A).& $\fh$ is               &\prope{LTI} & and
    \\(B).& $\rvx$ and $\rvy$ are  &\prope{WSS} &
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Swxy(\omega) &=& \ds \Swxx(\omega) \FH^\ast(\omega) & and
     \\(2).&\Swyy(\omega) &=& \ds \Swxy(\omega) \FH     (\omega)   & and
     \\(3).&\Swyy(\omega) &=& \mc{2}{l}{\ds \Swxx(\omega) \abs{\FH(\omega)}^2}
  \end{array}}
  }
\end{corollary}
\begin{proof}
The proof is given in \prefpp{prop:RxySwxy} (1).
\end{proof}

%=======================================
\section{Parallel operators on WSS random sequences}
%=======================================
%---------------------------------------
\begin{minipage}{\tw-70mm}
\begin{theorem}
\label{thm:xGw_xHy}
\label{cor:xGw_xHy}
%---------------------------------------
Let $\opS$ be the \structe{system} illustrated to the right,
where $\opT$ is \prope{not necessarily linear}.
Let 
\\\indentx$\ds\seqn{\fh(n)}\eqd\opH\kdelta(n)\eqd\sum_{m\in\Z}\fh(m)\kdelta(n-m)$
\\
be the \fncte{impulse response} of $\opH$.
\end{theorem}
\end{minipage}
\hfill\tbox{\includegraphics{graphics/xTy_xHw.pdf}}
\\
\thmbox{
  \brb{\begin{array}{FMMD}
      (A).& $\rvx(n)$ is &\prope{WSS}       & and
    \\(B).& $\opH$    is &\prope{LTI}       &
  \end{array}}
  \implies
  \brb{\begin{array}{Frc>{\ds}lD}
      (1).&\Rwy(m)       &=&    \sum_{n\in\Z}\fh(n)\Rxy(m-n) & (\ope{convolution})
        \\&              &\eqd& \fh(m)\convd\Rxy(m)          & and
    \\(2).&\Szwy(z)      &=&    \ZH(z)     \Szxy(z)          & and
    \\(3).&\Swwy(\omega) &=&    \FH(\omega)\Swxy(\omega)     &
  \end{array}}
  }
\\
\begin{proof}
\begin{align*}
  \Rwy(m)
    &\eqd \pE\brs{\rvw(m)\rvy^\ast(0)}
    && \text{by (A) and definition of $\Rwy$}
    && \text{\xref{def:Rxym}}
  \\&\eqd \pE\brp{\brs{\opH\rvx}(m)\rvy^\ast(0)}
    && \text{by definition of $\opS$}
  \\&= \opH\pE\brp{\rvx(m)\rvy^\ast(0)}
    && \text{by \prope{LTI} hypothesis}
    && \text{(B)}
  \\&\eqd \opH\Rxy(m)
    && \text{by definition of $\Rxy$}
    && \text{\xref{def:Rxym}}
  \\&= \sum_{n\in\Z}\fh(n)\Rxy(m-n)
    && \mathrlap{\text{by definition of $\opH$ \fncte{impulse response} $\seqn{\fh(n)}$}}
  \\&= \brs{\fh(m)\convd\Rxy(m)}
    && \text{by definition of \ope{convolution}}
    && \text{\xref{def:dsp_conv}}
  \\
  \Szwy(z)
    &\eqd \opZ\Rwy(m)
    && \text{by definition of $\Szwy$}
    && \text{\xref{def:Szxy}}
  \\&= \brs{\fh(m)\convd\Rxy(m)}
    && \text{by previous result}
  \\&= \ZH(z)\Szxy(z)
    && \text{by \thme{Convolution Theorem}}
    && \text{\xref{thm:conv}}
  \\
  \Swwy(\omega)
    &\eqd \opDTFT\Rwy(m)
    && \text{by definition of $\Swwy$}
    && \text{\xref{def:Swxy}}
  \\&= \brs{\fh(m)\convd\Rxy(m)}
    && \text{by previous result}
  \\&= \FH(\omega)\Swxy(\omega)
    && \text{by \thme{Convolution Theorem}}
    && \text{\xref{thm:conv}}
\end{align*}
\end{proof}

%=======================================
\section{Whitening discrete random sequences}
\index{whitening filter}
\label{sec:d-whiten}
%=======================================
Note that if $\fL(z)$ has a root at $z=re^{i\theta}$, then
$\fL^\ast(1/z^\ast)$ has a root at
\begin{align*}
   \frac{1}{z^\ast}
     &= \frac{1}{\brp{re^{i\theta}}^\ast}
      = \frac{1}{re^{-i\theta}}
      = \frac{1}{r} e^{i\theta}.
\end{align*}
That is, if $\fL(z)$ has a root inside the unit circle,
then $\fL^\ast(1/z^\ast)$ has a root directly opposite across the unit circle
boundary (see \prefp{fig:z-roots}).
A causal stable filter $\ZH(z)$ must have all of its poles inside
the unit circle.
A filter has \prope{minimum phase} \xref{def:minphase} if both its poles and zeros 
are inside the unit circle.
One advantage of a minimum phase filter is that its inverse
(zeros become poles and poles become zeros)
is also causal and stable.

\begin{figure}[ht]
\begin{center}
\begin{fsL}
\setlength{\unitlength}{0.2mm}
\begin{picture}(300,300)(-130,-130)
  %\graphpaper[10](0,0)(200,200)
  \thicklines%
  \color{axis}%
    \put(-130 ,   0 ){\line(1,0){260} }%
    \put(   0 ,-130 ){\line(0,1){260} }%
    \put( 140 ,   0 ){\makebox(0,0)[l]{$\Re$}}%
    \put(   0 , 140 ){\makebox(0,0)[b]{$\Im$}}%
  \color{zero}%
    \qbezier[24](  0,  0)( 56.5,56.5)(113,113)
    %\put(   0 ,   0 ){\line(1,1){120}}%
    \put(  28 ,  28 ){\circle{10}}%
    \put( 113 , 113 ){\circle{10}}%
    \put(  38 ,  28 ){\makebox(0,0)[l]{zero of $\fL(z)$}}%
    \put( 123 , 113 ){\makebox(0,0)[l]{zero of $\fL^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{pole}%
    \qbezier[24](0,0)(-61.5,-26.5)(-123,-53)%
    %\put(   0 ,   0 ){\line(-3,-1){130}}%
    \put( -76 , -25 ){\makebox(0,0){$\times$}}%
    \put(-119 , -40 ){\makebox(0,0){$\times$}}%
    \put( -76 , -25 ){\makebox(0,0)[lt]{pole of $\fL(z)$}}%
    \put(-119 , -40 ){\makebox(0,0)[lt]{pole of $\fL^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{circle}%
    \input{../common/circle.inp}
\end{picture}
\end{fsL}
\end{center}
\caption{
   Mirrored roots in complex-z plane
   \label{fig:z-roots}
   }
\end{figure}


\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(700,100)(-100,-60)
  \thicklines
  %\graphpaper[10](0,0)(160,80)
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(m)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[b]{$\Szxx(z)$}                  }
  \put(-100,   0 ){\vector  (  1,  0){100}                           }

  \put(   0, -50 ){\framebox(100,100)   {$\convd\gamma(n)$}           }
  \put(   0, -40 ){\makebox (100, 80)[t]{whitening}                  }
  \put(   0, -40 ){\makebox (100, 80)[b]{$\Gamma(z)$}                }
  \put( 100,   0 ){\vector  (  1,  0)   {200}                        }
  \put( 100,  10 ){\makebox (200, 40)[t]{white noise process}        }
  \put( 100,  10 ){\makebox (200, 40)[b]{$\vw(n)$}                 }
  \put( 100, -50 ){\makebox (200, 40)[t]{$\Rww(m)=\delta(m)$}  }
  \put( 100, -50 ){\makebox (200, 40)[b]{$\Sww(z)=1$}                }

  \put( 300, -50 ){\framebox(100,100)   {$\convd\fl(n)$}               }
  \put( 300, -40 ){\makebox (100, 80)[t]{innovations}                }
  \put( 300, -40 ){\makebox (100, 80)[b]{$\fL(z)$}                     }
  \put( 400,   0 ){\vector  (  1,  0)   {100}                        }
  \put( 400,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put( 400, -50 ){\makebox (200, 40)[t]{$\Rxx(m)=l(m)\convd\fl^\ast(-m)$}  }
  \put( 400, -50 ){\makebox (200, 40)[b]{$\Szxx(z)=L(z)\fL^\ast\brp{\frac{1}{z^\ast}}$}  }
  \end{picture}
\caption{
   Innovations and whitening filters
   \label{fig:d-innovations}
   }
\end{center}
\end{fsK}
\end{figure}


The next theorem demonstrates a method for ``whitening"
a \fncte{random sequence} $\rvx(n)$ with a filter constructed from a decomposition
of $\Rxx(m)$.
The technique is stated precisely in \prefp{thm:d-innovations}
and illustrated in \prefp{fig:d-innovations}.
Both imply two filters with impulse responses $l(n)$ and $\gamma(n)$.
Filter $l(n)$ is referred to as the \textbf{innovations filter}
(because it generates or ``innovates" $\rvx(n)$ from a white noise
process $\fw(n)$)
and $\gamma(n)$ is referred to as the \textbf{whitening filter}
because it produces a white noise sequence when the input sequence
is $\rvx(n)$.\footnote{\citerpp{papoulis}{401}{402}}


%---------------------------------------
\begin{theorem}
\label{thm:d-innovations}
%---------------------------------------
Let $\rvx(n)$ be a WSS \fncte{random sequence} with auto-correlation $\Rxx(m)$
and spectral density $\Szxx(z)$.
\textbf{If} $\Szxx(z)$ has a \textbf{rational expression},
then the following are true:

\begin{enume}
   \item There exists a rational expression $\fL(z)$ with minimum phase
         such that
         \[ \Szxx(z) =\fL(z)\fL^\ast\brp{\frac{1}{z^\ast}}. \]
   \item An LTI filter for which the Laplace transform of
         the impulse response $\gamma(n)$ is
         \[ \Gamma(z) = \frac{1}{\fL(z)} \]
         is both causal and stable.
   \item If $\rvx(n)$ is the input to the filter $\gamma(n)$,
         the output $\fy(n)$ is a \textbf{white noise sequence} such that
         \[ \Syy(z)=1 \hspace{2cm} \Ryy(m)=\kdelta(m).\]
\end{enume}
\end{theorem}


\begin{proof}
\begin{align*}
   \Sww(z)
     &= \Gamma(z)\Gamma^\ast\brp{\frac{1}{z^\ast}} \Szxx(z)
   \\&= \frac{1}{\fL(z)} \frac{1}{\fL^\ast\brp{\frac{1}{z^\ast}}} \Szxx(z)
   \\&= \frac{1}{\fL(z)} \frac{1}{\fL^\ast\brp{\frac{1}{z^\ast}}}
        \fL(z)\fL^\ast\brp{\frac{1}{z^\ast}}
   \\&= 1
\end{align*}
\end{proof}

