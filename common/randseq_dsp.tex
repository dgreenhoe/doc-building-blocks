%============================================================================
% LaTeX File
% Daniel J. Greenhoe
%============================================================================
%=======================================
\chapter{Random Sequence DSP}
%=======================================
%=======================================
\section{LTI filtering}
%=======================================
%---------------------------------------
\begin{minipage}{\tw-50mm}
\begin{theorem}
\footnotemark
\label{thm:Rxyh}
%---------------------------------------
Let $\rvx(n)$ be a \fncte{random sequence} with \fncte{mean} $\pmeanx$
and $\rvy(n)$    a \fncte{random sequence} with \fncte{mean} $\pmeany$.
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\end{theorem}
\end{minipage}
\hfill\tbox{\includegraphics{graphics/sysH_xy.pdf}}
\footnotetext{
  \citerp{papoulis}{310}
  }
\\
\thmbox{
   \brb{\begin{array}{M}
      $\opS$ is
   %\\\prope{linear time invariant}
    (\prope{LTI})
  \end{array}}
  \implies
  \brb{\begin{array}{Frc>{\ds}l>{\ds}lD}
       (1).&\pmeany(n)&=& \sum_{k\in\Z} \fh(k)      \pmeanx(n-k)  &\eqd \fh(n)\convd \pmeanx(n) & and
     \\(2).&\Rxy(n,m) &=& \sum_{k\in\Z} \fh^\ast(k) \Rxx(n-k,m+k) &                            & and 
     \\(3).&\Ryy(n,m) &=& \sum_{k\in\Z} \fh^\ast(k) \Ryx(n-k,m+k)
  \end{array}} 
  }
\\
\begin{proof}
\begin{align*}
   \pmeany(n)
     &\eqd \pE\brs{\rvy(n)}
     && \text{by definition of $\pmeany$}
     && \text{\xref{def:pmeanxn}}
   \\&= \pE\brs{\sum_{k\in\Z} \fh(k) \rvx(n-k)}
     && \text{by \prope{LTI} hypothesis}
   \\&= \sum_{k\in\Z} \fh(k) \pE\brs{\rvx(n-k)}
     && \text{by \prope{linear} property}
   \\&= \sum_{k\in\Z} \fh(k) \pmeanx(n-k)
     && \text{by definition of $\pmeanx$}
     && \text{\xref{def:pmeanxn}}
   \\&\eqd \fh(n)\convd \pmeanx(n) 
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Rxy(n,m)
     &\eqd \pE\brs{\rvx(n+m) \rvy^\ast(n) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvx(n+m) \brp{\fh(n)\convd\rvx(n)}^\ast}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvx(n+m) \brp{ \sum_{k\in\Z} h(k) \rvx(n-k) }^\ast }
     && \text{by definition of \ope{convolution} $\conv$}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvx(n+m) \sum_{k\in\Z} \fh^\ast(k) \rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvx(n+m)\rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(n-k+k+m) \rvx^\ast(n-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(n-k,m+k)
     && \text{by definition of $\Rxx(n,m)$}
     && \text{\xref{def:Rxxnm}}
   %\\&\eqd \sum_{k'\in\Z} \fh^\ast(-k') \Rxx(n+k',m-k')
   %  && \text{where $k'\eqd -k$}
   %\\&\eqd \sum_{k\in\Z} \fh^\ast(-k) \Rxx(n+k,m-k)
   %  && \text{where $k\eqd k'$}
   %\\&= \Rxx(n+k,m) \convd \fh^\ast(-m)
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Ryy(n,m)
     &\eqd \pE\brs{\rvy(n+m) \rvy^\ast(n) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvy(n+m) \brp{\fh(n)\convd\rvx(n)}^\ast}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvy(n+m) \brp{ \sum_{k\in\Z} \fh(k) \rvx(n-k) }^\ast }
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvy(n+m) \sum_{k\in\Z} \fh^\ast(k) \rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvy(n+m)\rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&=    \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvy(n-k+k+m) \rvx^\ast(n-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Ryx(n-k,m+k)
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Ryynm}}
   %\\&= \sum_{k'\in\Z} \fh^\ast(-k') \Ryx(n+k',m-k')
   %  && \text{where $k'\eqd-k$}
   %\\&= \sum_{k\in\Z} \fh^\ast(-k) \Ryx(n+k,m-k)
   %  && \text{where $k\eqd k'$}
   %\\&\eqd \Ryx(n+k,m) \convd \fh^\ast(-m)
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   %\\
   %\\
   %\Ryy(n,m)
   %  &= \Rxy(n,m)\convd \fh(m)
   %  && \text{by previous result}
   %\\&= \brs{\Rxx(n,m) \convd \fh^\ast(-m)}\convd \fh(-m)
   %  && \text{by previous result}
   %\\&= \Rxx(n,m) \convd \fh(-m) \convd \fh^\ast(-m)
   %  && \text{by previous result}
   %\\
   %\\
   %\Ryy(n,m)
   %  &= \Rxx(n,m)\convd\fh(-m) \convd \fh^\ast(-m)
   %  && \text{by previous result}
   %\\&\eqd \sum_{p\in\Z}\fh^\ast(-p) \brs{\Rxx(n,m-p)\convd\fh(-m)}
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   %\\&= \sum_{p\in\Z}\fh^\ast(-p) \sum_{k\in\Z}\fh(-k) \Rxx(n,m-p-k)
   %  && \text{by definition of \ope{convolution}}
   %  && \text{\xref{def:dsp_conv}}
   %\\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(-k) \fh^\ast(-p) \Rxx(n,m-p-k)
   %  && \text{by \prope{distributive} property of $\fieldC$}
   %  && \text{\xref{def:field}}
\end{align*}
\end{proof}

\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(300,100)(-100,-60)
  \thicklines
  %\graphpaper[10](0,0)(160,80)
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(m)$}  }
  \put(-100, -50 ){\makebox (100, 40)[b]{$\Sxx(z)$}  }
  \put(-100,   0 ){\vector  (  1,  0){100}             }
  \put(   0, -50 ){\framebox(100,100){$\convd\fh(n)$}  }
  \put( 100,   0 ){\vector  (  1,  0){100}             }
  \put( 100,  10 ){\makebox (100, 40)[b]{$\rvy(n)$}  }
  \put( 100, -50 ){\makebox (100, 40)[t]{$\Ryy(m)$}  }
  \put( 100, -50 ){\makebox (100, 40)[b]{$\Syy(z)$}  }
  \put(  50, -60 ){\makebox (  0,  0)[t]{$\Rxy(m)$}  }
  \end{picture}
\caption{
   Linear system with WSS \fncte{random sequence} input and output
   \label{fig:d-linear-sys-WSS}
   }
\end{center}
\end{fsK}
\end{figure}

%=======================================
\section{LTI filtering of WSS sequences}
%=======================================
%---------------------------------------
\begin{minipage}{\tw-50mm}
\begin{corollary}
\footnotemark
\label{cor:Rxyh}
%---------------------------------------
Let $\rvx(n)$ be a \fncte{random sequence} with \fncte{auto-correlation} $\Rxx(n,m)$,
    $\rvy(n)$    a \fncte{random sequence} with \fncte{auto-correlation} $\Ryy(n,m)$,
and $\Rxy(n,m)$  the \fncte{cross-correlation} of $\rvx$ and $\rvy$.
Let $\opS$ be a \structe{system} with input $\rvx(n)$, output $\rvy(n)$, 
and \fncte{impulse response} $\fh(n)$.
\end{corollary}
\end{minipage}
\hfill\tbox{\includegraphics{graphics/sysH_xy.pdf}}
\footnotetext{
  \citerp{papoulis}{323}
  }
\\
\corbox{
  \brbr{\begin{array}{FMD}
      (A). & $\opS$    is \prope{LTI} & and
    \\(B). & $\rvx(n)$ is \prope{WSS} & and
    \\(C). & $\rvy(n)$ is \prope{WSS} &
  \end{array}}
  \implies
  \brbl{\begin{array}{Frc>{\ds}lc>{\ds}lD}
       (1).&\pmeany &=& \pmeanx\sum_{n\in\Z} \fh(k)          &    &                                      & and
     \\(2).&\Rxy(m) &=& \Rxx(m)\convd \fh^\ast(-m)           &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxx(m+k)  & and
     \\(3).&\Ryy(m) &=& \Ryx(m)\convd \fh^\ast(-m)           &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxy(m+k)  & and
     \\(4).&\Ryy(m) &=& \mc{4}{l}{\ds\Rxx^\ast(m)\convd \fh(-m)\convd\fh^\ast(-m)} %&\eqd& \mc{2}{l}{\ds\sum_{p\in\Z}\sum_{k\in\Z}\fh(k)h^\ast(p) \Rxx(m-p-k)}
  \end{array}}
  }
\\
\begin{proof}
\begin{align*}
  \pmeany 
     &= \pmeany(n)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \sum_{n\in\Z} \fh(k) \pmeanx(n-k)
     && \text{by \prefp{thm:Rxynm}}
     && \text{and hypothesis (B)}
   \\&= \sum_{n\in\Z} \fh(k) \pmeanx(0)
     && \text{by \prefp{def:wss}}
     && \text{and hypothesis (B)}
   \\&= \pmeanx(0) \sum_{n\in\Z} \fh(k) 
     && \text{by \prope{linear} property of $\sum$}
   \\&= \pmeanx \sum_{n\in\Z} \fh(k) 
     && \text{by \prefp{prop:Rxynmm}}
   \\
  \Rxy(m)
     &\eqd \Rxy(0,m)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Rxx(0-k,m+k)
     && \text{by \prefp{thm:Rxyh}}
     && \text{and hypothesis (B)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Rxx(m+k)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \fh^\ast(-m) \convd\Rxx(m)
     && \text{by \prefp{prop:conv_knk}}
\\
  \Ryy(m)
     &\eqd \Ryy(0,m)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Ryx(n-k,m+k)
     && \text{by \prefp{thm:Rxyh}}
     && \text{and hypothesis (B)}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \Ryx(m+k)
     && \text{by \prefp{prop:Rxynmm}}
     && \text{and hypothesis (A)}
   \\&= \fh^\ast(-m) \convd\Ryx(m)
     && \text{by \prefp{prop:conv_knk}}
\\
  \Ryy(m)
     &= \fh^\ast(-m) \convd\Ryx(m)
     && \text{by result (2)}
   \\&= \fh^\ast(-m) \convd\Rxy^\ast(m)
     && \text{by \prefp{cor:Rxym}}
   \\&= \fh^\ast(-m) \convd\brs{\fh^\ast(-m) \convd\Rxx(m)}^\ast
     && \text{by result (1)}
   \\&= \fh^\ast(-m) \convd\fh(-m) \convd\Rxx^\ast(m)
      && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
      && \text{\xref{def:staralg}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{theorem}
\footnote{
  \citerp{papoulis}{323}
  }
\label{thm:ZSxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\thmbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{F>{\ds}rc>{\ds}lD}
       (1).&\ZSxy(z) &=& \ZSxx(z) \Zh^\ast\brp{\frac{1}{z^\ast}}      & and
     \\(2).&\ZSyy(z) &=& \ZSyx(z) \Zh^\ast\brp{\frac{1}{z^\ast}}      & and
     \\(3).&\ZSyy(z) &=& \ZSxx(z) \Zh\brp{z} \Zh^\ast\brp{\frac{1}{z^\ast}}
  \end{array}}
  }
\end{theorem}
\begin{proof}
\begin{align*}
  \ZSxy(z)
     &\eqd \opZ \Rxy(m)
    && \text{by definition of $\Sxy(z)$}
    && \text{\xref{def:csd}}
   \\&= \opZ \brs{\Rxx(m) \convd \fh^\ast(-m)}
    && \text{by \prefp{cor:Rxyh}}
   \\&= \brs{\opZ\Rxx(m)}\,\opZ\brs{\fh^\ast(-m)}
    && \text{by \thme{convolution theorem}}
    && \text{\xref{thm:conv}}
   \\&= \ZSxx(z) \Zh^\ast\brp{\frac{1}{z^\ast}}
    && \text{by \prefp{thm:opZ}}
   \\
   \\
  \ZSyy(z)
     &\eqd \opZ \Ryy(m)
    && \text{by definition of $\ZSyy(z)$}
    && \text{\xref{def:csd}}
   \\&= \opZ \brs{\Ryx(m) \convd \fh^\ast(-m)}
    && \text{by \prefp{cor:Rxyh}}
   \\&= \brs{\opZ\Ryx(m)}\,\opZ\brs{\fh^\ast(-m)}
    && \text{by \thme{convolution theorem}}
    && \text{\xref{thm:conv}}
   \\&= \ZSyx(z) \Zh^\ast\brp{\frac{1}{z^\ast}}
    && \text{by \prefp{thm:opZ}}
   \\
   \\
  \ZSyy(z)
     &= \ZSyx(z) \Zh^\ast\brp{\frac{1}{z^\ast}}
     && \text{by previous result}
     && \text{(2)}
   \\&= \ZSxy^\ast\brp{\frac{1}{z^\ast}} \Zh^\ast\brp{\frac{1}{z^\ast}}
     && \text{by \prefp{thm:ZSxy_sym}}
   \\&= \brs{ \ZSxx(z') \Zh^\ast\brp{\frac{1}{z'^\ast}} }^\ast_{z'=\frac{1}{z^\ast}} 
        \Zh^\ast\brp{\frac{1}{z^\ast}}
     && \text{by previous result}
     && \text{(1)}
   \\&= \ZSxx^\ast\brp{\frac{1}{z^\ast}} \Zh\brp{z} \Zh^\ast\brp{\frac{1}{z^\ast}}
   \\&= \ZSxx(z) \Zh\brp{z} \Zh^\ast\brp{\frac{1}{z^\ast}}
     && \text{by \pref{thm:ZSxy_sym}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:Swxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Swxy(\omega) &=& \ds \Swxx(\omega) \Fh^\ast(\omega) & and
     \\(2).&\Swyy(\omega) &=& \ds \Swxy(\omega) \Fh     (\omega)   & and
     \\(3).&\Swyy(\omega) &=& \mc{2}{l}{\ds \Swxx(\omega) \abs{\Fh(\omega)}^2}
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{align*}
   \Swxy(\omega)
     &= \brlr{\ZSxy(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\ZSxx(z)\Zh^\ast\brp{\frac{1}{z^\ast}}}_{z=e^{i\omega}}
     && \text{by \prefp{thm:ZSxy}}
   \\&= \ZSxx\brp{e^{i\omega}}\Zh^\ast\brp{\frac{1}{e^{i\omega\ast}}}
   \\&= \ZSxx\brp{e^{i\omega}}\Zh^\ast\brp{e^{i\omega}}
   \\&= \Swxx(\omega) \Fh^\ast(\omega)
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\
   \Swyy(\omega)
     &= \Swyy^\ast(\omega)
     && \text{becauase $\Swyy$ is \prope{real-valued}}
   \\&= \brp{\brlr{\ZSyy(z)}_{z=e^{i\omega}}}^\ast
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brp{\brlr{\ZSyx(z)\Zh^\ast\brp{\frac{1}{z^\ast}}}_{z=e^{i\omega}}}^\ast
     && \text{by \prefp{thm:ZSxy}}
   \\&= \brp{\ZSyx\brp{e^{i\omega}} \Zh^\ast\brp{\frac{1}{e^{i\omega\ast}}}}^\ast
   \\&= \brp{\ZSyx\brp{e^{i\omega}} \Zh^\ast\brp{e^{i\omega}}}^\ast
   \\&= \brp{\Swyx(\omega) \Fh^\ast(\omega)}^\ast
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \Swxy(\omega) \Fh(\omega)
   \\
   \Swyy(\omega)
     &= \brlr{\ZSyy(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\ZSxx(z)\Zh\brp{z} \Zh^\ast\brp{\frac{1}{z^\ast}}}_{z=e^{i\omega}}
     && \text{by \prefp{thm:ZSxy}}
   \\&= \ZSxx\brp{e^{i\omega}} \Zh\brp{e^{i\omega}} \Zh^\ast\brp{\frac{1}{e^{i\omega\ast}}}
   \\&= \ZSxx\brp{e^{i\omega}} \Zh\brp{e^{i\omega}} \Zh^\ast\brp{e^{i\omega}}
   \\&= \Swxx(\omega) \Fh(\omega) \Fh^\ast(\omega)
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \Swxx(\omega) \abs{\Fh(\omega)}^2
   \\
     &\text{alternative proof to previous one:}
   \\
   \Swyy(\omega)
     &= \Swyx(\omega) \Fh^\ast(\omega)
     && \text{by previous result}
     && \text{(2)}
   \\&= \Swxy^\ast(\omega) \Fh^\ast(\omega)
     && \text{by \prefp{cor:Swxy_sym}}
   \\&= \brs{\Swxx(\omega) \Fh^\ast(\omega)}^\ast \Fh^\ast(\omega)
     && \text{by previous result}
     && \text{(1)}
   \\&= \Swxx^\ast(\omega) \Fh(\omega) \Fh^\ast(\omega)
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&= \Swxx(\omega) \abs{\Fh(\omega)}^2
     && \text{by \prefp{cor:Swxy_sym}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{minipage}{\tw-70mm}
\begin{theorem}
\label{thm:xGw_xHy}
%---------------------------------------
Let $\opS$ be the \structe{system} illustrated to the right.
\end{theorem}
\end{minipage}
\hfill\tbox{\includegraphics{graphics/xGy_xHw.pdf}}
\\
\thmbox{
  \brb{\begin{array}{FMMD}
      (A).& $\fg(n)$  is &\prope{LTI}       & and
    \\(B).& $\rvx(n)$ is &\prope{WSS}       & 
  \end{array}}
  \implies
  \brb{\begin{array}{rc>{\ds}lDD}
    \Rwy(m) &=&    \sum_{n\in\Z}\fg(n)\Rxy(m-n) 
          \\&\eqd& \fg(n)\convd\Rxy(m-n)
            && (\ope{convolution})
  \end{array}}
  }
\\
\begin{proof}
\begin{align*}
  \Rwy(m)
  \\&\eqd \pE\brs{\rvw(m)\rvy^\ast(0)}
    && \text{by definition of $\Rxy$}
    && \text{\xref{def:Rxym}}
  \\&= \pE\brs{\sum_{n\in\Z}\fg(n)\rvx(m-n)\rvy^\ast(0)}
    && \text{by \prope{LTI} hypothesis}
    && \text{(A)}
  \\&= \sum_{n\in\Z}\fg(n)\pE\brs{\rvx(m-n)\rvy^\ast(0)}
    && \text{by \prope{linearity}}
    && \text{\xref{def:linop}}
  \\&= \sum_{n\in\Z}\fg(n)\Rxy(m-n)
    && \text{by definition of $\Rxy$}
    && \text{\xref{def:Rxym}}
  \\&= \brs{\fg(n)\convd\Rxy(m-n)}
    && \text{by definition of \ope{convolution}}
    && \text{\xref{def:dsp_conv}}
  \\&= \FG(\omega)\Sxy(\omega)
    && \text{by \thme{Convolution Theorem}}
    && \text{\xref{thm:conv}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:xGw_xHy}
%---------------------------------------
Let $\opS$ be the \structe{system} illustrated in \prefpp{thm:xGw_xHy}.
\corbox{
  \brb{\begin{array}{M}
    hypotheses of \prefpp{thm:xGw_xHy}
  \end{array}}
  \implies
  \brb{\begin{array}{Frc>{\ds}lD}
      (1).&\Szwy(z)      &=& \FG(z)     \Szxy(z)
    \\(2).&\Swwy(\omega) &=& \FG(\omega)\Swxy(\omega)
  \end{array}}
  }
\end{corollary}
%\\
%\begin{proof}
%\begin{align*}
%  \Swwy(m)
%  \\&\eqd \pE\brs{\rvw(m)\rvy^\ast(0)}
%    && \text{by definition of $\Rxy$}
%    && \text{\xref{def:Rxym}}
%  \\&= \pE\brs{\sum_{n\in\Z}\fg(n)\rvx(m-n)\rvy^\ast(0)}
%    && \text{by \prope{LTI} hypothesis}
%    && \text{(A)}
%  \\&= \sum_{n\in\Z}\fg(n)\pE\brs{\rvx(m-n)\rvy^\ast(0)}
%    && \text{by \prope{linearity}}
%    && \text{\xref{def:linop}}
%  \\&= \sum_{n\in\Z}\fg(n)\Rxy(m-n)
%    && \text{by definition of $\Rxy$}
%    && \text{\xref{def:Rxym}}
%  \\&= \brs{\fg(n)\convd\Rxy(m-n)}
%    && \text{by definition of \ope{convolution}}
%    && \text{\xref{def:dsp_conv}}
%  \\&= \FG(\omega)\Sxy(\omega)
%    && \text{by \thme{Convolution Theorem}}
%    && \text{\xref{thm:conv}}
%\end{align*}
%\end{proof}


%=======================================
\section{Whitening}
\index{whitening filter}
\label{sec:d-whiten}
%=======================================
\begin{figure}[h]
  \centering
  \includegraphics{graphics/pz_minphase.pdf}
  \caption{
     Poles ($\times$) and zeros ($o$) of a \prope{minimum phase} filter
     \label{fig:w_pz_minphase}
     }
\end{figure}
%---------------------------------------
\begin{definition}
\index{minimum phase}
\index{rational expression}
%---------------------------------------
Let $\Zh(z)$ be the z-transform of the impulse response of a filter.
If $\Zh(z)$ can be expressed as a rational expression with poles and zeros
$r_ne^{i\theta_n}$,
then the filter is \textbf{minimum phase} if each $r_n<1$
(all roots lie inside the unit circle in the complex $z$-plane).
\end{definition}
See \prefp{fig:w_pz_minphase}.

Note that if $\fL(z)$ has a root at $z=re^{i\theta}$, then
$\fL^\ast(1/z^\ast)$ has a root at
\begin{align*}
   \frac{1}{z^\ast}
     &= \frac{1}{\brp{re^{i\theta}}^\ast}
      = \frac{1}{re^{-i\theta}}
      = \frac{1}{r} e^{i\theta}.
\end{align*}
That is, if $\fL(z)$ has a root inside the unit circle,
then $\fL^\ast(1/z^\ast)$ has a root directly opposite across the unit circle
boundary (see \prefp{fig:z-roots}).
A causal stable filter $\Zh(z)$ must have all of its poles inside
the unit circle.
A minimum phase filter is a filter with both its poles and zeros inside the
unit circle.
One advantage of a minimum phase filter is that its recipricol
(zeros become poles and poles become zeros)
is also causal and stable.

\begin{figure}[ht]
\begin{center}
\begin{fsL}
\setlength{\unitlength}{0.2mm}
\begin{picture}(300,300)(-130,-130)
  %\graphpaper[10](0,0)(200,200)
  \thicklines%
  \color{axis}%
    \put(-130 ,   0 ){\line(1,0){260} }%
    \put(   0 ,-130 ){\line(0,1){260} }%
    \put( 140 ,   0 ){\makebox(0,0)[l]{$\Re$}}%
    \put(   0 , 140 ){\makebox(0,0)[b]{$\Im$}}%
  \color{zero}%
    \qbezier[24](  0,  0)( 56.5,56.5)(113,113)
    %\put(   0 ,   0 ){\line(1,1){120}}%
    \put(  28 ,  28 ){\circle{10}}%
    \put( 113 , 113 ){\circle{10}}%
    \put(  38 ,  28 ){\makebox(0,0)[l]{zero of $\fL(z)$}}%
    \put( 123 , 113 ){\makebox(0,0)[l]{zero of $\fL^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{pole}%
    \qbezier[24](0,0)(-61.5,-26.5)(-123,-53)%
    %\put(   0 ,   0 ){\line(-3,-1){130}}%
    \put( -76 , -25 ){\makebox(0,0){$\times$}}%
    \put(-119 , -40 ){\makebox(0,0){$\times$}}%
    \put( -76 , -25 ){\makebox(0,0)[lt]{pole of $\fL(z)$}}%
    \put(-119 , -40 ){\makebox(0,0)[lt]{pole of $\fL^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{circle}%
    \input{../common/circle.inp}
\end{picture}
\end{fsL}
\end{center}
\caption{
   Mirrored roots in complex-z plane
   \label{fig:z-roots}
   }
\end{figure}


\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(700,100)(-100,-60)
  \thicklines
  %\graphpaper[10](0,0)(160,80)
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(m)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[b]{$\Sxx(z)$}                  }
  \put(-100,   0 ){\vector  (  1,  0){100}                           }

  \put(   0, -50 ){\framebox(100,100)   {$\convd\gamma(n)$}           }
  \put(   0, -40 ){\makebox (100, 80)[t]{whitening}                  }
  \put(   0, -40 ){\makebox (100, 80)[b]{$\Gamma(z)$}                }
  \put( 100,   0 ){\vector  (  1,  0)   {200}                        }
  \put( 100,  10 ){\makebox (200, 40)[t]{white noise process}        }
  \put( 100,  10 ){\makebox (200, 40)[b]{$\vw(n)$}                 }
  \put( 100, -50 ){\makebox (200, 40)[t]{$\Rww(m)=\delta(m)$}  }
  \put( 100, -50 ){\makebox (200, 40)[b]{$\Sww(z)=1$}                }

  \put( 300, -50 ){\framebox(100,100)   {$\convd\fl(n)$}               }
  \put( 300, -40 ){\makebox (100, 80)[t]{innovations}                }
  \put( 300, -40 ){\makebox (100, 80)[b]{$\fL(z)$}                     }
  \put( 400,   0 ){\vector  (  1,  0)   {100}                        }
  \put( 400,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put( 400, -50 ){\makebox (200, 40)[t]{$\Rxx(m)=l(m)\convd\fl^\ast(-m)$}  }
  \put( 400, -50 ){\makebox (200, 40)[b]{$\Sxx(z)=L(z)\fL^\ast\brp{\frac{1}{z^\ast}}$}  }
  \end{picture}
\caption{
   Innovations and whitening filters
   \label{fig:d-innovations}
   }
\end{center}
\end{fsK}
\end{figure}


The next theorem demonstrates a method for ``whitening"
a \fncte{random sequence} $\rvx(n)$ with a filter constructed from a decomposition
of $\Rxx(m)$.
The technique is stated precisely in \prefp{thm:d-innovations}
and illustrated in \prefp{fig:d-innovations}.
Both imply two filters with impulse responses $l(n)$ and $\gamma(n)$.
Filter $l(n)$ is referred to as the \textbf{innovations filter}
(because it generates or ``innovates" $\rvx(n)$ from a white noise
process $\fw(n)$)
and $\gamma(n)$ is referred to as the \textbf{whitening filter}
because it produces a white noise sequence when the input sequence
is $\rvx(n)$.\footnote{\citerpp{papoulis}{401}{402}}


%---------------------------------------
\begin{theorem}
\label{thm:d-innovations}
%---------------------------------------
Let $\rvx(n)$ be a WSS \fncte{random sequence} with auto-correlation $\Rxx(m)$
and spectral density $\Sxx(z)$.
\textbf{If} $\Sxx(z)$ has a \textbf{rational expression},
then the following are true:

\begin{enume}
   \item There exists a rational expression $\fL(z)$ with minimum phase
         such that
         \[ \Sxx(z) =\fL(z)\fL^\ast\brp{\frac{1}{z^\ast}}. \]
   \item An LTI filter for which the Laplace transform of
         the impulse response $\gamma(n)$ is
         \[ \Gamma(z) = \frac{1}{\fL(z)} \]
         is both causal and stable.
   \item If $\rvx(n)$ is the input to the filter $\gamma(n)$,
         the output $\fy(n)$ is a \textbf{white noise sequence} such that
         \[ \Syy(z)=1 \hspace{2cm} \Ryy(m)=\kdelta(m).\]
\end{enume}
\end{theorem}


\begin{proof}
\begin{align*}
   \Sww(z)
     &= \Gamma(z)\Gamma^\ast\brp{\frac{1}{z^\ast}} \Sxx(z)
   \\&= \frac{1}{\fL(z)} \frac{1}{\fL^\ast\brp{\frac{1}{z^\ast}}} \Sxx(z)
   \\&= \frac{1}{\fL(z)} \frac{1}{\fL^\ast\brp{\frac{1}{z^\ast}}}
        \fL(z)\fL^\ast\brp{\frac{1}{z^\ast}}
   \\&= 1
\end{align*}
\end{proof}

