%============================================================================
% LaTeX File
% Daniel J. Greenhoe
%============================================================================

%======================================
\chapter{Random Sequences}
\label{app:random_processes}
%======================================
\qboxnps
  {Aristotle (384 BC -- 322 BC)
    \index{Aristotle}
    \index{quotes!Aristotle}
    \footnotemark
  }
  {../common/people/aristot.jpg}
  {A likely impossibility is always preferable to an
  unconvincing possibility.}
  \footnotetext{\begin{tabular}[t]{ll}
    quote: & \url{http://en.wikiquote.org/wiki/Aristotle} \\
    image: & \url{http://en.wikipedia.org/wiki/Aristotle}
  \end{tabular}}

%=======================================
%\section{Random sequences}
%=======================================
%---------------------------------------
\section{Definitions}
%---------------------------------------
%---------------------------------------
\begin{definition}
\label{def:pmeanxn}
\label{def:pvarxn}
\label{def:Rxxnm}
\label{def:Rxxnm}
\label{def:Ryynm}
\label{def:Rxynm}
%---------------------------------------
Let $\rvx(n)$ and $\rvy(n)$ be \fncte{random sequence}s.\\
\defbox{\begin{array}{MlMlc>{\ds}l}
     The \fnctd{mean}             & \pmeanx(n) & of $\rvx(n)$               is & \pmeanx(n)&\eqd& \pE\brs{\rvx(n)}
   \\The \fnctd{variance}         & \pvarx(n)  & of $\rvx(n)$               is & \pvarx(n) &\eqd& \pE\brp{\brs{\rvx(n)-\pmeanx(n)}^2}
   \\The \fnctd{autocorrelation}  & \Rxx(n,m)  & of $\rvx(n)$               is & \Rxx(n,m) &\eqd& \pE\brs{\rvx(n)\rvx^\ast(n+m)}        %& \text{(\prope{auto-correlation bilinear functional})} 
   \\The \fnctd{crosscorrelation} & \Rxy(n,m)  & of $\rvx(n)$ and $\rvy(n)$ is & \Rxy(n,m) &\eqd& \pE\brs{\rvx(n)\rvy^\ast(n+m)}        %& \text{(\prope{cross-correlation bilinear functional})}
  %\\The \fnctd{autocorrelation operator} & \opR\ff    & of $\ff(t)$               is & \opR f    &\eqd& \int_{u\in\R}\Rxx(t,u) f(u) \du     %& \text{(\prope{auto-correlation operator})}
\end{array}}
\end{definition}

%---------------------------------------
\section{Properties}
%---------------------------------------
%---------------------------------------
\begin{theorem}
\label{thm:Rxxnm}
\label{thm:Ryynm}
\label{thm:Rxynm}
%---------------------------------------
\thmbox{\begin{array}{rcl}
   \Rxx(n,m) &=& \Rxx^\ast(n+m,-m)\\ 
   \Rxy(n,m) &=& \Ryx^\ast(n+m,-m)
\end{array}}
\end{theorem}
\begin{proof}
\begin{align*}
  \Rxy(n,m)
     &\eqd \pE\brs{\rvx(n) \rvy^\ast(n+m)}
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvy^\ast(n+m) \rvx(n)}
     && \text{by \prope{commutative} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&= \brp{\pE\brs{\rvy(n+m) \rvx^\ast(n)}}^\ast
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&= \brp{\pE\brs{\rvy(n+m) \rvx^\ast(n+m-m)}}^\ast
     && \text{by \prope{additive identity} property of $\fieldR$}
     && \text{\ifxref{algebra}{def:field}}
   \\&\eqd \Ryx^\ast(n+m,-m)
     && \text{by definition of $\Rxy$}
     && \text{\xref{def:Rxy}}
   \\
   \\
   \Rxx(n,m)
     &= \brlr{\Rxy(n,m)}_{y=x}
   \\&= \brlr{\Rxy^\ast(n+m,-m)}_{y=x}
     && \text{by previous result}
   \\&= \Rxx^\ast(n+m,-m)
\end{align*}
\end{proof}

\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(300,130)(-100,-80)
  \thicklines
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(n,m)$}  }
  \put(-100,   0 ){\vector  (  1,  0){100}             }
  \put(   0, -50 ){\framebox(100,100){$\conv\fh(n)$}  }
  \put( 100,   0 ){\vector  (  1,  0){100}             }
  \put( 110,   0 ){\makebox (100, 40)[lb]{$\ds\rvy(n)=\fh(n)\conv\rvx(n)=\sum_k\fh(k)\rvx(n-k)$}  }
  \put( 100, -50 ){\makebox (100, 40)[t]{$\Ryy(n,m)$}  }
  \put(  50, -60 ){\makebox (  0,  0)[t]{$\Rxy(n,m)$}  }
  \end{picture}
\caption{
   Linear system with \fncte{random sequence} input and output
   \label{fig:d-linear-sys}
   }
\end{center}
\end{fsK}
\end{figure}

The next theorem describes the statistical properties of an LTI system
with impulse response $\fh(t)$ \xref{fig:d-linear-sys}.

%---------------------------------------
\begin{theorem}
\footnote{
  \citerp{papoulis}{310}
  }
\label{thm:Rxyh}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$, 
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\thmboxt{
  $\brb{\begin{array}{M}
    $\opS$ is \prope{linear time invariant} (\prope{LTI})
  \end{array}}
  \quad\implies$
  \\\qquad$
  \brb{\begin{array}{Frc>{\ds}lc>{\ds}lD}
       (A).&\Rxy(n,m) &=& \Rxx(n,m)\conv \fh^\ast(m) &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxx(n,m-k) & and 
     \\(B).&\Ryy(n,m) &=& \Rxy(n,m)\conv \fh(m)      &\eqd& \sum_{k\in\Z} \fh(k)      \Rxy(n,m-k) & and 
     \\(C).&\Ryy(n,m) &=& \Rxx(n,m)\conv \fh(m)\conv h^\ast(m)
                      &\eqd& \mc{2}{l}{\ds\sum_{p\in\Z} \sum_{k\in\Z} \fh(k)h^\ast(p) \Rxx(n,m-p-k)}
  \end{array}}$
  }
\end{theorem}

\begin{proof}
\begin{align*}
   \Rxy(n,m)
     &\eqd \pE\brs{\rvx(n) \rvy^\ast(n+m) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvx(n) \brp{\fh\conv\rvx}^\ast(n+m)}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvx(n) \brp{ \sum_{k\in\Z} h(k) \rvx(n+m-k) }^\ast }
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvx(n) \sum_{k\in\Z} \fh^\ast(k) \rvx^\ast(n+m-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvx(n)\rvx^\ast(n+m-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(n) \rvx^\ast(n+m-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(n,m-k)
     && \text{by definition of $\Rxx(n,m)$}
     && \text{\xref{def:Rxxnm}}
   \\&\eqd \Rxx(n,m) \conv \fh^\ast(m)
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Ryy(n,m)
     &\eqd \pE\brs{\rvy(n) \rvy^\ast(n+m) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvy(n) \brp{\fh\conv\rvy}^\ast(n+m)}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvy(n) \brp{ \sum_{k\in\Z} h(k) \rvy(n+m-k) }^\ast }
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvy(n) \sum_{k\in\Z} \fh^\ast(k) \rvy^\ast(n+m-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvy(n)\rvy^\ast(n+m-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&=    \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvy(n) \rvy^\ast(n+m-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Ryy(n,m-k)
     && \text{by definition of $\Ryy(n,m)$}
     && \text{\xref{def:Ryynm}}
   \\&\eqd \Ryy(n,m) \conv \fh^\ast(m)
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Ryy(n,m)
     &= \Rxy(n,m)\conv \fh(m)
     && \text{by previous result}
   \\&= \brs{\Rxx(n,m) \conv \fh^\ast(m)}\conv \fh(m)
     && \text{by previous result}
   \\&= \Rxx(n,m) \conv \fh(m) \conv \fh^\ast(m)
     && \text{by previous result}
\\
\\
   \Ryy(n,m)
     &= \Rxx(n,m)\conv\fh(m) \conv \fh^\ast(m)
     && \text{by previous result}
   \\&\eqd \sum_{p\in\Z}\fh^\ast(p) \brs{\Rxx(n,m-p)\conv\fh(m)}
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&= \sum_{p\in\Z}\fh^\ast(p) \sum_{k\in\Z}\fh(k) \Rxx(n,m-p-k)
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(k) \fh^\ast(p) \Rxx(n,m-p-k)
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\xref{def:field}}
\end{align*}
\end{proof}


%---------------------------------------
\section{Wide Sense Stationary processes}
\index{wide sense stationary}
\index{WSS}
%---------------------------------------
%---------------------------------------
\begin{definition}
%---------------------------------------
Let $\rvx(n)$ be a \fncte{random sequence} with \fncte{mean} $\pmeanx(n)$ and
\fncte{variance} $\pvar(n)$ \xref{def:pvarxn}.
\\
\defboxt{
  $\rvx(n)$ is \propd{wide sense stationary} (\propd{WSS}) if
  \\\indentx
    $\begin{array}{FlMMD}
       1. & \pmeanx(n)  & is \prope{constant} with respect to $n$ & (\prope{stationary in the 1st moment})    & and\\
       2. & \pvarx(n)   & is \prope{constant} with respect to $n$ & (\prope{stationary in the 2nd moment})
    \end{array}$
  }
\end{definition}

%---------------------------------------
\begin{definition}
\label{def:mean_wss}
\label{def:Rxxm}
\label{def:Rxym}
%---------------------------------------
Let $\rvx(n)$ be a \fncte{random sequence} with statistics 
$\pmeanx(n)$, $\pvarx(n)$, $\Rxx(n,m)$, and $\Rxy(n,m)$ \xref{def:Rxynm}.
\defboxt{
  $\brb{\begin{array}{M}
    $\rvx$ and $\rvy$ are
    \prope{wide sense stationary}
  \end{array}}\quad\implies$
  \\\quad$
  \brb{\begin{array}{FMlMlc>{\ds}l}
     (1).&The \fnctd{mean}             & \pmeanx  & of $\rvx(n)$               is & \pmeanx &\eqd& \pE\brs{\rvx(0)}
   \\(2).&The \fnctd{variance}         & \pvarx   & of $\rvx(n)$               is & \pvarx  &\eqd& \pE\brp{\brs{\rvx(0)-\pmeanx}^2}
   \\(3).&The \fnctd{autocorrelation}  & \Rxx(m)  & of $\rvx(n)$               is & \Rxx(m) &\eqd& \pE\brs{\rvx(0)\rvx^\ast(n+m)}
   \\(4).&The \fnctd{crosscorrelation} & \Rxy(m)  & of $\rvx(n)$ and $\rvy(n)$ is & \Rxy(m) &\eqd& \pE\brs{\rvx(0)\rvy^\ast(n+m)}
  %\\The \fnctd{autocorrelation operator} & \opR\ff    & of $\ff(t)$               is & \opR f    &\eqd& \int_{u\in\R}\Rxx(t,u) f(u) \du     %& \text{(\prope{auto-correlation operator})}
\end{array}}$
  }
\end{definition}

%---------------------------------------
\begin{remark}
%---------------------------------------
  The $\Rxy(n,m)$ of \prefpp{def:Rxynm} and the $\Rxy(m)$ of \prefpp{def:Rxym} (etc.) are examples
  of \hie{function overload}---that is, functions that use the same 
  mnemonic but are distinguished by different domains.
  Perhaps a more common example of function overload is the ``$+$" mnemonic. 
  Traditionally it is used with domain of the natural numbers $\N$ as in $3+2$.
  Later it was extended for domain real numbers $\R$ as in $\sqrt{3}+\sqrt{2}$,
  or even complex numbers $\C$ as in $\brp{\sqrt{3}+i\sqrt{2}}+\brp{e+i\pi}$.
  And it was even more dramatically extended for use with domain $\R^\xN\times\R^\xM$
  in ``linear algebra" as in
  \\\indentx$
    \brs{\begin{array}{cc}1&2\\3&4\end{array}} +
    \brs{\begin{array}{cc}5&6\\7&8\end{array}} =
    \brs{\begin{array}{cc}6&8\\10&12\end{array}}
   $
\end{remark}

%---------------------------------------
\begin{corollary}
\label{cor:Rxx}
%---------------------------------------
Let $\rvy(n)$ be a \fncte{random process},
    $\rvx(n)$    a \fncte{random sequence} with \fncte{autocorrelation} $\Rxx(n,m)$,
and $\Rxy$    the \fncte{cross-correlation} of $\rvx$ and $\rvy$.
\corbox{
  \brb{\begin{array}{M}
    $\rvx$ and $\rvy$ are\\
    \prope{wide sense stationary}
  \end{array}}
  \implies
  \brb{\begin{array}{rclD}
    \Rxx(m) &=& \Rxx^\ast(-m) & (\prope{conjugate symmetric})\\ 
    \Rxy(m) &=& \Ryx^\ast(-m)
  \end{array}}
}
\end{corollary}
\begin{proof}
\begin{align*}
  \Rxy(m)
     &\eqd \Rxy(0,m)
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxym}}
   \\&= \Ryx^\ast(0+m,-m)
     && \text{by \prope{non-WSS result}}
     && \text{\xref{thm:Rxynm}}
   \\&\eqd \brp{\pE\brs{\rvy(0+m) \rvx^\ast(0+m-m)}}^\ast
   \\&=    \brp{\pE\brs{\rvy(m-m) \rvx^\ast(0+m-m-m)}}^\ast
     && \text{by \prope{WSS} hypothesis}
     && \text{\xref{def:wss}}
   \\&=    \brp{\pE\brs{\rvy(0) \rvx^\ast(-m)}}^\ast
   \\&\eqd \Ryx^\ast(0,-m)
     && \text{by definition of $\Rxy(m,n)$}
     && \text{\xref{def:Rxy}}
   \\&\eqd \Ryx^\ast(-m)
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxym}}
   \\
   \\
   \Rxx(m)
     &= \brlr{\Rxy(m)}_{y=x}
   \\&= \brlr{\Ryx^\ast(-m)}_{y=x}
     && \text{by previous result}
   \\&= \Rxx^\ast(-m)
\end{align*}
\end{proof}


\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(300,100)(-100,-60)
  \thicklines
  %\graphpaper[10](0,0)(160,80)
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(m)$}  }
  \put(-100, -50 ){\makebox (100, 40)[b]{$\Sxx(z)$}  }
  \put(-100,   0 ){\vector  (  1,  0){100}             }
  \put(   0, -50 ){\framebox(100,100){$\conv\fh(n)$}  }
  \put( 100,   0 ){\vector  (  1,  0){100}             }
  \put( 100,  10 ){\makebox (100, 40)[b]{$\rvy(n)$}  }
  \put( 100, -50 ){\makebox (100, 40)[t]{$\Ryy(m)$}  }
  \put( 100, -50 ){\makebox (100, 40)[b]{$\Syy(z)$}  }
  \put(  50, -60 ){\makebox (  0,  0)[t]{$\Rxy(m)$}  }
  \end{picture}
\caption{
   Linear system with WSS \fncte{random sequence} input and output
   \label{fig:d-linear-sys-WSS}
   }
\end{center}
\end{fsK}
\end{figure}

The next theorem describes the statistical properties of an LTI system
with impulse response $\fh(t)$ and with an input which is a
WSS \fncte{random sequence} \xref{fig:d-linear-sys-WSS}.
%---------------------------------------
\begin{corollary}
\footnote{
  \citerp{papoulis}{323}
  }
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$, 
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corboxt{
  $\brb{\begin{array}{FMMD}
    (A). & $\opS$ is \prope{linear time invariant}             & (\prope{LTI}) & and\\
    (B). & $\rvx$ and $\rvy$ are \prope{wide sense stationary} & (\prope{WSS}) & 
  \end{array}}
  \quad\implies$
    \\\qquad$
  \brb{\begin{array}{Frc>{\ds}lc>{\ds}lD}
       (1).&\Rxy(m) &=& \Rxx(m)\conv \fh^\ast(m)            &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxx(m-k)  & and 
     \\(2).&\Ryy(m) &=& \Rxy(m)\conv \fh(m)                 &\eqd& \sum_{k\in\Z} \fh(k) \Rxy(m-k)        & and 
     \\(3).&\Ryy(m) &=& \Rxx(m)\conv \fh(m)\conv\fh^\ast(m) &\eqd& \mc{2}{l}{\ds\sum_{p\in\Z}\sum_{k\in\Z}\fh(k)h^\ast(p) \Rxx(m-p-k)}
  \end{array}}
  $
  }
\end{corollary}
\begin{proof}
\begin{align*}
  \Rxy(m)
     &\eqd \Rxy(0,m)
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxym}}
   \\&= \Rxx(0,m)\conv \fh^\ast(m) %\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(0,m-k) 
     && \text{by \prope{non-WSS} case}
     && \text{\xref{thm:Rxyh}}
   \\&\eqd \Rxx(m)\conv \fh^\ast(m) 
     && \text{by definition of $\Rxx(m)$}
     && \text{\xref{def:Rxxm}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(m-k) 
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
\\
\\
  \Ryy(m)
     &\eqd Ryy(0,m)
     && \text{by definition of $\Ryy(m)$}
     && \text{\xref{def:Rxxm}}
   \\&= \Rxy(0,m)\conv \fh(m) 
     && \text{by \prope{non-WSS} case}
     && \text{\xref{thm:Rxyh}}
   \\&\eqd \Rxy(m)\conv \fh(m) 
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxxm}}
   \\&\eqd \sum_{k\in\Z} \fh(k) \Rxy(m-k) 
\\
\\
  \Ryy(m)
    &= \Rxy(m)\conv \fh(m) 
    && \text{by previous result}
  \\&= \Rxx(m)\conv \fh^\ast(m) \conv \fh(m) 
    && \text{by previous result}
  \\&= \Rxx(m)\conv \fh(m) \conv \fh^\ast(m) 
\\
\\
  \Ryy(m) 
     &\eqd \Ryy(0,m) 
     && \text{by definition of $\Ryy(m)$}
     && \text{\xref{def:Rxxm}}
   \\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(k)h^\ast(p) \Rxx(0-k,m-p)
     && \text{by \prope{non-WSS} case}
     && \text{\xref{thm:Rxyh}}
   \\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(k)h^\ast(p) \Rxx(m-p-k)
     && \text{by definition of $\Rxx(m)$}
     && \text{\xref{def:Rxxm}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{definition}
\label{def:psd}
\label{def:csd}
%---------------------------------------
Let $\rvx(n)$ and $\rvy(n)$ be a \prope{wide sense stationary} \fncte{random sequence}es
with auto-correlation $\Rxx(m)$ and cross-correlation $\Rxy(m)$.
Let $\opZ$ be the \ope{Z-transform operator}\ifsxref{dsp}{def:opZ}.
\\
\defbox{\begin{array}{MMrclcl}
   The \opd{power spectral density} & (\opd{PSD}) of $\vx$ is           & \Sxx(z) &\eqd& \opZ{\Rxx(m)} &\eqd& \ds \sum_{m\in\Z} \Rxx(m) z^{-m}\\
   The \opd{cross spectral density} & (\opd{CSD}) of $\vx$ and $\vy$ is & \Sxy(z) &\eqd& \opZ{\Rxy(m)} &\eqd& \ds \sum_{m\in\Z} \Rxy(m) z^{-m}
\end{array}}
\end{definition}

%---------------------------------------
\begin{theorem}
\footnote{
  \citerp{papoulis}{323}
  }
\label{thm:Sxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$, 
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\thmbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Sxy(z) &=& \ds \Sxx(z) \Zh^\ast\brp{z^\ast} & and 
     \\(2).&\Syy(z) &=& \ds \Sxy(z) \Zh(z)               & and 
     \\(3).&\Syy(z) &=& \mc{2}{l}{\ds \Sxx(z) \Zh(z) \Zh^\ast\brp{z^\ast}}
  \end{array}}
  }
\end{theorem}
\begin{proof}
\begin{align*}
  \Sxy(z)
     &\eqd \opZ \Rxy(m)
    && \text{by definition of $\Sxy(z)$}
    && \text{\xref{def:csd}}
   \\&= \opZ \brs{\Rxx(m) \conv \fh^\ast(m)}
    && \text{by \prefp{thm:Rxyh}}
   \\&= \brs{\opZ\Rxx(m)}\,\opZ\brs{\fh^\ast(m)}
    && \text{by \thme{convolution theorem}}
    && \text{\xref{thm:conv}}
   \\&= \Sxx(z) \Zh^\ast\brp{z^\ast}
   \\
   \\
  \Syy(z)
     &\eqd \opZ \Ryy(m)
    && \text{by definition of $\Syy(z)$}
    && \text{\xref{def:csd}}
   \\&= \opZ \brs{\Rxy(m) \conv \fh(m)}
    && \text{by \prefp{thm:Rxyh}}
   \\&= \brs{\opZ\Rxy(m)}\,\opZ\brs{\fh(m)}
    && \text{by \thme{convolution theorem}}
    && \text{\xref{thm:conv}}
   \\&\eqd \Sxy(z) \Zh(z)
   \\
   \\
  \Syy(z)
     &= \Sxy(z) \Zh(z)
     && \text{by previous result}
   \\&= \Sxx(z) \Zh^\ast\brp{z^\ast} \Zh(z)
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:Swxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$, 
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Swxy(\omega) &=& \ds \Swxx(\omega) \Fh^\ast(-\omega) & and 
     \\(2).&\Swyy(\omega) &=& \ds \Swxy(\omega) \Fh(\omega)       & and 
     \\(3).&\Swyy(\omega) &=& \mc{2}{l}{\ds \Swxx(\omega) \Fh(\omega) \Fh^\ast(-\omega)}
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{align*}
   \Swxy(\omega)
     &= \brlr{\Sxy(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\Sxx(z)\Zh^\ast(z)}_{z=e^{i\omega}}
     && \text{by \prefp{thm:Sxy}}
   \\&= \Sxx\brp{e^{i\omega}}\Zh^\ast\brp{e^{-i\omega}}
   \\&= \Swxx(\omega) \Fh^\ast(-\omega)
   \\
   \Swyy(\omega)
     &= \brlr{\Syy(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\Sxy(z)\Zh(z)}_{z=e^{i\omega}}
     && \text{by \prefp{thm:Sxy}}
   \\&= \Sxy\brp{e^{i\omega}}\Zh\brp{e^{-i\omega}}
   \\&= \Swxy(\omega) \Fh(\omega)
   \\
   \Swyy(\omega)
     &= \Swxy(\omega) \Fh(\omega)
     && \text{by previous result}
   \\&= \Swxx(\omega) \Fh^\ast(-\omega) \Fh(\omega)
     && \text{by previous result}
\end{align*}

\begin{align*}
  \Swxy(\omega)
    &\eqd \opDTFT\pE\Rxy(m)
  \\&\eqd \opDTFT\pE\brs{\rvx(0)\rvy^\ast(0+m)}
  \\&=    \opDTFT\pE\brs{\rvx(0)\brp{\sum_{k\in\Z} \fh(k)           \rvx(m-k)}^\ast}
  \\&=    \opDTFT\pE\brs{\rvx(0)     \sum_{k\in\Z} \fh^\ast(k)      \rvx^\ast(m-k)}
  \\&=    \opDTFT\pE\brs{            \sum_{k\in\Z} \fh^\ast(k)      \rvx(0)\rvx^\ast(m-k)}
  \\&=    \opDTFT                    \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(0)\rvx^\ast(m-k)}
  \\&\eqd \opDTFT                    \sum_{k\in\Z} \fh^\ast(k) \Rxx(m-k)
  \\&\eqd \opDTFT                             \brs{\fh^\ast(m) \conv \Rxx(m)}
  \\&\eqd \Fh^\ast(-\omega) \Swxx(\omega)
\end{align*}

\begin{align*}
  \Swxy(\omega)
    &\eqd \opDTFT\pE\Rxy(m)
  \\&\eqd \opDTFT\pE\brs{\rvx(m)\rvy^\ast(0)}
  \\&=    \opDTFT\pE\brs{\rvx(m-m)\rvy^\ast(0-m)}
  \\&=    \opDTFT\pE\brs{\rvx(0)\brp{\sum_{k\in\Z} \fh(k)           \rvx(-m-k)}^\ast}
  \\&=    \opDTFT\pE\brs{\rvx(0)     \sum_{k\in\Z} \fh^\ast(k)      \rvx^\ast(-m-k)}
  \\&=    \opDTFT\pE\brs{            \sum_{k\in\Z} \fh^\ast(k)      \rvx(0)\rvx^\ast(-m-k)}
  \\&=    \opDTFT                    \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(0)\rvx^\ast(-m-k)}
  \\&\eqd \opDTFT                    \sum_{k\in\Z} \fh^\ast(k) \Rxx(-m-k)
  \\&\eqd \opDTFT                             \brs{\fh^\ast(m) \conv \Rxx(-m)}
  \\&=    \opDTFT                             \brs{\fh^\ast(-n) \conv \Rxx(n)}
  \\&\eqd \Fh^\ast(\omega) \Swxx(\omega)
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:Swxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$, 
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& $\rvx$ and $\rvy$ are \prope{wide sense stationary} & and\\
    (C).& $\fh(n)$ is \prope{real-valued}
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Swxy(\omega) &=& \ds \Swxx(\omega) \Fh(\omega) & and 
     \\(2).&\Swyy(\omega) &=& \ds \Swxy(\omega) \Fh(\omega) & and 
     \\(3).&\Swyy(\omega) &=& \mc{2}{l}{\ds \Swxx(\omega) \Fh(\omega) \Fh(\omega)}
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{align*}
   \Swxy(\omega)
     &= \Swxx(\omega) \Fh^\ast(-\omega)
     && \text{by \prefp{cor:Swxy}}
   \\&= \Swxx(\omega) \Fh(\omega)
     && \text{by hypothesis (C)}
   \\
   \Swyy(\omega)
     &= \Swxy(\omega) \Fh(\omega)
     && \text{by \prefp{cor:Swxy}}
   \\
   \Swyy(\omega)
     &= \Swxx(\omega) \Fh^\ast(-\omega) \Fh(\omega)
     && \text{by \prefp{cor:Swxy}}
   \\&= \Swxx(\omega) \Fh(\omega) \Fh(\omega)
     && \text{by hypothesis (C)}
\end{align*}
\end{proof}

%---------------------------------------
\section{Whitening}
\index{whitening filter}
\label{sec:d-whiten}
%---------------------------------------
\begin{figure}[h]
  \centering
  \includegraphics{graphics/pz_minphase.pdf}
  \caption{
     Poles ($\times$) and zeros ($o$) of a \prope{minimum phase} filter
     \label{fig:w_pz_minphase}
     }
\end{figure}
%---------------------------------------
\begin{definition}
\index{minimum phase}
\index{rational expression}
%---------------------------------------
Let $\Zh(z)$ be the z-transform of the impulse response of a filter.
If $\Zh(z)$ can be expressed as a rational expression with poles and zeros
$r_ne^{i\theta_n}$,
then the filter is \textbf{minimum phase} if each $r_n<1$
(all roots lie inside the unit circle in the complex $z$-plane).
\end{definition}
See \prefp{fig:w_pz_minphase}.

Note that if $L(z)$ has a root at $z=re^{i\theta}$, then
$L^\ast(1/z^\ast)$ has a root at
\begin{eqnarray*}
   \frac{1}{z^\ast}
     &=& \frac{1}{\brp{re^{i\theta}}^\ast}
      = \frac{1}{re^{-i\theta}}
      = \frac{1}{r} e^{i\theta}.
\end{eqnarray*}
That is, if $L(z)$ has a root inside the unit circle,
then $L^\ast(1/z^\ast)$ has a root directly opposite across the unit circle
boundary (see \prefp{fig:z-roots}).
A causal stable filter $\Z\Zh(z)$ must have all of its poles inside
the unit circle.
A minimum phase filter is a filter with both its poles and zeros inside the
unit circle.
One advantage of a minimum phase filter is that its recipricol
(zeros become poles and poles become zeros)
is also causal and stable.

\begin{figure}[ht]
\begin{center}
\begin{fsL}
\setlength{\unitlength}{0.2mm}
\begin{picture}(300,300)(-130,-130)
  %\graphpaper[10](0,0)(200,200)
  \thicklines%
  \color{axis}%
    \put(-130 ,   0 ){\line(1,0){260} }%
    \put(   0 ,-130 ){\line(0,1){260} }%
    \put( 140 ,   0 ){\makebox(0,0)[l]{$\Re$}}%
    \put(   0 , 140 ){\makebox(0,0)[b]{$\Im$}}%
  \color{zero}%
    \qbezier[24](  0,  0)( 56.5,56.5)(113,113)
    %\put(   0 ,   0 ){\line(1,1){120}}%
    \put(  28 ,  28 ){\circle{10}}%
    \put( 113 , 113 ){\circle{10}}%
    \put(  38 ,  28 ){\makebox(0,0)[l]{zero of $L(z)$}}%
    \put( 123 , 113 ){\makebox(0,0)[l]{zero of $L^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{pole}%
    \qbezier[24](0,0)(-61.5,-26.5)(-123,-53)%
    %\put(   0 ,   0 ){\line(-3,-1){130}}%
    \put( -76 , -25 ){\makebox(0,0){$\times$}}%
    \put(-119 , -40 ){\makebox(0,0){$\times$}}%
    \put( -76 , -25 ){\makebox(0,0)[lt]{pole of $L(z)$}}%
    \put(-119 , -40 ){\makebox(0,0)[lt]{pole of $L^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{circle}%
    \input{../common/circle.inp}
\end{picture}
\end{fsL}
\end{center}
\caption{
   Mirrored roots in complex-z plane
   \label{fig:z-roots}
   }
\end{figure}


\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(700,100)(-100,-60)
  \thicklines
  %\graphpaper[10](0,0)(160,80)
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(m)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[b]{$\Sxx(z)$}                  }
  \put(-100,   0 ){\vector  (  1,  0){100}                           }

  \put(   0, -50 ){\framebox(100,100)   {$\conv\gamma(n)$}           }
  \put(   0, -40 ){\makebox (100, 80)[t]{whitening}                  }
  \put(   0, -40 ){\makebox (100, 80)[b]{$\Gamma(z)$}                }
  \put( 100,   0 ){\vector  (  1,  0)   {200}                        }
  \put( 100,  10 ){\makebox (200, 40)[t]{white noise process}        }
  \put( 100,  10 ){\makebox (200, 40)[b]{$\vw(n)$}                 }
  \put( 100, -50 ){\makebox (200, 40)[t]{$\Rww(m)=\delta(m)$}  }
  \put( 100, -50 ){\makebox (200, 40)[b]{$\Sww(z)=1$}                }

  \put( 300, -50 ){\framebox(100,100)   {$\conv l(n)$}               }
  \put( 300, -40 ){\makebox (100, 80)[t]{innovations}                }
  \put( 300, -40 ){\makebox (100, 80)[b]{$L(z)$}                     }
  \put( 400,   0 ){\vector  (  1,  0)   {100}                        }
  \put( 400,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put( 400, -50 ){\makebox (200, 40)[t]{$\Rxx(m)=l(m)\conv l^\ast(-m)$}  }
  \put( 400, -50 ){\makebox (200, 40)[b]{$\Sxx(z)=L(z) L^\ast\brp{\frac{1}{z^\ast}}$}  }
  \end{picture}
\caption{
   Innovations and whitening filters
   \label{fig:d-innovations}
   }
\end{center}
\end{fsK}
\end{figure}


The next theorem demonstrates a method for ``whitening"
a \fncte{random sequence} $\fx(n)$ with a filter constructed from a decomposition
of $\Rxx(m)$.
The technique is stated precisely in \prefp{thm:d-innovations}
and illustrated in \prefp{fig:d-innovations}.
Both imply two filters with impulse responses $l(n)$ and $\gamma(n)$.
Filter $l(n)$ is referred to as the \textbf{innovations filter}
(because it generates or ``innovates" $\fx(n)$ from a white noise
process $\fw(n)$)
and $\gamma(n)$ is referred to as the \textbf{whitening filter}
because it produces a white noise sequence when the input sequence
is $\fx(n)$.\footnote{\citerpp{papoulis}{401}{402}}


%---------------------------------------
\begin{theorem}
\label{thm:d-innovations}
%---------------------------------------
Let $\fx(n)$ be a WSS \fncte{random sequence} with autocorrelation $\Rxx(m)$
and spectral density $\Sxx(z)$.
\textbf{If} $\Sxx(z)$ has a \textbf{rational expression},
then the following are true:

\begin{enume}
   \item There exists a rational expression $L(z)$ with minimum phase
         such that
         \[ \Sxx(z) = L(z)L^\ast\brp{\frac{1}{z^\ast}}. \]
   \item An LTI filter for which the Laplace transform of
         the impulse response $\gamma(n)$ is
         \[ \Gamma(z) = \frac{1}{L(z)} \]
         is both causal and stable.
   \item If $\fx(n)$ is the input to the filter $\gamma(n)$,
         the output $\fy(n)$ is a \textbf{white noise sequence} such that
         \[ \Syy(z)=1 \hspace{2cm} \Ryy(m)=\kdelta(m).\]
\end{enume}
\end{theorem}


\begin{proof}
\begin{eqnarray*}
   \Sww(z)
     &=& \Gamma(z)\Gamma^\ast\brp{\frac{1}{z^\ast}} \Sxx(z)
   \\&=& \frac{1}{L(z)} \frac{1}{L^\ast\brp{\frac{1}{z^\ast}}} \Sxx(z)
   \\&=& \frac{1}{L(z)} \frac{1}{L^\ast\brp{\frac{1}{z^\ast}}}
         L(z) L^\ast\brp{\frac{1}{z^\ast}}
   \\&=& 1
\end{eqnarray*}
\end{proof}



%=======================================
\section{Beware of Estimators}
%=======================================
Estimators yield, as the name implies, estimates.
These estimates in general contain some error.

%---------------------------------------
\begin{example}[The Welch estimate of \ope{coherence} with $K=1$]
%---------------------------------------
Suppose we have two \prope{uncorrelated} stationary sequences $\rvx[n]$ and $\rvy[n]$. Then, there 
CSD $\Sxy(\omega)$ should be $0$ because
\begin{align*}
  \Sxy(\omega)
    &\eqd \opDTFT\pE\Rxy(m)
  \\&=    \opDTFT\pE\brs{x[n]y[n+m]}
  \\&=    \opDTFT\brs{\pEx[n]} \brs{\pEy[n+m]}
  \\&=    \opDTFT\brs{0} \brs{0}
  \\&=    0
\end{align*}

This will give a coherence of $0$ also:
\[ C(\omega) = \frac{\Sxy}{\sqrt{\Sxx\Syy}} = 0\]

However, the Welch estimate with $K=1$ will yield
\begin{align*}
  \abs{C(\omega)}
    &= \abs{\frac{\ds\Sxy}{\sqrt{\ds\Sxx\Syy}}}
  \\&= \abs{\frac{\ds (\opFT x)(\opFT y)^\ast}{\sqrt{\ds\abs{\opFT x}^2\abs{\opFT y}^2}}}
  \\&= 1
\end{align*}

\end{example}


