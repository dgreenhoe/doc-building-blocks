%============================================================================
% LaTeX File
% Daniel J. Greenhoe
%============================================================================
%======================================
\section{Random Sequences}
%\label{app:random_processes}
%======================================
%\qboxnps
%  {Aristotle (384 BC -- 322 BC)
%    \index{Aristotle}
%    \index{quotes!Aristotle}
%    \footnotemark
%  }
%  {../common/people/aristot.jpg}
%  {A likely impossibility is always preferable to an
%  unconvincing possibility.}
%  \footnotetext{\begin{tabular}[t]{ll}
%    quote: & \url{http://en.wikiquote.org/wiki/Aristotle} \\
%    image: & \url{http://en.wikipedia.org/wiki/Aristotle}
%  \end{tabular}}

%%=======================================
%\subsection{Definitions}
%%=======================================
%%---------------------------------------
%\begin{definition}
%\label{def:randseq}
%%---------------------------------------
%\defboxt{
%    A \fnctd{random sequence} is a \fncte{sequence} \ifsxref{seq}{def:seq} 
%  \\over a \structe{probability space} \xref{def:ps}.
%  }
%\end{definition}
%
%%---------------------------------------
%\begin{definition}
%\footnote{
%  \citerpgc{papoulis1984}{263}{0070484686}{$R_{xy}(m)=E\brb{\rvx(m)\rvy^\ast(0)}$},
%  \citerpgc{cadzow}      {341}{0023180102}{$r_{xy}(m)=E\brs{\rvx(m)\rvy^\ast(0)}$},
%  \citePc  {matlab_xcorr}                 {$R_{xy}(m)=E\setn{x_{n+m}y_n^\ast}   $},
%  \citePc  {matlab_cpsd}                  {$R_{xy}(m)=E\setn{x_{n+m}y_n^\ast}   $}
%  }
%\label{def:pmeanxn}
%\label{def:pvarxn}
%\label{def:Rxxnm}
%\label{def:Rxxnm}
%\label{def:Ryynm}
%\label{def:Rxynm}
%%---------------------------------------
%Let $\rvx(n)$ and $\rvy(n)$ be \fncte{random sequence}s.\\
%\defbox{\begin{array}{MlMlc>{\ds}l}
%     The \fnctd{mean}             & \pmeanx(n) & of $\rvx(n)$               is & \pmeanx(n)&\eqd& \pE\brs{\rvx(n)}
%   \\The \fnctd{variance}         & \pvarx(n)  & of $\rvx(n)$               is & \pvarx(n) &\eqd& \pE\brp{\brs{\rvx(n)-\pmeanx(n)}^2}
%   \\The \fnctd{cross-correlation}& \Rxy(n,m)  & of $\rvx(n)$ and $\rvy(n)$ is & \Rxy(n,m) &\eqd& \pE\brs{\rvx(n+m)\rvy^\ast(n)}
%   \\The \fnctd{auto-correlation} & \Rxx(n,m)  & of $\rvx(n)$               is & \Rxx(n,m) &\eqd& \brlr{\Rxy(n,m)}_{\rvy=\rvx}
%  %\\The \fnctd{auto-correlation operator} & \opR\ff    & of $\ff(t)$               is & \opR f    &\eqd& \int_{u\in\R}\Rxx(t,u) f(u) \du     %& \text{(\prope{auto-correlation operator})}
%\end{array}}
%\end{definition}
%
%---------------------------------------
\subsection{Properties}
%---------------------------------------
%20190430%%---------------------------------------
%20190430%\begin{theorem}
%20190430%\label{thm:Rxxnm}
%20190430%\label{thm:Ryynm}
%20190430%\label{thm:Rxynm}
%20190430%%---------------------------------------
%20190430%\thmbox{\begin{array}{rcl}
%20190430%   \Rxx(n,m) &=& \Rxx^\ast(n+m,-m)\\
%20190430%   \Rxy(n,m) &=& \Ryx^\ast(n+m,-m)
%20190430%\end{array}}
%20190430%\end{theorem}
%20190430%\begin{proof}
%20190430%\begin{align*}
%20190430%  \Rxy(n,m)
%20190430%     &\eqd \pE\brs{\rvx(n+m) \rvy^\ast(n)}
%20190430%     && \text{by definition of $\Rxy(n,m)$}
%20190430%     && \text{\xref{def:Rxynm}}
%20190430%   \\&= \pE\brs{\rvy^\ast(n) \rvx(n+m)}
%20190430%     && \text{by \prope{commutative} property of $\fieldC$}
%20190430%     && \text{\ifxref{algebra}{def:field}}
%20190430%   \\&= \brp{\pE\brs{\rvy(n) \rvx^\ast(n+m)}}^\ast
%20190430%     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
%20190430%     && \text{\xref{def:staralg}}
%20190430%   \\&= \brp{\pE\brs{\rvy(n+m-m) \rvx^\ast(n+m)}}^\ast
%20190430%     && \text{by \prope{additive identity} property of $\fieldR$}
%20190430%     && \text{\ifxref{algebra}{def:field}}
%20190430%   \\&\eqd \Ryx^\ast(n+m,-m)
%20190430%     && \text{by definition of $\Rxy(n,m)$}
%20190430%     && \text{\xref{def:Rxynm}}
%20190430%   \\
%20190430%   \\
%20190430%   \Rxx(n,m)
%20190430%     &= \brlr{\Rxy(n,m)}_{\rvy=\rvx}
%20190430%     && \text{by $\rvy=\rvx$ constraint}
%20190430%   \\&= \brlr{\Rxy^\ast(n+m,-m)}_{\rvy=\rvx}
%20190430%     && \text{by previous result}
%20190430%   \\&= \Rxx^\ast(n+m,-m)
%20190430%     && \text{by $\rvy=\rvx$ constraint}
%20190430%\end{align*}
%20190430%\end{proof}

%%---------------------------------------
%\subsection{Wide Sense Stationary processes}
%\index{wide sense stationary}
%\index{WSS}
%%---------------------------------------
%%---------------------------------------
%\begin{definition}
%\label{def:wss}
%%---------------------------------------
%\defboxt{
%  A random process $\rvx(n)$ is \propd{wide sense stationary} (\propd{WSS}) if
%  \\\indentx$\begin{array}{FlMMD}
%   (1).& \pmeanx(t)     & is \prope{constant} with respect to $t$ & (\prope{stationary in the mean})    & and \\
%   (2).& \Rxx(t+\tau,t) & is \prope{constant} with respect to $t$ & (\prope{stationary in correlation})
%  \end{array}$
%  }
%\end{definition}

%%---------------------------------------
%\begin{definition}
%%---------------------------------------
%Let $\rvx(n)$ be a \fncte{random sequence} with \fncte{mean} $\pmeanx(n)$ and
%\fncte{variance} $\pvar(n)$ \xref{def:pvarxn}.
%\\
%\defboxt{
%  $\rvx(n)$ is \propd{wide sense stationary} (\propd{WSS}) if
%  \\\indentx
%    $\begin{array}{FlMMD}
%       1. & \pmeanx(n)  & is \prope{constant} with respect to $n$ & (\prope{stationary in the 1st moment})    & and\\
%       2. & \pvarx(n)   & is \prope{constant} with respect to $n$ & (\prope{stationary in the 2nd moment})
%    \end{array}$
%  }
%\end{definition}
%
%%---------------------------------------
%\begin{definition}
%\footnote{
%  \citerpgc{papoulis1984}{263}{0070484686}{``$R_{xy}(\tau)=E\brb{\rvx(t+\tau)\rvy^\ast(t)}$"},
%  %\citerpgc{kay1988}{52}{8131733564}{``$r_{xy}[k] = \mathcal{E}\brb{x^\ast[n]y[n+k]}\quad(3.42)"$},
%  %\citerpgc{bendat2011}{111}{1118210824}{$R_{xy}(\tau)=E\brs{\rvx(t)\rvy(t+\tau)}$},
%  \citerpgc{cadzow}{341}{0023180102}{$r_{xy}(n)=E\brs{\rvx(k+n)\rvy^\ast(k)}$ (10.41)}
%  %\citerpgc{koopmans1995}{}{{0124192513}{}
%  %\citerpgc{weisstein2002}{594}{1420035223}{entry: Cross-Correlation; $f\star g=\int_{-\infty}^{\infty}\bar{f}(\tau)g(t+\tau)\dtau$ (4)},
%  %\citerpgc{bracewell1965}{46,243}{???}{cited by other reference} % https://books.google.com/books?id=oVFTDwAAQBAJ&pg=PA92&dq=bracewell+%22pentagram+notation%22&hl=en&sa=X&ved=0ahUKEwigptTEq-DeAhXIi60KHd1RCJIQ6AEILjAB#v=onepage&q=bracewell%20%22pentagram%20notation%22&f=false
%  }
%\label{def:mean_wss}
%\label{def:Rxxm}
%\label{def:Rxym}
%%---------------------------------------
%Let $\rvx(n)$ be a \fncte{random sequence} with statistics
%$\pmeanx(n)$, $\pvarx(n)$, $\Rxx(n,m)$, and $\Rxy(n,m)$ \xref{def:Rxynm}.
%\defboxt{
%  $\brb{\begin{array}{M}
%    $\rvx$ and $\rvy$ are
%    \prope{wide sense stationary}
%  \end{array}}\quad\implies$
%  \\\quad$
%  \brb{\begin{array}{FMlMlc>{\ds}l}
%     (1).&The \fnctd{mean}              & \pmeanx  & of $\rvx(n)$               is & \pmeanx &\eqd& \pE\brs{\rvx(0)}
%   \\(2).&The \fnctd{variance}          & \pvarx   & of $\rvx(n)$               is & \pvarx  &\eqd& \pE\brp{\brs{\rvx(0)-\pmeanx}^2}
%   \\(4).&The \fnctd{cross-correlation} & \Rxy(m)  & of $\rvx(n)$ and $\rvy(n)$ is & \Rxy(m) &\eqd& \pE\brs{\rvx(m)\rvy^\ast(0)}
%   \\(3).&The \fnctd{auto-correlation}  & \Rxx(m)  & of $\rvx(n)$               is & \Rxx(m) &\eqd& \brlr{\Rxy(m)}_{\rvy=\rvx}
%  %\\The \fnctd{auto-correlation operator} & \opR\ff    & of $\ff(t)$               is & \opR f    &\eqd& \int_{u\in\R}\Rxx(t,u) f(u) \du     %& \text{(\prope{auto-correlation operator})}
%\end{array}}$
%  }
%\end{definition}
%
%%---------------------------------------
%\begin{remark}
%%---------------------------------------
%  The $\Rxy(n,m)$ of \prefpp{def:Rxynm} and the $\Rxy(m)$ of \prefpp{def:Rxym} (etc.) are examples
%  of \hie{function overload}---that is, functions that use the same
%  mnemonic but are distinguished by different domains.
%  Perhaps a more common example of function overload is the ``$+$" mnemonic.
%  Traditionally it is used with domain of the natural numbers $\N$ as in $3+2$.
%  Later it was extended for domain real numbers $\R$ as in $\sqrt{3}+\sqrt{2}$,
%  or even complex numbers $\C$ as in $\brp{\sqrt{3}+i\sqrt{2}}+\brp{e+i\pi}$.
%  And it was even more dramatically extended for use with domain $\R^\xN\times\R^\xM$
%  in ``linear algebra" as in
%  \\\indentx$
%    \brs{\begin{array}{cc}1&2\\3&4\end{array}} +
%    \brs{\begin{array}{cc}5&6\\7&8\end{array}} =
%    \brs{\begin{array}{cc}6&8\\10&12\end{array}}
%   $
%\end{remark}
%20190502%
%20190502%%---------------------------------------
%20190502%\begin{proposition}
%20190502%\label{prop:Rxynmm}
%20190502%\label{prop:Rxxnmm}
%20190502%%---------------------------------------
%20190502%Let $\rvy(n)$ be a \fncte{random sequence},
%20190502%    $\rvx(n)$    a \fncte{random sequence} with \fncte{auto-correlation} $\Rxx(n,m)$,
%20190502%and $\Rxy$    the \fncte{cross-correlation} of $\rvx$ and $\rvy$.
%20190502%\propbox{
%20190502%  \brb{\begin{array}{M}
%20190502%    $\rvx$ and $\rvy$ are
%20190502%    \\\prope{wide sense stationary}
%20190502%    \\(\prope{WSS}) \xref{def:wss}
%20190502%  \end{array}}
%20190502%  \implies
%20190502%  \brb{\begin{array}{rcll}
%20190502%    \Rxx(n,m) &=& \Rxx(m) & \forall n\in\Z\\
%20190502%    \Rxy(n,m) &=& \Rxy(m) & \forall n\in\Z\\
%20190502%    \text{\xref{def:Rxynm}} && \text{\xref{def:Rxym}}
%20190502%  \end{array}}
%20190502%}
%20190502%\end{proposition}
%20190502%\begin{proof}
%20190502%\begin{align*}
%20190502%  \Rxy(n,m)
%20190502%     &\eqd \pE\brs{\rvx[n+m]\rvy^\ast[n]}
%20190502%     &&    \text{by definition of $\Rxy(n,m)$}
%20190502%     &&    \text{\xref{def:Rxynm}}
%20190502%   \\&=    \pE\brs{\rvx[n-n+m]\rvy^\ast[n-n]}
%20190502%     &&    \text{by \prope{wide sense stationary} hypothesis}
%20190502%   \\&=    \pE\brs{\rvx[m]\rvy^\ast[0]}
%20190502%   \\&\eqd \Rxy(m)
%20190502%     && \text{by definition of $\Rxy(m)$}
%20190502%     && \text{\xref{def:Rxym}}
%20190502%   \\
%20190502%  \Rxx(n,m)
%20190502%     &=    \brlr{\Rxy(n,m)}_{\rvy=\rvx}
%20190502%   \\&=    \brlr{\Rxy(m)}_{\rvy=\rvx}
%20190502%     && \text{by previous result}
%20190502%   \\&= \Rxx(m)
%20190502%\end{align*}
%20190502%\end{proof}
%20190502%
%20190502%
%20190502%\begin{figure}[ht]\color{figcolor}
%20190502%\centering%
%20190502%\setlength{\unitlength}{0.08mm}
%20190502%\begin{tabular}{*{3}{c@{\hspace{1cm}}}c}
%20190502%$\Real{\Rxx(m)}$ & $\Imag{\Rxx(m)}$ & $|\Rxx(m)|$ & $\angle\Rxx(m)$
%20190502%\\
%20190502%\begin{picture}(340,300)(-150,-150)
%20190502%  %\graphpaper[10](0,0)(600,200)
%20190502%  \thicklines%
%20190502%  \color{figcolor}%
%20190502%  \put(-150,   0){\line(1,0){300} }
%20190502%  \put(   0,-150){\line(0,1){300} }
%20190502%  \put( 160,   0){\makebox(0,0)[l]{$f$} }
%20190502%  \put(-100,   0){\line( 1,1){100} }
%20190502%  \put( 100,   0){\line(-1,1){100} }
%20190502%\end{picture}
%20190502%&
%20190502%\begin{picture}(340,300)(-150,-150)
%20190502%  \thicklines%
%20190502%  \color{figcolor}%
%20190502%  \put(-150,   0){\line(1,0){300} }
%20190502%  \put(   0,-150){\line(0,1){300} }
%20190502%  \put( 160,   0){\makebox(0,0)[l]{$f$} }
%20190502%  \qbezier(0,0)( 20, 80)( 100, 100)
%20190502%  \qbezier(0,0)(-20,-80)(-100,-100)
%20190502%  \put( 100,   0){\line(0, 1){100} }
%20190502%  \put(-100,   0){\line(0,-1){100} }
%20190502%\end{picture}
%20190502%&
%20190502%\begin{picture}(340,300)(-150,-150)
%20190502%  \thicklines%
%20190502%  \color{figcolor}%
%20190502%  \put(-150,   0){\line(1,0){300} }
%20190502%  \put(   0,-150){\line(0,1){300} }
%20190502%  \put( 160,   0){\makebox(0,0)[l]{$f$} }
%20190502%  \qbezier(0,100)( 20,20)( 100, 0)
%20190502%  \qbezier(0,100)(-20,20)(-100, 0)
%20190502%\end{picture}
%20190502%&
%20190502%\begin{picture}(340,300)(-150,-150)
%20190502%  \thicklines%
%20190502%  \color{figcolor}%
%20190502%  \put(-150,   0){\line(1,0){300} }
%20190502%  \put(   0,-150){\line(0,1){300} }
%20190502%  \put( 160,   0){\makebox(0,0)[l]{$f$} }
%20190502%  \put( 100,   0){\line(0, 1){100} }
%20190502%  \put(-100,   0){\line(0,-1){100} }
%20190502%  \put(-100,-100){\line(1, 1){200} }
%20190502%\end{picture}
%20190502%\\
%20190502%(\prope{symmetric}) & (\prope{anti-symmetric}) & (\prope{symmetric}) & (\prope{anti-symmetric})
%20190502%\end{tabular}
%20190502%\caption{
%20190502%   \fncte{auto-correlation} $\Rxx(m)$
%20190502%   \label{fig:Rxxm}
%20190502%   }
%20190502%\end{figure}
%20190502%
%20190502%%---------------------------------------
%20190502%\begin{corollary}
%20190502%\label{cor:Rxxm}
%20190502%\label{cor:Rxym}
%20190502%%---------------------------------------
%20190502%Let $\rvx(n)$ be a \fncte{random sequence} with \fncte{auto-correlation} $\Rxx(n,m)$,
%20190502%    $\rvy(n)$    a \fncte{random sequence} with \fncte{auto-correlation} $\Ryy(n,m)$,
%20190502%and $\Rxy(n,m)$  the \fncte{cross-correlation} of $\rvx$ and $\rvy$.
%20190502%Let $\opS$ be a \structe{system} with input $\rvx(n)$ and output $\rvy(n)$.
%20190502%\corbox{
%20190502%  \brb{\begin{array}{FMD}
%20190502%      (A).&$\rvx$ is \prope{WSS} & and
%20190502%    \\(B).&$\rvy$ is \prope{WSS} & and
%20190502%    \\(C).&$\opS$ is \prope{LTI} &
%20190502%  \end{array}}
%20190502%  \implies
%20190502%  \brb{\begin{array}{Frc>{\ds}lDD}
%20190502%      (1).&      \Rxy(m) &=&       \Ryx^\ast(-m)  &                               & and
%20190502%    \\(2).&      \Rxx(m) &=&       \Rxx^\ast(-m)  & (\prope{conjugate symmetric}) & and
%20190502%    \\(3).&\Real \Rxx(m) &=& \Real \Rxx     (-m)  & (\prope{symmetric})           & and
%20190502%    \\(4).&\Imag \Rxx(m) &=&-\Imag \Rxx     (-m)  & (\prope{anti-symmetric})      & and
%20190502%    \\(5).&\abs{ \Rxx(m)}&=& \abs{ \Rxx     (-m)} & (\prope{symmetric})           & and
%20190502%    \\(6).&\angle\Rxx(m) &=&-\angle\Rxx     (-m)  & (\prope{anti-symmetric})      &
%20190502%  \end{array}}
%20190502%}
%20190502%\end{corollary}
%20190502%\begin{proof}
%20190502%\begin{align*}
%20190502%  \Rxy(m)
%20190502%     &= \Rxy(n,m)
%20190502%     && \text{by \prefp{prop:Rxynmm}}
%20190502%     && \text{and hypotheses (A),(B)}
%20190502%   \\&= \Ryx^\ast(n+m,-m)
%20190502%     && \text{by \prefp{thm:Rxynm}}
%20190502%     && \text{and hypothesis (B)}
%20190502%   \\&= \Ryx^\ast(-m)
%20190502%     && \text{by \prefp{prop:Rxynmm}}
%20190502%     && \text{and hypothesis (A)}
%20190502%   \\
%20190502%  \Rxx(m)
%20190502%     &= \Rxx(n,m)
%20190502%     && \text{by \prefp{prop:Rxynmm}}
%20190502%     && \text{and hypothesis (A)}
%20190502%   \\&= \Rxx^\ast(n+m,-m)
%20190502%     && \text{by \prefp{thm:Rxynm}}
%20190502%     && \text{and hypothesis (B)}
%20190502%   \\&= \Rxx^\ast(-m)
%20190502%     && \text{by \prefp{prop:Rxynmm}}
%20190502%     && \text{and hypothesis (A)}
%20190502%\end{align*}
%20190502%\end{proof}

%%=======================================
%\subsection{Spectral density}
%%=======================================
%%---------------------------------------
%\begin{definition}
%\label{def:Szxx}
%\label{def:Szxy}
%%---------------------------------------
%Let $\rvx(n)$ and $\rvy(n)$ be \prope{wide sense stationary} \fncte{random sequence}s
%with auto-correlation $\Rxx(m)$ and cross-correlation $\Rxy(m)$.
%Let $\opZ$ be the \ope{Z-transform operator}\ifsxref{dsp}{def:opZ}.
%\\
%\defbox{\begin{array}{MMrcl}
%   The \opd{z-domain cross spectral density} & (\opd{CSD}) $\ZSxy(z)$ of $\vx$ and $\vy$ is 
%     \\\mc{5}{l}{\ds\Szxy(z) \eqd \opZ{\Rxy(m)} \eqd \sum_{m\in\Z} \Rxy(m) z^{-m}}
%     \\
%   The \opd{z-domain power spectral density} & (\opd{PSD}) $\ZSxx(z)$ of $\vx$ is & \Szxx(z) &\eqd& \brlr{\Szxy(z)}_{\rvy(n)=\rvx(n)}
%\end{array}}
%\end{definition}
%
%%---------------------------------------
%\begin{definition}
%\label{def:psd}
%\label{def:csd}
%\label{def:Swxx}
%\label{def:Swxy}
%%---------------------------------------
%Let $\rvx(n)$ and $\rvy(n)$ be \prope{wide sense stationary} \fncte{random sequence}s
%with auto-correlation $\Rxx(m)$ and cross-correlation $\Rxy(m)$.
%Let $\opDTFT$ be the \ope{Discrete Time Fourier Transform} (\ope{DTFT}) operator\ifsxref{dtft}{def:dtft}.
%\\
%\defbox{\begin{array}{M rclcl}
%  The \opd{auto-spectral density}
%  \\$\ZSxx(z)$ of $\vx$ is           & \Swxx(z) &\eqd& \opDTFT{\Rxx(m)} &\eqd& \ds \sum_{m\in\Z} \Rxx(m) e^{-i\omega m}
%  \\The \opd{cross spectral density}
%  \\(\opd{CSD}) $\ZSxy(z)$ of $\vx$ and $\vy$ is & \Swxy(z) &\eqd& \opDTFT{\Rxy(m)} &\eqd& \ds \sum_{m\in\Z} \Rxy(m) e^{-i\omega m}
%  \\\mc{6}{M}{The \opd{auto-spectral density} is also called \opd{power spectral density} (\opd{PSD}).}
%\end{array}}
%\end{definition}
%
%---------------------------------------
\begin{theorem}
\label{thm:ZSxy_sym}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\thmbox{
  \brb{\begin{array}{MD}
    \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{F>{\ds}rc>{\ds}lD}
       (1).&\Szxx(z) &=& \Szxx^\ast\brp{\frac{1}{z^\ast}}             & and
     \\(2).&\Szyx(z) &=& \Szxy^\ast\brp{\frac{1}{z^\ast}}             &
  \end{array}}
  }
\end{theorem}
\begin{proof}
\begin{align*}
  \ZSyx(z)
     &\eqd \opZ \Ryx(m)
    && \text{by definition of $\ZSxy(z)$}
    && \text{\xref{def:csd}}
  \\&\eqd \sum_{m\in\Z}\Ryx(m) z^{-m}
    && \text{by definition of $\opZ$}
    && \text{\xref{def:opZ}}
  \\&\eqd \sum_{m\in\Z} \Rxy^\ast(-m) z^{-m}
    && \text{by \prefp{cor:Rxym}}
  \\&= \brs{\sum_{m\in\Z} \Rxy(-m) (z^\ast)^{-m}}^\ast
  \\&= \brs{\sum_{-p\in\Z} \Rxy(p) (z^\ast)^{p}}^\ast
    && \text{where $p\eqd -m$}
    && \text{$\implies$ $m=-p$}
  \\&= \brs{\sum_{p\in\Z} \Rxy(p) (z^\ast)^{p}}^\ast
    && \text{by \prope{absolutely summable} property}
    && \text{\xref{def:spllR}}
  \\&= \brs{\sum_{p\in\Z} \Rxy(p) \brp{\frac{1}{z^\ast}}^{-p}}^\ast
  \\&= \ZSxy^\ast\brp{\frac{1}{z^\ast}}
    && \text{by definition of $\opZ$}
    && \text{\xref{def:opZ}}
  \\
  \ZSxx(z)
    &= \brlr{\ZSxy(z)}_{\rvy=\rvx}
  \\&= \brlr{\ZSyx^\ast(z)}_{\rvy=\rvx}
  \\&= \brlr{\ZSxy^\ast\brp{\frac{1}{z^\ast}}}_{\rvy=\rvx}
    && \text{by (2)---previous result}
  \\&= \ZSxx^\ast\brp{\frac{1}{z^\ast}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:Swxy_sym}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{LTI} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{WSS}}
  \end{array}}
  \implies
  \brb{\begin{array}{F>{\ds}rc>{\ds}lDD}
       (1).&\Swxy^\ast(\omega) &=& \ds \Swyx(\omega)          & (\prope{conjugate-symmetric}) & and
     \\(2).&\Swxx^\ast(\omega) &=& \ds \Swxx(\omega)          & (\prope{conjugate symmetric}) & and
     \\(3).&\Swxx(\omega)      &\in& \R                       & (\prope{real-valued})         &
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{align*}
   \Swxy^\ast(\omega)
     &= \brlr{\ZSxy^\ast(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\ZSyx^{\ast\ast}\brp{\frac{1}{z^\ast}}}_{z=e^{i\omega}}
     && \text{by \prefp{thm:ZSxy_sym}}
   \\&= \brlr{\ZSyx\brp{\frac{1}{z^\ast}}}_{z=e^{i\omega}}
     && \text{by \prope{involutory} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&= \ZSyx\brp{\frac{1}{e^{i\omega\ast}}}
   \\&= \ZSyx\brp{e^{i\omega}}
   \\&= \Swyx\brp{\omega}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\
   \Swxx^\ast(\omega)
     &= \brlr{\ZSxx^\ast(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\ZSxx^{\ast\ast}\brp{\frac{1}{z^\ast}}}_{z=e^{i\omega}}
     && \text{by \prefp{thm:ZSxy_sym}}
   \\&= \brlr{\ZSxx\brp{\frac{1}{z^\ast}}}_{z=e^{i\omega}}
     && \text{by \prope{involutory} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&= \ZSxx\brp{\frac{1}{e^{i\omega\ast}}}
   \\&= \ZSxx\brp{e^{i\omega}}
   \\&= \Swxx\brp{\omega}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&\implies\text{$\Swxx(\omega)$ is \prope{real-valued}}
   \\
   \Swxx^\ast(\omega)
     &= \brlr{\Swxy^\ast(\omega)}_{\rvy=\rvx}
   \\&= \brlr{\Swyx(\omega)}_{\rvy=\rvx}
     && \text{by previous result}
   \\&= \Swxx(\omega)
\end{align*}
\end{proof}


%%=======================================
%\subsection{Spectral Power}
%%=======================================
%The term ``\fncte{spectral power}" is a bit of an oxymoron because ``spectral" 
%deals with leaving the time-domain for the frequency-domain, howbeit 
%the concept of power is solidly founded on the concept of time in that power = energy per time.
%
%However, \prope{Parseval's Theorem} \xref{prop:parseval_reconstruction}
%demonstrates that power in time can also be calculated in frequency.
%So, it makes some sense to speak of the term ``spectral power". 
%Moreover, one way to estimate this power is to average the 
%Fourier Transforms of the product $\abs{\rvx(n)}^2=\rvx(n)\rvx^\ast(n)$\ldots that is, to use an estimate of 
%the auto-spectral density $\Swxx(\omega)$.
%Thus, an alternate name for \fncte{auto-spectral density} is \fnctb{power spectral density} (PSD).

