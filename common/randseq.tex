%============================================================================
% LaTeX File
% Daniel J. Greenhoe
%============================================================================

%======================================
\chapter{Random Sequences}
\label{app:random_processes}
%======================================
\qboxnps
  {Aristotle (384 BC -- 322 BC)
    \index{Aristotle}
    \index{quotes!Aristotle}
    \footnotemark
  }
  {../common/people/aristot.jpg}
  {A likely impossibility is always preferable to an
  unconvincing possibility.}
  \footnotetext{\begin{tabular}[t]{ll}
    quote: & \url{http://en.wikiquote.org/wiki/Aristotle} \\
    image: & \url{http://en.wikipedia.org/wiki/Aristotle}
  \end{tabular}}

%=======================================
%\section{Random sequences}
%=======================================
%---------------------------------------
\section{Definitions}
%---------------------------------------
%---------------------------------------
\begin{definition}
\footnote{
  \citerpgc{papoulis1984}{263}{0070484686}{$R_{xy}(m)=E\brb{\rvx(m)\rvy^\ast(0)}$},
  \citerpgc{cadzow}      {341}{0023180102}{$r_{xy}(m)=E\brs{\rvx(m)\rvy^\ast(0)}$},
  \citePc  {matlab_xcorr}                 {$R_{xy}(m)=E\setn{x_{n+m}y_n^\ast}   $},
  \citePc  {matlab_cpsd}                  {$R_{xy}(m)=E\setn{x_{n+m}y_n^\ast}   $}
  }
\label{def:pmeanxn}
\label{def:pvarxn}
\label{def:Rxxnm}
\label{def:Rxxnm}
\label{def:Ryynm}
\label{def:Rxynm}
%---------------------------------------
Let $\rvx(n)$ and $\rvy(n)$ be \fncte{random sequence}s.\\
\defbox{\begin{array}{MlMlc>{\ds}l}
     The \fnctd{mean}             & \pmeanx(n) & of $\rvx(n)$               is & \pmeanx(n)&\eqd& \pE\brs{\rvx(n)}
   \\The \fnctd{variance}         & \pvarx(n)  & of $\rvx(n)$               is & \pvarx(n) &\eqd& \pE\brp{\brs{\rvx(n)-\pmeanx(n)}^2}
   \\The \fnctd{crosscorrelation} & \Rxy(n,m)  & of $\rvx(n)$ and $\rvy(n)$ is & \Rxy(n,m) &\eqd& \pE\brs{\rvx(n+m)\rvy^\ast(n)}
   \\The \fnctd{autocorrelation}  & \Rxx(n,m)  & of $\rvx(n)$               is & \Rxx(n,m) &\eqd& \brlr{\Rxy(n,m)}_{\rvy=\rvx}
  %\\The \fnctd{autocorrelation operator} & \opR\ff    & of $\ff(t)$               is & \opR f    &\eqd& \int_{u\in\R}\Rxx(t,u) f(u) \du     %& \text{(\prope{auto-correlation operator})}
\end{array}}
\end{definition}

%---------------------------------------
\section{Properties}
%---------------------------------------
%---------------------------------------
\begin{theorem}
\label{thm:Rxxnm}
\label{thm:Ryynm}
\label{thm:Rxynm}
%---------------------------------------
\thmbox{\begin{array}{rcl}
   \Rxx(n,m) &=& \Rxx^\ast(n+m,-m)\\
   \Rxy(n,m) &=& \Ryx^\ast(n+m,-m)
\end{array}}
\end{theorem}
\begin{proof}
\begin{align*}
  \Rxy(n,m)
     &\eqd \pE\brs{\rvx(n+m) \rvy^\ast(n)}
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvy^\ast(n) \rvx(n+m)}
     && \text{by \prope{commutative} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&= \brp{\pE\brs{\rvy(n) \rvx^\ast(n+m)}}^\ast
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&= \brp{\pE\brs{\rvy(n+m-m) \rvx^\ast(n+m)}}^\ast
     && \text{by \prope{additive identity} property of $\fieldR$}
     && \text{\ifxref{algebra}{def:field}}
   \\&\eqd \Ryx^\ast(n+m,-m)
     && \text{by definition of $\Rxy$}
     && \text{\xref{def:Rxy}}
   \\
   \\
   \Rxx(n,m)
     &= \brlr{\Rxy(n,m)}_{y=x}
   \\&= \brlr{\Rxy^\ast(n+m,-m)}_{y=x}
     && \text{by previous result}
   \\&= \Rxx^\ast(n+m,-m)
\end{align*}
\end{proof}

\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(300,130)(-100,-80)
  \thicklines
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(n,m)$}  }
  \put(-100,   0 ){\vector  (  1,  0){100}             }
  \put(   0, -50 ){\framebox(100,100){$\conv\fh(n)$}  }
  \put( 100,   0 ){\vector  (  1,  0){100}             }
  \put( 110,   0 ){\makebox (100, 40)[lb]{$\ds\rvy(n)=\fh(n)\conv\rvx(n)=\sum_k\fh(k)\rvx(n-k)$}  }
  \put( 100, -50 ){\makebox (100, 40)[t]{$\Ryy(n,m)$}  }
  \put(  50, -60 ){\makebox (  0,  0)[t]{$\Rxy(n,m)$}  }
  \end{picture}
\caption{
   Linear system with \fncte{random sequence} input and output
   \label{fig:d-linear-sys}
   }
\end{center}
\end{fsK}
\end{figure}

The next theorem describes the statistical properties of an LTI system
with impulse response $\fh(t)$ \xref{fig:d-linear-sys}.
\newpage
%---------------------------------------
\begin{theorem}
\footnote{
  \citerp{papoulis}{310}
  }
\label{thm:Rxyh}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\thmboxt{
  $\brb{\begin{array}{M}
    $\opS$ is \prope{linear time invariant} (\prope{LTI})
  \end{array}}
  \quad\implies$
  \\\qquad$
  \brb{\begin{array}{Frc>{\ds}lc>{\ds}lD}
       (A).&\Rxy(n,m) &=& \Rxx(n,m)\conv \fh^\ast(m) &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxx(n,m-k) & and
     \\(B).&\Ryy(n,m) &=& \Rxy(n,m)\conv \fh(m)      &\eqd& \sum_{k\in\Z} \fh(k)      \Rxy(n,m-k) & and
     \\(C).&\Ryy(n,m) &=& \Rxx(n,m)\conv \fh(m)\conv h^\ast(m)
                      &\eqd& \mc{2}{l}{\ds\sum_{p\in\Z} \sum_{k\in\Z} \fh(k)h^\ast(p) \Rxx(n,m-p-k)}
  \end{array}}$
  }
\end{theorem}

\begin{proof}
\begin{align*}
   \Rxy(n,m)
     &\eqd \pE\brs{\rvx(n+m) \rvy^\ast(n) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvx(n+m) \brp{\fh\conv\rvx}^\ast(n)}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvx(n+m) \brp{ \sum_{k\in\Z} h(k) \rvx(n-k) }^\ast }
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvx(n+m) \sum_{k\in\Z} \fh^\ast(k) \rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvx(n+m)\rvx^\ast(n-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&= \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(n-k+k+m) \rvx^\ast(n-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(n-k,m+k)
     && \text{by definition of $\Rxx(n,m)$}
     && \text{\xref{def:Rxxnm}}
   \\&= \Rxx(n-k,m) \conv \fh^\ast(-m)
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Ryy(n,m)
     &\eqd \pE\brs{\rvy(n+m) \rvy^\ast(n) }
     && \text{by definition of $\Rxy(n,m)$}
     && \text{\xref{def:Rxynm}}
   \\&= \pE\brs{\rvy(n+m) \brp{\fh\conv\rvy}^\ast(n)}
     && \text{by \prope{LTI} hypothesis}
   \\&\eqd \pE\brs{\rvy(n+m) \brp{ \sum_{k\in\Z} h(k) \rvy(n-k) }^\ast }
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&=    \pE\brs{\rvy(n+m) \sum_{k\in\Z} \fh^\ast(k) \rvy^\ast(n-k)  }
     && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
     && \text{\xref{def:staralg}}
   \\&=    \pE\brs{ \sum_{k\in\Z} \fh^\ast(k) \rvy(n+m)\rvy^\ast(n-k)  }
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\ifxref{algebra}{def:field}}
   \\&=    \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvy(n-k+k+m) \rvy^\ast(n-k) }
     && \text{by \prope{linear} property of $\pE$}
     && \text{\xref{thm:pE}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Ryy(n-k,m+k)
     && \text{by definition of $\Ryy(n,m)$}
     && \text{\xref{def:Ryynm}}
   \\&\eqd \Ryy(n-k,m) \conv \fh^\ast(-m)
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\
   \\
   \Ryy(n,m)
     &= \Rxy(n,m)\conv \fh(m)
     && \text{by previous result}
   \\&= \brs{\Rxx(n,m) \conv \fh^\ast(-m)}\conv \fh(-m)
     && \text{by previous result}
   \\&= \Rxx(n,m) \conv \fh(-m) \conv \fh^\ast(-m)
     && \text{by previous result}
\\
\\
   \Ryy(n,m)
     &= \Rxx(n,m)\conv\fh(-m) \conv \fh^\ast(-m)
     && \text{by previous result}
   \\&\eqd \sum_{p\in\Z}\fh^\ast(-p) \brs{\Rxx(n,m-p)\conv\fh(-m)}
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&= \sum_{p\in\Z}\fh^\ast(-p) \sum_{k\in\Z}\fh(-k) \Rxx(n,m-p-k)
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
   \\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(-k) \fh^\ast(-p) \Rxx(n,m-p-k)
     && \text{by \prope{distributive} property of $\fieldC$}
     && \text{\xref{def:field}}
\end{align*}
\end{proof}


%---------------------------------------
\section{Wide Sense Stationary processes}
\index{wide sense stationary}
\index{WSS}
%---------------------------------------
%---------------------------------------
\begin{definition}
%---------------------------------------
Let $\rvx(n)$ be a \fncte{random sequence} with \fncte{mean} $\pmeanx(n)$ and
\fncte{variance} $\pvar(n)$ \xref{def:pvarxn}.
\\
\defboxt{
  $\rvx(n)$ is \propd{wide sense stationary} (\propd{WSS}) if
  \\\indentx
    $\begin{array}{FlMMD}
       1. & \pmeanx(n)  & is \prope{constant} with respect to $n$ & (\prope{stationary in the 1st moment})    & and\\
       2. & \pvarx(n)   & is \prope{constant} with respect to $n$ & (\prope{stationary in the 2nd moment})
    \end{array}$
  }
\end{definition}

%---------------------------------------
\begin{definition}
\footnote{
  \citerpgc{papoulis1984}{263}{0070484686}{``$R_{xy}(\tau)=E\brb{\rvx(t+\tau)\rvy^\ast(t)}$"},
  %\citerpgc{kay1988}{52}{8131733564}{``$r_{xy}[k] = \mathcal{E}\brb{x^\ast[n]y[n+k]}\quad(3.42)"$},
  %\citerpgc{bendat2011}{111}{1118210824}{$R_{xy}(\tau)=E\brs{\rvx(t)\rvy(t+\tau)}$},
  \citerpgc{cadzow}{341}{0023180102}{$r_{xy}(n)=E\brs{\rvx(k+n)\rvy^\ast(k)}$ (10.41)}
  %\citerpgc{koopmans1995}{}{{0124192513}{}
  %\citerpgc{weisstein2002}{594}{1420035223}{entry: Cross-Correlation; $f\star g=\int_{-\infty}^{\infty}\bar{f}(\tau)g(t+\tau)\dtau$ (4)},
  %\citerpgc{bracewell1965}{46,243}{???}{cited by other reference} % https://books.google.com/books?id=oVFTDwAAQBAJ&pg=PA92&dq=bracewell+%22pentagram+notation%22&hl=en&sa=X&ved=0ahUKEwigptTEq-DeAhXIi60KHd1RCJIQ6AEILjAB#v=onepage&q=bracewell%20%22pentagram%20notation%22&f=false
  }
\label{def:mean_wss}
\label{def:Rxxm}
\label{def:Rxym}
%---------------------------------------
Let $\rvx(n)$ be a \fncte{random sequence} with statistics
$\pmeanx(n)$, $\pvarx(n)$, $\Rxx(n,m)$, and $\Rxy(n,m)$ \xref{def:Rxynm}.
\defboxt{
  $\brb{\begin{array}{M}
    $\rvx$ and $\rvy$ are
    \prope{wide sense stationary}
  \end{array}}\quad\implies$
  \\\quad$
  \brb{\begin{array}{FMlMlc>{\ds}l}
     (1).&The \fnctd{mean}             & \pmeanx  & of $\rvx(n)$               is & \pmeanx &\eqd& \pE\brs{\rvx(0)}
   \\(2).&The \fnctd{variance}         & \pvarx   & of $\rvx(n)$               is & \pvarx  &\eqd& \pE\brp{\brs{\rvx(0)-\pmeanx}^2}
   \\(4).&The \fnctd{crosscorrelation} & \Rxy(m)  & of $\rvx(n)$ and $\rvy(n)$ is & \Rxy(m) &\eqd& \pE\brs{\rvx(n+m)\rvy^\ast(0)}
   \\(3).&The \fnctd{autocorrelation}  & \Rxx(m)  & of $\rvx(n)$               is & \Rxx(m) &\eqd& \brlr{\Rxx(m)}_{\rvy=\rvx}
  %\\The \fnctd{autocorrelation operator} & \opR\ff    & of $\ff(t)$               is & \opR f    &\eqd& \int_{u\in\R}\Rxx(t,u) f(u) \du     %& \text{(\prope{auto-correlation operator})}
\end{array}}$
  }
\end{definition}

%---------------------------------------
\begin{remark}
%---------------------------------------
  The $\Rxy(n,m)$ of \prefpp{def:Rxynm} and the $\Rxy(m)$ of \prefpp{def:Rxym} (etc.) are examples
  of \hie{function overload}---that is, functions that use the same
  mnemonic but are distinguished by different domains.
  Perhaps a more common example of function overload is the ``$+$" mnemonic.
  Traditionally it is used with domain of the natural numbers $\N$ as in $3+2$.
  Later it was extended for domain real numbers $\R$ as in $\sqrt{3}+\sqrt{2}$,
  or even complex numbers $\C$ as in $\brp{\sqrt{3}+i\sqrt{2}}+\brp{e+i\pi}$.
  And it was even more dramatically extended for use with domain $\R^\xN\times\R^\xM$
  in ``linear algebra" as in
  \\\indentx$
    \brs{\begin{array}{cc}1&2\\3&4\end{array}} +
    \brs{\begin{array}{cc}5&6\\7&8\end{array}} =
    \brs{\begin{array}{cc}6&8\\10&12\end{array}}
   $
\end{remark}

%---------------------------------------
\begin{corollary}
\label{cor:Rxxm}
\label{cor:Rxym}
%---------------------------------------
Let $\rvy(n)$ be a \fncte{random process},
    $\rvx(n)$    a \fncte{random sequence} with \fncte{autocorrelation} $\Rxx(n,m)$,
and $\Rxy$    the \fncte{cross-correlation} of $\rvx$ and $\rvy$.
\corbox{
  \brb{\begin{array}{M}
    $\rvx$ and $\rvy$ are\\
    \prope{wide sense stationary}
  \end{array}}
  \implies
  \brb{\begin{array}{rclD}
    \Rxx(m) &=& \Rxx     (-m) & (\prope{symmetric})\\
    \Rxy(m) &=& \Ryx^\ast(-m) & (\prope{conjugate symmetric})
  \end{array}}
}
\end{corollary}
\begin{proof}
\begin{align*}
  \Rxy(m)
     &\eqd \Rxy(0,m)
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxym}}
   \\&= \Ryx^\ast(0+m,-m)
     && \text{by \prope{non-WSS result}}
     && \text{\xref{thm:Rxynm}}
   \\&\eqd \brp{\pE\brs{\rvy(0+m) \rvx^\ast(0+m-m)}}^\ast
   \\&=    \brp{\pE\brs{\rvy(m-m) \rvx^\ast(0+m-m-m)}}^\ast
     && \text{by \prope{WSS} hypothesis}
     && \text{\xref{def:wss}}
   \\&=    \brp{\pE\brs{\rvy(0) \rvx^\ast(-m)}}^\ast
   \\&\eqd \Ryx^\ast(0,-m)
     && \text{by definition of $\Rxy(m,n)$}
     && \text{\xref{def:Rxy}}
   \\&\eqd \Ryx^\ast(-m)
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxym}}
   \\
   \\
   \Rxx(m)
     &= \brlr{\Rxy(m)}_{y=x}
   \\&= \brlr{\Ryx^\ast(-m)}_{y=x}
     && \text{by previous result}
   \\&= \Rxx^\ast(-m)
   \\&= \Rxx(-m)
     && \text{because \prope{real-valued}}
\end{align*}
\end{proof}


\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(300,100)(-100,-60)
  \thicklines
  %\graphpaper[10](0,0)(160,80)
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(m)$}  }
  \put(-100, -50 ){\makebox (100, 40)[b]{$\Sxx(z)$}  }
  \put(-100,   0 ){\vector  (  1,  0){100}             }
  \put(   0, -50 ){\framebox(100,100){$\conv\fh(n)$}  }
  \put( 100,   0 ){\vector  (  1,  0){100}             }
  \put( 100,  10 ){\makebox (100, 40)[b]{$\rvy(n)$}  }
  \put( 100, -50 ){\makebox (100, 40)[t]{$\Ryy(m)$}  }
  \put( 100, -50 ){\makebox (100, 40)[b]{$\Syy(z)$}  }
  \put(  50, -60 ){\makebox (  0,  0)[t]{$\Rxy(m)$}  }
  \end{picture}
\caption{
   Linear system with WSS \fncte{random sequence} input and output
   \label{fig:d-linear-sys-WSS}
   }
\end{center}
\end{fsK}
\end{figure}

The next theorem describes the statistical properties of an LTI system
with impulse response $\fh(t)$ and with an input which is a
WSS \fncte{random sequence} \xref{fig:d-linear-sys-WSS}.
%---------------------------------------
\begin{corollary}
\footnote{
  \citerp{papoulis}{323}
  }
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corboxt{
  $\brb{\begin{array}{FMMD}
    (A). & $\opS$ is \prope{linear time invariant}             & (\prope{LTI}) & and\\
    (B). & $\rvx$ and $\rvy$ are \prope{wide sense stationary} & (\prope{WSS}) &
  \end{array}}
  \quad\implies$
    \\\qquad$
  \brb{\begin{array}{Frc>{\ds}lc>{\ds}lD}
       (1).&\Rxy(m) &=& \Rxx(m)\conv \fh^\ast(m)            &\eqd& \sum_{k\in\Z} \fh^\ast(k) \Rxx(m-k)  & and
     \\(2).&\Ryy(m) &=& \Rxy(m)\conv \fh(m)                 &\eqd& \sum_{k\in\Z} \fh(k) \Rxy(m-k)        & and
     \\(3).&\Ryy(m) &=& \Rxx(m)\conv \fh(m)\conv\fh^\ast(m) &\eqd& \mc{2}{l}{\ds\sum_{p\in\Z}\sum_{k\in\Z}\fh(k)h^\ast(p) \Rxx(m-p-k)}
  \end{array}}
  $
  }
\end{corollary}
\begin{proof}
\begin{align*}
  \Rxy(m)
     &\eqd \Rxy(0,m)
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxym}}
   \\&= \Rxx(0,m)\conv \fh^\ast(m) %\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(0,m-k)
     && \text{by \prope{non-WSS} case}
     && \text{\xref{thm:Rxyh}}
   \\&\eqd \Rxx(m)\conv \fh^\ast(m)
     && \text{by definition of $\Rxx(m)$}
     && \text{\xref{def:Rxxm}}
   \\&\eqd \sum_{k\in\Z} \fh^\ast(k) \Rxx(m-k)
     && \text{by definition of \ope{convolution}}
     && \text{\xref{def:dsp_conv}}
\\
\\
  \Ryy(m)
     &\eqd Ryy(0,m)
     && \text{by definition of $\Ryy(m)$}
     && \text{\xref{def:Rxxm}}
   \\&= \Rxy(0,m)\conv \fh(m)
     && \text{by \prope{non-WSS} case}
     && \text{\xref{thm:Rxyh}}
   \\&\eqd \Rxy(m)\conv \fh(m)
     && \text{by definition of $\Rxy(m)$}
     && \text{\xref{def:Rxxm}}
   \\&\eqd \sum_{k\in\Z} \fh(k) \Rxy(m-k)
\\
\\
  \Ryy(m)
    &= \Rxy(m)\conv \fh(m)
    && \text{by previous result}
  \\&= \Rxx(m)\conv \fh^\ast(m) \conv \fh(m)
    && \text{by previous result}
  \\&= \Rxx(m)\conv \fh(m) \conv \fh^\ast(m)
\\
\\
  \Ryy(m)
     &\eqd \Ryy(0,m)
     && \text{by definition of $\Ryy(m)$}
     && \text{\xref{def:Rxxm}}
   \\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(k)h^\ast(p) \Rxx(0-k,m-p)
     && \text{by \prope{non-WSS} case}
     && \text{\xref{thm:Rxyh}}
   \\&= \sum_{p\in\Z} \sum_{k\in\Z} \fh(k)h^\ast(p) \Rxx(m-p-k)
     && \text{by definition of $\Rxx(m)$}
     && \text{\xref{def:Rxxm}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{definition}
\label{def:psd}
\label{def:csd}
\label{def:Swxy}
%---------------------------------------
Let $\rvx(n)$ and $\rvy(n)$ be a \prope{wide sense stationary} \fncte{random sequence}es
with auto-correlation $\Rxx(m)$ and cross-correlation $\Rxy(m)$.
Let $\opZ$ be the \ope{Z-transform operator}\ifsxref{dsp}{def:opZ}.
\\
\defbox{\begin{array}{MMrclcl}
   The \opd{power spectral density} & (\opd{PSD}) of $\vx$ is           & \Sxx(z) &\eqd& \opZ{\Rxx(m)} &\eqd& \ds \sum_{m\in\Z} \Rxx(m) z^{-m}\\
   The \opd{cross spectral density} & (\opd{CSD}) of $\vx$ and $\vy$ is & \Sxy(z) &\eqd& \opZ{\Rxy(m)} &\eqd& \ds \sum_{m\in\Z} \Rxy(m) z^{-m}
\end{array}}
\end{definition}

%---------------------------------------
\begin{theorem}
\footnote{
  \citerp{papoulis}{323}
  }
\label{thm:Sxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\thmbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Sxy(z) &=& \ds \Sxx(z) \Zh^\ast\brp{z^\ast} & and
     \\(2).&\Syy(z) &=& \ds \Sxy(z) \Zh(z)               & and
     \\(3).&\Syy(z) &=& \mc{2}{l}{\ds \Sxx(z) \Zh(z) \Zh^\ast\brp{z^\ast}}
  \end{array}}
  }
\end{theorem}
\begin{proof}
\begin{align*}
  \Sxy(z)
     &\eqd \opZ \Rxy(m)
    && \text{by definition of $\Sxy(z)$}
    && \text{\xref{def:csd}}
   \\&= \opZ \brs{\Rxx(m) \conv \fh^\ast(m)}
    && \text{by \prefp{thm:Rxyh}}
   \\&= \brs{\opZ\Rxx(m)}\,\opZ\brs{\fh^\ast(m)}
    && \text{by \thme{convolution theorem}}
    && \text{\xref{thm:conv}}
   \\&= \Sxx(z) \Zh^\ast\brp{z^\ast}
   \\
   \\
  \Syy(z)
     &\eqd \opZ \Ryy(m)
    && \text{by definition of $\Syy(z)$}
    && \text{\xref{def:csd}}
   \\&= \opZ \brs{\Rxy(m) \conv \fh(m)}
    && \text{by \prefp{thm:Rxyh}}
   \\&= \brs{\opZ\Rxy(m)}\,\opZ\brs{\fh(m)}
    && \text{by \thme{convolution theorem}}
    && \text{\xref{thm:conv}}
   \\&\eqd \Sxy(z) \Zh(z)
   \\
   \\
  \Syy(z)
     &= \Sxy(z) \Zh(z)
     && \text{by previous result}
   \\&= \Sxx(z) \Zh^\ast\brp{z^\ast} \Zh(z)
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:Swxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& \mc{2}{M}{$\rvx$ and $\rvy$ are \prope{wide sense stationary}}
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Swxy(\omega) &=& \ds \Swxx(\omega) \Fh^\ast(-\omega) & and
     \\(2).&\Swyy(\omega) &=& \ds \Swxy(\omega) \Fh(\omega)       & and
     \\(3).&\Swyy(\omega) &=& \mc{2}{l}{\ds \Swxx(\omega) \Fh(\omega) \Fh^\ast(-\omega)}
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{align*}
   \Swxy(\omega)
     &= \brlr{\Sxy(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\Sxx(z)\Zh^\ast(z)}_{z=e^{i\omega}}
     && \text{by \prefp{thm:Sxy}}
   \\&= \Sxx\brp{e^{i\omega}}\Zh^\ast\brp{e^{-i\omega}}
   \\&= \Swxx(\omega) \Fh^\ast(-\omega)
   \\
   \Swyy(\omega)
     &= \brlr{\Syy(z)}_{z=e^{i\omega}}
     && \text{by definition of \ope{DTFT}}
     && \text{\xref{def:dtft}}
   \\&= \brlr{\Sxy(z)\Zh(z)}_{z=e^{i\omega}}
     && \text{by \prefp{thm:Sxy}}
   \\&= \Sxy\brp{e^{i\omega}}\Zh\brp{e^{-i\omega}}
   \\&= \Swxy(\omega) \Fh(\omega)
   \\
   \Swyy(\omega)
     &= \Swxy(\omega) \Fh(\omega)
     && \text{by previous result}
   \\&= \Swxx(\omega) \Fh^\ast(-\omega) \Fh(\omega)
     && \text{by previous result}
\end{align*}
\end{proof}

%---------------------------------------
\begin{corollary}
\label{cor:Swxy}
%---------------------------------------
Let $\opS$ be a system with \fncte{impulse response} $\fh(n)$,
\fncte{input} $\rvx(n)$, and \fncte{output} $\rvy(n)$.
\corbox{
  \brb{\begin{array}{FMD}
    (A).& $\fh$ is \prope{linear time invariant} & and\\
    (B).& $\rvx$ and $\rvy$ are \prope{wide sense stationary} & and\\
    (C).& $\fh(n)$ is \prope{real-valued}
  \end{array}}
  \implies
  \brb{\begin{array}{FrclD}
       (1).&\Swxy(\omega) &=& \ds \Swxx(\omega) \Fh(\omega) & and
     \\(2).&\Swyy(\omega) &=& \ds \Swxy(\omega) \Fh(\omega) & and
     \\(3).&\Swyy(\omega) &=& \mc{2}{l}{\ds \Swxx(\omega) \Fh(\omega) \Fh(\omega)}
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{align*}
   \Swxy(\omega)
     &= \Swxx(\omega) \Fh^\ast(-\omega)
     && \text{by \prefp{cor:Swxy}}
   \\&= \Swxx(\omega) \Fh(\omega)
     && \text{by hypothesis (C)}
   \\
   \Swyy(\omega)
     &= \Swxy(\omega) \Fh(\omega)
     && \text{by \prefp{cor:Swxy}}
   \\
   \Swyy(\omega)
     &= \Swxx(\omega) \Fh^\ast(-\omega) \Fh(\omega)
     && \text{by \prefp{cor:Swxy}}
   \\&= \Swxx(\omega) \Fh(\omega) \Fh(\omega)
     && \text{by hypothesis (C)}
\end{align*}
\end{proof}

%---------------------------------------
\begin{remark}
\label{rem:Rxym}
%---------------------------------------
In the literature, there are varying and in general incompatible definitions of
\fncte{cross-correlation} functions $\Rxy(n,m)$ and $\Rxy(m)$ \xxref{def:Rxynm}{def:Rxym}.
The choice of definitions has consequences for results involving $\Swxy$ \xref{cor:Swxy}.
Here is a very limited overview:
\\\indentx$\begin{array}{>{\qquad}cNM>{\ds}rc>{\ds}l}
  \mc{6}{M}{References that put conjugate $\conj$ on $\rvy$:}
  \\&\imark&\citerpg{papoulis1984}{263}{0070484686} & R_{xy}(m) &=& E\brb{\rvx(m)\rvy^\ast(0)}
  \\&\imark&\citerpg{cadzow}{341}{0023180102}       & r_{xy}(m) &=& E\brs{\rvx(m)\rvy^\ast(0)}
  \\&\imark&\citeP{matlab_xcorr} & R_{xy}(m) &=& E\setn{x_{n+m}y_n^\ast}
  \\&\imark&\citeP{matlab_cpsd}  & R_{xy}(m) &=& E\setn{x_{n+m}y_n^\ast}
  \\
  \mc{6}{M}{References that put conjugate $\conj$ on $\rvx$:}
  \\&\imark&\citerpg{kay1988}{52}{8131733564}       & r_{xy}[m] &=& \mathcal{E}\brb{x^\ast[0]y[m]}
  \\&\imark&\citerpg{weisstein2002}{594}{1420035223}\footnotemark& f\star g  &=& \int_{-\infty}^{\infty}\bar{f}(\tau)g(t+\tau)\dtau
  \\
  \mc{6}{M}{References that use no conjugate $\conj$:}
  \\&\imark&\citerpg{bendat2011}{111}{1118210824}   & R_{xy}(m)            &=& E\brs{\rvx(0)\rvy(m)}
  \\&\imark&\citerpg{helstrom1991}{369}{0023535717} & \Rxy(t_1,t_2)        &=& E[\rvx(t_1)\rvy(t_2)]
  \\&\imark&\citerpg{proakis1996}{A4}{0133737624}   & \gamma_{xy}(t_1,t_2) &=& E(X_{t_1}Y_{t_2})
  \\&\imark&\citerpg{shin2008}{280}{0470725648}     & R_{xy}(\tau)         &=& E[x(t)y(t+\tau)]
  \\&\imark&\citerpg{bracewell1978}{46}{007007013X}\footnotemark & g^\ast\star h  &=& \int_{-\infty}^{\infty}g^\ast(u)h(u+x)\du   %{Pentagram notation for cross correlation}
\end{array}$
\addtocounter{footnote}{-2}
\footnotetext{
  Bracewell and Weisstein here use the \ope{integral operator} $\int_{\R}\!\dx$ rather than the 
  \ope{expectation operator} $\pE$. 
  That is, they use a \ope{time average} rather than an \ope{ensemble average}. 
  But in essence, the two types of operators are ``the same" because both types represent
  \ope{inner product}s. 
  That is, $\int_{x\in\R}\ff(x)\fg^\ast(x)\dx\eqd\inprod{\ff(x)}{\fg(x)}_1$ and
  $\pE\brs{\rvx(t)\rvy^\ast(t)}\eqd\inprod{\rvx(t)}{\rvy(t)}_2$
  (both are inner products, but operate in perpendicular orientations across the ensemble plane).
  }
\stepcounter{footnote}
\footnotetext{
  Note that Bracewell's ``\ope{Pentagram notation for cross correlation}"
  $g^\ast\star h =\int_{-\infty}^{\infty}g^\ast(u)h(u+x)\du$ 
  implies
  $g\star h =\int_{-\infty}^{\infty}g(u)h(u+x)\du$ 
  (and hence in the ``References that use no conjugate" category).
  }
Note the following:
\begin{enumerate}
\item Depending on how we define $\Rxy(m)$ we can get 8 different results for $\Swxy(\omega)$:\label{item:RxySwxy}
\\\rembox{\begin{array}{FM >{\ds}rc l*{3}{@{\hspace{0pt}}l} c >{\ds}rc l*{2}{@{\hspace{0pt}}l}}
    (1).&Papoulis:        & \Rxy(m) &\eqd& \pE[\rvx     &(m)\rvy^\ast&(0&)] &\implies& \Swxy(\omega) &=&\Fh^\ast&( &\omega)\Swxx(\omega)
  \\(2).&Kay:             & \Rxy(m) &\eqd& \pE[\rvx^\ast&(0)\rvy     &(m&)] &\implies& \Swxy(\omega) &=&\Fh     &( &\omega)\Swxx(\omega)
  \\(3).&y-star-m:        & \Rxy(m) &\eqd& \pE[\rvx     &(0)\rvy^\ast&(m&)] &\implies& \Swxy(\omega) &=&\Fh^\ast&(-&\omega)\Swxx(\omega)
  \\(4).&x-star-m:        & \Rxy(m) &\eqd& \pE[\rvx^\ast&(m)\rvy     &(0&)] &\implies& \Swxy(\omega) &=&\Fh     &(-&\omega)\Swxx(\omega)
  \\(5).&Bendat:          & \Rxy(m) &\eqd& \pE[\rvx     &(0)\rvy     &(m&)] &\implies& \Swxy(\omega) &=&\Fh     &( &\omega)\Swxx(\omega)
  \\(6).&alt-Bendat:      & \Rxy(m) &\eqd& \pE[\rvx     &(m)\rvy     &(0&)] &\implies& \Swxy(\omega) &=&\Fh     &(-&\omega)\Swxx(\omega)
  \\(7).&Bendat-star      & \Rxy(m) &\eqd& \pE[\rvx^\ast&(0)\rvy^\ast&(m&)] &\implies& \Swxy(\omega) &=&\Fh^\ast&(-&\omega)\Swxx(\omega)
  \\(8).&alt-Bendat-star: & \Rxy(m) &\eqd& \pE[\rvx^\ast&(m)\rvy^\ast&(0&)] &\implies& \Swxy(\omega) &=&\Fh     &(-&\omega)\Swxx(\omega)
\end{array}}


\item The \ope{expectation} operator $\pE\brp{\rvX\rvY^\ast}$ is an \fncte{inner product}.
As such, it would seem the most natural to follow the convention of other inner product definitions
and thus put the conjugate $\conj$ on $\rvy$ (i.e. follow Papoulis):
\\\indentx$\begin{array}{c>{\ds}rc>{\ds}l}
    \imark & \inprod{\fx(t)}{\fy(t)} &\eqd& \int_{t\in\R} \fx(t)\fy^\conj(t) \dt
  \\\imark & \inprod{\fx(n)}{\fy(n)} &\eqd& \sum_{n\in\Z} \fx(n)\fy^\conj(n)
  \\\imark & \inprod{\rvX}{\rvY}     &\eqd& \pE\brp{\rvX\rvY^\conj}
\end{array}$

\item If we view $\Rxy(m)$ as an \ope{analysis} of $\rvy$ in terms of $\rvx$ 
      (or as a \ope{projection} of $\rvy$ onto $\rvx$),
      then it would seem more natural to put the conjugate on $\rvx$ (i.e. follow Kay).
      This is what is done in Fourier analysis when projecting a function $\ff(t)$ onto the 
      set of basis functions $\set{e^{i\omega n}}{\omega\in\R}$, as in 
      \\\begin{align*}
        \opDTFT\brs{\rvy[n]}(\omega) 
          &\eqd \inprod{\rvy[n]}{e^{i\omega n}} 
          && \text{(\ope{project} $\rvy[n]$ onto $e^{i\omega n}$ for some $\omega\in\R$)}
        \\&\eqd \sum_{n\in\Z} \rvy[n] \brs{e^{+i\omega n}}^\ast
        \\&\eqd \sum_{n\in\Z} \rvy[n] e^{-i\omega n}
      \end{align*}
      But arguably, a ``projection of $\rvy$ onto $\rvx$" would better be served by the use of $\Ryx(m)$ rather than $\Rxy(m)$.

\item If we follow Kay, then there is the advantage that you also end up with Bendat's result for $\Swxy(\omega)$.

\item In the special case where $\rvx[n]$ and $\rvy[n]$ are \propb{real-valued} and by 
      \prefpp{thm:dtft_conjneg_real}, \pref{item:RxySwxy} becomes
\\\rembox{\begin{array}{FM >{\ds}rc l*{3}{@{\hspace{0pt}}l} c >{\ds}rc l@{\hspace{0pt}}l}
    (1s).&Papoulis:        & \Rxy(m) &\eqd& \pE[\rvx     &(m)\rvy^\ast&(0&)] &\implies& \Swxy(\omega) &=&\Fh^\ast&(\omega)\Swxx(\omega)
  \\(2s).&Kay:             & \Rxy(m) &\eqd& \pE[\rvx^\ast&(0)\rvy     &(m&)] &\implies& \Swxy(\omega) &=&\Fh     &(\omega)\Swxx(\omega)
  \\(3s).&y-star-m:        & \Rxy(m) &\eqd& \pE[\rvx     &(0)\rvy^\ast&(m&)] &\implies& \Swxy(\omega) &=&\Fh     &(\omega)\Swxx(\omega)
  \\(4s).&x-star-m:        & \Rxy(m) &\eqd& \pE[\rvx^\ast&(m)\rvy     &(0&)] &\implies& \Swxy(\omega) &=&\Fh^\ast&(\omega)\Swxx(\omega)
  \\(5s).&Bendat:          & \Rxy(m) &\eqd& \pE[\rvx     &(0)\rvy     &(m&)] &\implies& \Swxy(\omega) &=&\Fh     &(\omega)\Swxx(\omega)
  \\(6s).&alt-Bendat:      & \Rxy(m) &\eqd& \pE[\rvx     &(m)\rvy     &(0&)] &\implies& \Swxy(\omega) &=&\Fh^\ast&(\omega)\Swxx(\omega)
  \\(7s).&Bendat-star      & \Rxy(m) &\eqd& \pE[\rvx^\ast&(0)\rvy^\ast&(m&)] &\implies& \Swxy(\omega) &=&\Fh     &(\omega)\Swxx(\omega)
  \\(8s).&alt-Bendat-star: & \Rxy(m) &\eqd& \pE[\rvx^\ast&(m)\rvy^\ast&(0&)] &\implies& \Swxy(\omega) &=&\Fh^\ast&(\omega)\Swxx(\omega)
\end{array}}
\end{enumerate}
\end{remark}
\begin{proof}
\begin{enumerate}
\item If we follow Papoulis $\brp{\Rxy(m)\eqd\pE\brs{\rvx(m)\rvy^\ast(0)}}$, then\ldots \label{item:Rxy_papoulis}
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\pE\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvx(m)\rvy^\ast(0)}
      && \text{by Papoulis' definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\rvx(m)\brp{\sum_{k\in\Z} \fh(k)\rvx(0-k)}^\ast}
      && \text{by \prope{LTI} property}
    \\&=    \opDTFT\pE\brs{\rvx(m) \sum_{k\in\Z} \fh^\ast(k)      \rvx^\ast(0-k)}
      && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
      && \text{\xref{def:staralg}}
    \\&=    \opDTFT        \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(m)\rvx^\ast(0-k)}
    \\&=    \opDTFT        \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(0)\rvx^\ast(-m-k)}
      &&    \text{by \prope{wide sense stationary} property}
    \\&=    \opDTFT        \sum_{k\in\Z} \fh^\ast(k) \brp{\pE\brs{\rvx(-m-k)\rvx^\ast(0)}}^\ast
    \\&\eqd \opDTFT        \sum_{k\in\Z} \fh^\ast(k) \Rxx^\ast(-m-k)
      && \text{by Papoulis' definition of $\Rxy(m)$}
    \\&\eqd \opDTFT\brs{\fh^\ast(-m) \conv \Rxx^\ast(-m)}
      && \text{by definition of \ope{convolution}}
      && \text{\xref{def:conv}}
    \\&=    \brs{\opDTFT\fh^\ast(-m)} \brs{\opDTFT\Rxx^\ast(-m)}
      && \text{by \thme{convolution theorem}}
      && \text{\xref{thm:conv}}
    \\&\eqd \Fh^\ast(\omega) \Swxx^\ast(\omega)
      && \text{by \prefp{thm:dtft_conjneg}}
    \\&= \Fh^\ast(\omega) \Swxx(\omega)
      && \text{because $\Swxx(\omega)$ is \prope{real-valued}}
  \end{align*}

\item If we follow Kay $\brp{\Rxy(m)\eqd\pE\brs{\rvx^\ast(0)\rvy(m)}}$, then\ldots
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvy(m)\rvx^\ast(0)}
      && \text{by Kay's definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\brp{\fh(m)\conv\rvx(m)}\rvx^\ast(0)}
      && \text{by \prope{LTI} property}
      && \text{\xref{thm:conv}}
    \\&=    \opDTFT\pE\brs{\brp{\sum_{k\in\Z} \fh(k)\rvx(m-k)}\rvx^\ast(0)}
    \\&=    \opDTFT\brp{\sum_{k\in\Z} \fh(k)\pE\brs{\rvx(m-k)\rvx^\ast(0)}}
      && \text{by \prope{linearity} of $\sum$}
    \\&\eqd \opDTFT\brp{\sum_{k\in\Z} \fh(k)\Rxx(m-k)}
      && \text{by Kay's definition of $\Rxy(m)$}
    \\&\eqd \opDTFT\brp{\fh(m)\conv\Rxx(m)}
      && \text{by definition of \ope{convolution}}
      && \text{\xref{def:conv}}
    \\&=    \brs{\opDTFT\fh(m)}\brs{\opDTFT\Rxx(m)}
    \\&\eqd \Fh(\omega) \Swxx(\omega)
      && \text{by definitions of $\Fh(\omega)$ and $\Swxx(\omega)$}
      && \text{\xref{def:dtft}}
  \end{align*}

\item For y-star-m $\brp{\Rxy(m)\eqd\pE\brs{\rvx(0)\rvy^\ast(m)}}$ \ldots \label{item:Rxy_ystarm}
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\pE\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvx(0)\rvy^\ast(m)}
      && \text{by \pref{item:Rxy_ystarm} definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\rvx(0)\brp{\sum_{k\in\Z} \fh(k)\rvx(m-k)}^\ast}
      && \text{by \prope{LTI} property}
    \\&=    \opDTFT\pE\brs{\rvx(0) \sum_{k\in\Z} \fh^\ast(k)      \rvx^\ast(m-k)}
      && \text{by \prope{distributive} property of \structd{$\invo$-algebra}s}
      && \text{\xref{def:staralg}}
    \\&=    \opDTFT        \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx(0)\rvx^\ast(m-k)}
    \\&\eqd \opDTFT        \sum_{k\in\Z} \fh^\ast(k) \Rxx^\ast(m-k)
      && \text{by \pref{item:Rxy_ystarm} definition of $\Rxy(m)$}
    \\&\eqd \opDTFT\brs{\fh(m) \conv \Rxx^\ast(m)}
      && \text{by definition of \ope{convolution}}
      && \text{\xref{def:conv}}
    \\&=    \brs{\opDTFT\fh^\ast(m)} \brs{\opDTFT\Rxx^\ast(m)}
      && \text{by \thme{convolution theorem}}
      && \text{\xref{thm:conv}}
    \\&\eqd \Fh(\omega) \Swxx(\omega)
      && \text{by definition of \ope{DTFT}}
      && \text{\xref{def:dtft}}
  \end{align*}

\item For x-star-m $\brp{\Rxy(m)\eqd\pE\brs{\rvx^\ast(m)\rvy(0)}}$ \ldots \label{item:Rxy_xstarm}
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\pE\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvx^\ast(m)\rvy(0)}
      && \text{by \pref{item:Rxy_xstarm} definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\rvx^\ast(m)\sum_{k\in\Z} \fh(k)           \rvx(0-k)}
      && \text{by prope{LTI} property}
    \\&=    \opDTFT\sum_{k\in\Z} \fh(k)\pE\brs{\rvx^\ast(m)\rvx(0-k)}
      && \text{by \prope{linearity} of $\sum$}
    \\&=    \opDTFT\sum_{k\in\Z} \fh(k)\pE\brs{\rvx^\ast(m+k)\rvx(0)}
      && \text{by \prope{wide sense stationary} property}
      && \text{\xref{def:wss}}
    \\&=    \opDTFT\sum_{k\in\Z} \fh(k)\Rxx(m+k)
      && \text{by \pref{item:Rxy_xstarm} definition of $\Rxy(m)$}
    \\&=    \opDTFT\sum_{k'\in\Z} \fh(-k')\Rxx(m-k')
      && \text{where $k'\eqd k$}
    \\&\eqd \opDTFT\brs{\fh(-m) \conv \Rxx(m)}
      && \text{by definition of \ope{convolution}}
      && \text{\xref{def:conv}}
    \\&\eqd \brs{\opDTFT\fh(-m)} \brs{\opDTFT\Rxx(m)}
      && \text{by \thme{convolution theorem}}
      && \text{\xref{thm:conv}}
    \\&\eqd \Fh(-\omega) \Swxx(\omega)
      && \text{by \prefp{thm:dtft_conjneg}}
  \end{align*}

\item If we follow Bendat $\brp{\Rxy(m)\eqd\pE\brs{\rvx(0)\rvy(m)}}$, then\ldots \label{item:Rxy_bendat}
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\pE\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvx(0)\rvy(m)}
      && \text{by Bendat's definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\rvx(0)\brp{\sum_{k\in\Z} \fh(k) \rvx(m-k)}}
      && \text{by \prope{LTI} property}
    \\&=    \opDTFT                    \sum_{k\in\Z} \fh(k) \pE\brs{\rvx(0)\rvx(m-k)}
      && \text{by \prope{linearity} of $\sum$}
    \\&\eqd \opDTFT                    \sum_{k\in\Z} \fh(k) \Rxx(m-k)
      && \text{by Bendat's definition of $\Rxy(m)$}
    \\&\eqd \opDTFT\brs{\fh(m) \conv \Rxx(m)}
    \\&\eqd \Fh(\omega) \Swxx(\omega)
  \end{align*}

\item For alt-Bendat $\brp{\Rxy(m)\eqd\pE\brs{\rvx(m)\rvy(0)}}$ \ldots \label{item:Rxy_bendatalt}
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\pE\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvx(m)\rvy(0)}
      && \text{by \pref{item:Rxy_bendatalt} definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\rvx(m)\brp{\sum_{k\in\Z} \fh(k) \rvx(0-k)}}
      && \text{by \prope{LTI} property}
    \\&=    \opDTFT\sum_{k\in\Z} \fh(k) \pE\brs{\rvx(m)\rvx(-k)}
      && \text{by \prope{linearity} of $\sum$}
    \\&=    \opDTFT\sum_{k\in\Z} \fh(k) \pE\brs{\rvx(0)\rvx(-m-k)}
      && \text{by \prope{wide sense stationary} property}
      && \text{\xref{def:wss}}
    \\&=    \opDTFT\sum_{k\in\Z} \fh(k) \pE\brs{\rvx(-m-k)\rvx(0)}
      && \text{by \prope{commutative} property}
    \\&\eqd \opDTFT                    \sum_{k\in\Z} \fh(k) \Rxx(-m-k)
      && \text{by \pref{item:Rxy_bendatalt} definition of $\Rxy(m)$}
    \\&\eqd \opDTFT\brs{\fh(-m) \conv \Rxx(-m)}
      && \text{by definition of \ope{convolution} operation}
      && \text{\xref{def:conv}}
    \\&\eqd \opDTFT\brs{\fh(-m) \conv \Rxx(m)}
      && \text{by \prefp{cor:Rxxm}}
    \\&\eqd \Fh(-\omega) \Swxx(\omega)
  \end{align*}

\item For Bendat-star $\brp{\Rxy(m)\eqd\pE\brs{\rvx^\ast(0)\rvy^\ast(m)}}$, then\ldots \label{item:Rxy_bendat-star}
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\pE\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvx^\ast(0)\rvy^\ast(m)}
      && \text{by Bendat-star definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\rvx^\ast(0)\rvy^\ast(m)}
    \\&=    \opDTFT\pE\brs{\rvx^\ast(0)\brp{\sum_{k\in\Z} \fh(k) \rvx(m-k)}^\ast}
      && \text{by \prope{LTI} property}
    \\&=    \opDTFT                    \sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx^\ast(0)\rvx^\ast(m-k)}
      && \text{by \prope{linearity} of $\sum$}
    \\&\eqd \opDTFT                    \sum_{k\in\Z} \fh^\ast(k) \Rxx(m-k)
      && \text{by Bendat-star definition of $\Rxy(m)$}
    \\&\eqd \opDTFT\brs{\fh^\ast(m) \conv \Rxx(m)}
    \\&\eqd \Fh^\ast(-\omega) \Swxx(\omega)
  \end{align*}

\item For alt-Bendat-star $\brp{\Rxy(m)\eqd\pE\brs{\rvx^\ast(m)\rvy^\ast(0)}}$ \ldots \label{item:Rxy_bendatalt}
  \begin{align*}
    \Swxy(\omega)
      &\eqd \opDTFT\pE\Rxy(m)
      && \text{by definition of $\Swxy(\omega)$}
      && \text{\xref{def:Swxy}}
    \\&\eqd \opDTFT\pE\brs{\rvx^\ast(m)\rvy^\ast(0)}
      && \text{by \pref{item:Rxy_bendatalt} definition of $\Rxy(m)$}
    \\&=    \opDTFT\pE\brs{\rvx^\ast(m)\brp{\sum_{k\in\Z} \fh^\ast(k) \rvx^\ast(0-k)}}
      && \text{by \prope{LTI} property}
    \\&=    \opDTFT\sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx^\ast(m)\rvx^\ast(-k)}
      && \text{by \prope{linearity} of $\sum$}
    \\&=    \opDTFT\sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx^\ast(0)\rvx^\ast(-m-k)}
      && \text{by \prope{wide sense stationary} property}
      && \text{\xref{def:wss}}
    \\&=    \opDTFT\sum_{k\in\Z} \fh^\ast(k) \pE\brs{\rvx^\ast(-m-k)\rvx^\ast(0)}
      && \text{by \prope{commutative} property}
    \\&\eqd \opDTFT                    \sum_{k\in\Z} \fh^\ast(k) \Rxx^\ast(-m-k)
      && \text{by \pref{item:Rxy_bendatalt} definition of $\Rxy(m)$}
    \\&\eqd \opDTFT\brs{\fh(-m) \conv \Rxx^\ast(-m)}
      && \text{by definition of \ope{convolution} operation}
      && \text{\xref{def:conv}}
    \\&\eqd \opDTFT\brs{\fh(-m) \conv \Rxx(m)}
      && \text{by \prefp{cor:Rxxm}}
    \\&\eqd \Fh(-\omega) \Swxx(\omega)
  \end{align*}
\end{enumerate}
\end{proof}

%=======================================
\section{Whitening}
\index{whitening filter}
\label{sec:d-whiten}
%=======================================
\begin{figure}[h]
  \centering
  \includegraphics{graphics/pz_minphase.pdf}
  \caption{
     Poles ($\times$) and zeros ($o$) of a \prope{minimum phase} filter
     \label{fig:w_pz_minphase}
     }
\end{figure}
%---------------------------------------
\begin{definition}
\index{minimum phase}
\index{rational expression}
%---------------------------------------
Let $\Zh(z)$ be the z-transform of the impulse response of a filter.
If $\Zh(z)$ can be expressed as a rational expression with poles and zeros
$r_ne^{i\theta_n}$,
then the filter is \textbf{minimum phase} if each $r_n<1$
(all roots lie inside the unit circle in the complex $z$-plane).
\end{definition}
See \prefp{fig:w_pz_minphase}.

Note that if $L(z)$ has a root at $z=re^{i\theta}$, then
$L^\ast(1/z^\ast)$ has a root at
\begin{eqnarray*}
   \frac{1}{z^\ast}
     &=& \frac{1}{\brp{re^{i\theta}}^\ast}
      = \frac{1}{re^{-i\theta}}
      = \frac{1}{r} e^{i\theta}.
\end{eqnarray*}
That is, if $L(z)$ has a root inside the unit circle,
then $L^\ast(1/z^\ast)$ has a root directly opposite across the unit circle
boundary (see \prefp{fig:z-roots}).
A causal stable filter $\Z\Zh(z)$ must have all of its poles inside
the unit circle.
A minimum phase filter is a filter with both its poles and zeros inside the
unit circle.
One advantage of a minimum phase filter is that its recipricol
(zeros become poles and poles become zeros)
is also causal and stable.

\begin{figure}[ht]
\begin{center}
\begin{fsL}
\setlength{\unitlength}{0.2mm}
\begin{picture}(300,300)(-130,-130)
  %\graphpaper[10](0,0)(200,200)
  \thicklines%
  \color{axis}%
    \put(-130 ,   0 ){\line(1,0){260} }%
    \put(   0 ,-130 ){\line(0,1){260} }%
    \put( 140 ,   0 ){\makebox(0,0)[l]{$\Re$}}%
    \put(   0 , 140 ){\makebox(0,0)[b]{$\Im$}}%
  \color{zero}%
    \qbezier[24](  0,  0)( 56.5,56.5)(113,113)
    %\put(   0 ,   0 ){\line(1,1){120}}%
    \put(  28 ,  28 ){\circle{10}}%
    \put( 113 , 113 ){\circle{10}}%
    \put(  38 ,  28 ){\makebox(0,0)[l]{zero of $L(z)$}}%
    \put( 123 , 113 ){\makebox(0,0)[l]{zero of $L^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{pole}%
    \qbezier[24](0,0)(-61.5,-26.5)(-123,-53)%
    %\put(   0 ,   0 ){\line(-3,-1){130}}%
    \put( -76 , -25 ){\makebox(0,0){$\times$}}%
    \put(-119 , -40 ){\makebox(0,0){$\times$}}%
    \put( -76 , -25 ){\makebox(0,0)[lt]{pole of $L(z)$}}%
    \put(-119 , -40 ){\makebox(0,0)[lt]{pole of $L^\ast\brp{\frac{1}{z^\ast}}$}}%
  \color{circle}%
    \input{../common/circle.inp}
\end{picture}
\end{fsL}
\end{center}
\caption{
   Mirrored roots in complex-z plane
   \label{fig:z-roots}
   }
\end{figure}


\begin{figure}[ht]\color{figcolor}
\begin{fsK}
\begin{center}
  \setlength{\unitlength}{0.2mm}
  \begin{picture}(700,100)(-100,-60)
  \thicklines
  %\graphpaper[10](0,0)(160,80)
  \put(-100,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[t]{$\Rxx(m)$}                  }
  \put(-100, -50 ){\makebox (100, 40)[b]{$\Sxx(z)$}                  }
  \put(-100,   0 ){\vector  (  1,  0){100}                           }

  \put(   0, -50 ){\framebox(100,100)   {$\conv\gamma(n)$}           }
  \put(   0, -40 ){\makebox (100, 80)[t]{whitening}                  }
  \put(   0, -40 ){\makebox (100, 80)[b]{$\Gamma(z)$}                }
  \put( 100,   0 ){\vector  (  1,  0)   {200}                        }
  \put( 100,  10 ){\makebox (200, 40)[t]{white noise process}        }
  \put( 100,  10 ){\makebox (200, 40)[b]{$\vw(n)$}                 }
  \put( 100, -50 ){\makebox (200, 40)[t]{$\Rww(m)=\delta(m)$}  }
  \put( 100, -50 ){\makebox (200, 40)[b]{$\Sww(z)=1$}                }

  \put( 300, -50 ){\framebox(100,100)   {$\conv l(n)$}               }
  \put( 300, -40 ){\makebox (100, 80)[t]{innovations}                }
  \put( 300, -40 ){\makebox (100, 80)[b]{$L(z)$}                     }
  \put( 400,   0 ){\vector  (  1,  0)   {100}                        }
  \put( 400,  10 ){\makebox (100, 40)[b]{$\rvx(n)$}                  }
  \put( 400, -50 ){\makebox (200, 40)[t]{$\Rxx(m)=l(m)\conv l^\ast(-m)$}  }
  \put( 400, -50 ){\makebox (200, 40)[b]{$\Sxx(z)=L(z) L^\ast\brp{\frac{1}{z^\ast}}$}  }
  \end{picture}
\caption{
   Innovations and whitening filters
   \label{fig:d-innovations}
   }
\end{center}
\end{fsK}
\end{figure}


The next theorem demonstrates a method for ``whitening"
a \fncte{random sequence} $\fx(n)$ with a filter constructed from a decomposition
of $\Rxx(m)$.
The technique is stated precisely in \prefp{thm:d-innovations}
and illustrated in \prefp{fig:d-innovations}.
Both imply two filters with impulse responses $l(n)$ and $\gamma(n)$.
Filter $l(n)$ is referred to as the \textbf{innovations filter}
(because it generates or ``innovates" $\fx(n)$ from a white noise
process $\fw(n)$)
and $\gamma(n)$ is referred to as the \textbf{whitening filter}
because it produces a white noise sequence when the input sequence
is $\fx(n)$.\footnote{\citerpp{papoulis}{401}{402}}


%---------------------------------------
\begin{theorem}
\label{thm:d-innovations}
%---------------------------------------
Let $\fx(n)$ be a WSS \fncte{random sequence} with autocorrelation $\Rxx(m)$
and spectral density $\Sxx(z)$.
\textbf{If} $\Sxx(z)$ has a \textbf{rational expression},
then the following are true:

\begin{enume}
   \item There exists a rational expression $L(z)$ with minimum phase
         such that
         \[ \Sxx(z) = L(z)L^\ast\brp{\frac{1}{z^\ast}}. \]
   \item An LTI filter for which the Laplace transform of
         the impulse response $\gamma(n)$ is
         \[ \Gamma(z) = \frac{1}{L(z)} \]
         is both causal and stable.
   \item If $\fx(n)$ is the input to the filter $\gamma(n)$,
         the output $\fy(n)$ is a \textbf{white noise sequence} such that
         \[ \Syy(z)=1 \hspace{2cm} \Ryy(m)=\kdelta(m).\]
\end{enume}
\end{theorem}


\begin{proof}
\begin{eqnarray*}
   \Sww(z)
     &=& \Gamma(z)\Gamma^\ast\brp{\frac{1}{z^\ast}} \Sxx(z)
   \\&=& \frac{1}{L(z)} \frac{1}{L^\ast\brp{\frac{1}{z^\ast}}} \Sxx(z)
   \\&=& \frac{1}{L(z)} \frac{1}{L^\ast\brp{\frac{1}{z^\ast}}}
         L(z) L^\ast\brp{\frac{1}{z^\ast}}
   \\&=& 1
\end{eqnarray*}
\end{proof}

