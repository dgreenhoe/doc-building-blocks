%============================================================================
% LaTeX File
% Daniel J. Greenhoe
%============================================================================
%======================================
\chapter{Operations on Random Variables}
\label{chp:rval}
%======================================

%=======================================
\section{Functions of one random variable}
%=======================================
%---------------------------------------
\begin{proposition}
\label{prop:cdf_uniform}
%---------------------------------------
Let $\ps$ be a probability space, and $\rvX$ a \fncte{random variable}
with \fncte{cumulative distribution function} $\pcx(x)$.
\propbox{
  \brb{\begin{array}{M}
    $\rvX$ is \prope{uniformly distributed}\\
    \xref{def:uniform}
  \end{array}}
  \iff
  \pcx(x) = \brb{\begin{array}{cM}
                   0   & for $x<0$\\
                   x   & for $0< x \le 1$ \\
                   1   & otherwise
            \end{array}}
  }
\end{proposition}

%---------------------------------------
\begin{theorem}[\thmd{Probability integral transform}]
\footnote{
  \citeP{angus1994},
  \citerpgc{roussas2014}{232}{0128004371}{Theorem 10},
  \citerpgc{devroye1986}{28}{0387963057}{Theorem 2.1}
  }
\label{thm:pit}
%---------------------------------------
Let $\ps$ be a probability space.
Let $\rvX$ be a \fncte{random variable} with \fncte{probability density function} $\ppx(x)$ and \fncte{cumulative distribution function} $\pcx(x)$.
Let $\rvY$ be a \fncte{random variable} \fncte{cumulative distribution function} $\pcy(y)$.
\thmbox{
  \brb{\begin{array}{FMD}
         (1).&$\rvY=\pcx(\rvX)$               & and\\
         (2).&$\ppx(x)$ is \prope{continuous} &    \\
       \end{array}}
  \quad\implies\quad
  \brb{\begin{array}{M}
    $\rvY$ is \prope{uniformly distributed}\\
    \xref{def:uniform}
  \end{array}}
  }
\end{theorem}
\begin{proof}
\begin{align*}
  \pcy(y)
    &\eqd \psp\setn{\rvY\le y}
    &&    \text{by definition of \fncte{cdf}}   && \text{\xref{def:cdf}}
  \\&=    \psp\setn{\pcx(\rvX)\le y}
    &&    \text{by hypothesis (1)}
  \\&=    \psp\setn{\rvX\le \pcx^{-1}(y)}
    &&    \text{by hypothesis (2) and}          && \text{\prefp{prop:cdf_monotone}}
  \\&\eqd \pcx\brs{\pcx^{-1}(y)}
    &&    \text{by definition of \fncte{cdf}}   && \text{\xref{def:cdf}}
  \\&=    y
  \\\implies&\quad\text{$\rvY$ is \prope{uniformly distributed}}
    &&    \text{by}                             && \text{\prefp{prop:cdf_uniform}}
\end{align*}
\end{proof}

%---------------------------------------
\begin{theorem}[\thmd{Inverse probability integral transform}] %[\thmd{Inverse transform sampling}]
\footnote{
  \citerpgc{devroye1986}{28}{0387963057}{Theorem 2.1},
  \citerpgc{balakrishnan2009}{624}{0387096140}{14.2.1 Introduction}
  }
\label{thm:its}
%---------------------------------------
Let $\ps$ be a probability space.
Let $\rvX$ be a \fncte{random variable} with \fncte{probability density function} $\ppx(x)$ and \fncte{cumulative distribution function} $\pcx(x)$.
Let $\rvY$ be a \fncte{random variable} \fncte{cumulative distribution function} $\pcy(y)$.
\thmbox{
  \brb{\begin{array}{FMD}
         (1).&$\rvY=\pcz^{-1}(\rvX)$                     & and\\
         (2).&$\rvX$    is \prope{uniformly distributed} & and\\
         (3).&$\ppz(z)$ is \prope{continuous}            &
       \end{array}}
  \quad\implies\quad
  \brb{\begin{array}{M}
    $\ppy(y) = \ppz(y)$\\
    ($\rvY$ has distribution $\ppz(y)$)
  \end{array}}
  }
\end{theorem}
\begin{proof}
\begin{align*}
  \pcy(y)
    &\eqd \psp\setn{\rvY\le y}
    &&    \text{by definition of $\pcy$}          &&    \text{\xref{def:cdf}}
  \\&=    \psp\setn{\pcz^{-1}(\rvX)\le y}
    &&    \text{by hypothesis (1)}
  \\&=    \psp\setn{\rvX \le \pcz(y)}
    &&    \text{by hypothesis (3) and}            &&    \text{\prefp{prop:cdf_monotone}}
  \\&\eqd \pcx\brs{\pcz(y)}
    &&    \text{by definition of $\pcx$}          &&    \text{\xref{def:cdf}}
  \\&=    \pcz(y)
    &&    \text{because $0\le\pcz(y)\le1$ and by} && \text{\prefp{prop:cdf_uniform}}
  \\\implies&\quad\text{$\ppy(y)=\ppz(y)$}
    &&    \text{($\rvY$ has the distribution of $\rvZ$)}
\end{align*}
\end{proof}

\begin{figure}\color{figcolor}
\setlength{\unitlength}{0.4mm}
\thicklines
\begin{center}
\begin{footnotesize}
\begin{picture}(250,150)(-100,-20)
  {\color{axis}% axis
    \put(-100,   0){\line(1,0){200}}%
    \put(   0, -20){\line(0,1){120}}%
    }
  {\color{blue}% f(x)
    \qbezier(-100,100)(0,-100)(100,100)%
    \put( 100, 105){\makebox(0,0)[b]{$y=\ff(x)$}}%
    }%
  {\color{red}% dotted guide lines
    \qbezier[8](-40,0)(-40,8)(-40,16)%
    \qbezier[8](40,0)(40,8)(40,16)%
    \qbezier[28](-80,0)(-80,32)(-80,64)%
    \qbezier[28](80,0)(80,32)(80,64)%
    \qbezier[64](-80,64)(0,64)(80,64)%
    \qbezier[40](-40,16)(0,16)(40,16)%
    }%
  \put(   0, 110){\makebox(0,0)[r]{$y$}}
  \put( 110,   0){\makebox(0,0)[r]{$x$}}
  \put(  -5,  64){\makebox(0,0)[r]{$y+\varepsilon$}}
  \put(  -5,  16){\makebox(0,0)[r]{$y$}}
  \put( -40,  -5){\makebox(0,0)[t]{$\fgi_1(y)$}}
  \put(  40,  -5){\makebox(0,0)[t]{$\fgi_2(y)$}}
  \put( -80,  -5){\makebox(0,0)[t]{$\fgi_1(y+\varepsilon)$}}
  \put(  80,  -5){\makebox(0,0)[t]{$\fgi_2(y+\varepsilon)$}}
  \put(-100,  40){\makebox(0,0)[r]{$\left.\frac{\dy}{\dx}\right|_{x=\fgi_1(y)}$}}
  \put( 100,  40){\makebox(0,0)[l]{$\left.\frac{\dy}{\dx}\right|_{x=\fgi_2(y)}$}}
  \put(  95,  40){\vector(-1,0){35}}%
  \put( -95,  40){\vector(1,0){35}}%
  %\put(-100,  20){\makebox(0,0)[r]{$\fgi_1(y) + \left.\frac{\Delta y}{\dy/\dx}\right|_{x=\fgi_1(y)} = \fgi_1(y) + \frac{\varepsilon}{\ffp\brs{\fgi_1(y)}}$}}%
  \put(-100,  20){\makebox(0,0)[r]{$\fgi_1(y) + \frac{\varepsilon}{\ffp\brs{\fgi_1(y)}}$}}%
  \put( 100,  20){\makebox(0,0)[l]{$\fgi_2(y) + \left.\frac{\Delta y}{\dy/\dx}\right|_{x=\fgi_2(y)} = \fgi_2(y) + \frac{\varepsilon}{\ffp\brs{\fgi_2(y)}}$}}%
  \put( -95,  15){\vector( 1,-1){15}}
  \put(  95,  15){\vector(-1,-1){15}}
  \put( -60,   0){$\setA_1$}%
  \put(  60,   0){$\setA_2$}%
  {\color{red}% slope lines
    \put(  40,  16){\line(5,6){40}}%   %straight line
    \put( -40,  16){\line(-5,6){40}}%   %straight line
    }%
  %{\color{green}\qbezier(40,16)(60,40)(80,64)}     %straight line
\end{picture}
\end{footnotesize}
\end{center}
\caption{
  $\rvY=\ff(\rvX)$
  \label{fig:YfX}
  }
\end{figure}

%---------------------------------------
\begin{example}
%---------------------------------------
Suppose we have a random generator that yields a value $\rvX$ with
\prope{uniform distribution}.
Design a function $\ff(x)$ such that $\rvY\eqd\ff(\rvX)$ has distribution
\\\indentx$\ds\ppy(y) \eqd \brbl{\begin{array}{lM}
                              \frac{1}{2} & for $y\in\intoc{1}{3}$\\
                              0           & otherwise
                            \end{array}}$
\exbox{
  \ff(x) \eqd 2x + 1
  \qquad\implies\qquad
  \rvY \eqd \ff(\rvX)\qquad\text{has distribution $\ppy(y)$}
}

Moreover, here's some R code demonstrating the concept:
\begin{lstlisting}[language=R]
N = 1e6                                                       # Number of samples
X = runif( n=N, min=0, max=1 )                                # X = Uniformly distributed RV
Y = 2 * X + 1                                                 # Y = f( X )
plot( X, Y, ylim=c(0,3), col="red" )                          # plot X -> Y mapping
plot( density( Y, bw="SJ" ), lwd=3, xlim=c(0,4), col="blue" ) # plot estimated pdf of Y
\end{lstlisting}
\end{example}
\begin{proof}
\begin{enumerate}
  \item The \fncte{cumulative distribution function} $\pcy(y)$ of $\rvY$ with desired pdf $\ppy(y)$ is
    \begin{align*}
      \pcy(y)
        &  \eqd \int_{-\infty}^y \ppy(u) \du
        &&    \text{by definition of cdf} &&\text{\xref{def:cdf}}
      \\&  \eqd \int_{-\infty}^y \brb{\begin{array}{lM}
                                        \frac{1}{2} & for $u\in\intcc{1}{3}$\\
                                        0           & otherwise
                                      \end{array}} \du
        &&    \text{by definition of $\ppy(y)$}
      \\&= \brb{\begin{array}{lM}
             0            & for $y\le1$\\
             \frac{1}{2}y & for $1<y\le 3$\\
             1            & otherwise
           \end{array}}
    \end{align*}

  \item The inverse cdf $\pcy^{-1}(x)$ is
    $\ds\pcy^{-1}(x) = \brbl{\begin{array}{lMM}
                               \intcc{0}{1} & for $x=0$     & (undefined but in $\intcc{0}{1}$)\\
                               2x + 1       & for $0<x\le 1$\\
                               $undefined$  & otherwise
                             \end{array}}$

  \item Since we are using $\pcy^{-1}(x)$ with $\rvX$ which only yields values of non-zero probablity in $\intoc{0}{1}$ \xref{def:uniform},
        we can simplify $\ff(x)$ to
        only necessarily match $\pcy^{-1}$ in the domain $\intoc{0}{1}$, and be whatever is convenient elsewhere.
        As such, let $\ds \ff(x) \eqd 2x + 1$.

  \item By the \thme{Inverse probability integral transform} \xref{thm:its}, $\rvY\eqd\ff(\rvX)\eqd 2\rvX + 1$ has the
        desired pdf $\ppy(y)$.
\end{enumerate}
\end{proof}

%---------------------------------------
\begin{definition}
\footnote{
  \citerpgc{callahan2010}{189}{144197332X}{Definition 6.1}
  }
\label{def:cp}
%---------------------------------------
Let $\ff(x)$ be a \structe{differentiable function} in $\clFrr$.
\defboxt{
  A point $p\in\R$ is a \propd{critical point} of $\ff(x)$ if
  \\\indentx$\ffp(p)=0$.
  }
\end{definition}

%---------------------------------------
\begin{theorem}
\footnote{
  \citerppgc{papoulis1984}{95}{96}{0070484686}{``Fundamental Theorem"},
  \citerpgc{papoulis1990}{157}{0137116985}{``Fundamental Theorem"},
  \citerp{papoulis}{93},
  \citerpgc{haykin1994}{235}{239}{0471571768}{\textsection ``{\scshape 4.5 Transformations of Random Variables}"},
  \citerp{proakis}{30},
  }
\label{thm:YfX}
%---------------------------------------
Let $\rvX$ and $\rvY$ be \fncte{random variable}s in $\clFrr$.
Let $\ff$ be a \structe{differentiable function} in $\clFrr$
with $\xN$ \prope{critical point}s \xref{def:cp}.
Let the range of $\rvX$ be partitioned into $\xN+1$ partitions
$\set{\setA_n}{n=1,2,\ldots,\xN+1}$
with partition boundaries set at the $\xN$ \structe{critical point}s of $\ff(x)$%
---as illustrated in \prefpp{fig:YfX}.
Let $\fg_n(x)\eqd\ff(x)$ but with domain restricted to $x\in\setA_n$.
\thmbox{
  \brb{\begin{array}{FMD}
    (1).&$\rvY=\ff(\rvX)$  & and \\
    (2).&$\ff$ is \prope{differentiable}
  \end{array}}
  \implies
  \brb{\ppy(y) = \sum_{n=1}^{\xN+1} \frac{\ppx\brp{\fgi_n(y)}}{\abs{\ffp\brp{\fgi_n(y)}}}}
  }
\end{theorem}
\begin{proof}
\begin{enumerate}
  \item \label{item:YfX_gn}
        The problem with a function $\ff(x)$ with at least $\xN=1$ critical point is that
        $\ffi(y)$ is \prope{not invertible}.
        That is,
        $\ffi(y)$ has more than one solution (and thus the \structe{relation} $\ffi(y)$ is not a \structe{function}).
        However, note that in each partition $\setA_n$, $\ff(x)$ is \prope{invertible} and thus
        $\ffi(y)$ in that partition has a \prope{unique} solution.
        Thus, each $\fg_n(x)$ \emph{is} \prop{invertible} in it's domain (and each $\fgi_n(y)$ exists as a function).

  %\item lemma. \label{ilem:YfX_ffp}  \label{ilem:YfX_dygi}
  %  \\\indentx$\ds
  %    \lim_{\varepsilon\to0} \fgi_n(y+\varepsilon)
  %       = \lim_{\varepsilon\to0}\brs{\fgi_n(y) + \left.\Delta y\frac{1}{\dy/\dx}\right|_{x=\fgi_n(y)}}
  %       = \lim_{\varepsilon\to0}\brs{\fgi_n(y) + \frac{\varepsilon}{\ffp\brs{\fgi_n(y)}}}
  %      $

  \item Using \pref{item:YfX_gn}, the remainder of the proof follows \ldots
    \begin{align*}
      \ppy(y)
        &\eqd \ddy\psp\setn{\rvY \le y}
        && \text{by definition of $\ppy$ \xref{def:pdf}}
      \\&= \ddy\psp\setn{\ff(\rvX)\le y}
        && \text{by hypothesis (1)}
      \\&= \ddy\sum_{n=1}^{\xN+1} \psp\set{\ff(\rvX)\le y}{\rvX\in\setA_n}
        && \text{by \thme{sum of products} \xref{thm:psp_sop}}
      \\&= \ddy\sum_{n=1}^{\xN+1} \pPc{\ff(\rvX)\le y}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}
        && \text{by definition of $\psp\setn{\setX|\setY}$ \xref{def:conP}}
      \\&= \ddy\sum_{n=1}^{\xN+1} \pPc{\fg_n(\rvX)\le y}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}
        && \text{by definition of $\fg_n(x)$}
      \\&= \mathrlap{\ddy\brb{\begin{array}{>{\ds}lM}
            \sum_{n=1}^{\xN+1} \pPc{\rvX \le \fgi_n(y)}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n} & for $\ffp(x)\ge0$ \\
            \sum_{n=1}^{\xN+1} \pPc{\rvX \ge \fgi_n(y)}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n} & otherwise
           \end{array}}\quad\text{by \pref{item:YfX_gn}}}
      \\&= \mathrlap{\ddy\brb{\begin{array}{>{\ds}lM}
            \sum_{n=1}^{\xN+1} \pPc{\rvX \le \fgi_n(y)}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}          & for $\ffp(x)\ge0$ \\
            \sum_{n=1}^{\xN+1} \brs{1-\pPc{\rvX \le \fgi_n(y)}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}}  & otherwise
           \end{array}}}
      \\&= \mathrlap{\ddy\brb{\begin{array}{>{\ds}lM}
            \sum_{n=1}^{\xN+1} \psp\set{\rvX \le \fgi_n(y)}{\rvX\in\setA_n}          & for $\ffp(x)\ge0$ \\
            \sum_{n=1}^{\xN+1} \brs{1-\psp\set{\rvX \le \fgi_n(y)}{\rvX\in\setA_n}}  & otherwise
           \end{array}}\quad\text{by definition of $\psp\setn{\setX|\setY}$}}
      \\&= \mathrlap{\ddy\brb{\begin{array}{>{\ds}lM}
            \sum_{n=1}^{\xN+1} \brp{\psp\setn{\rvX \le \fgi_n(y)}-\psp\setn{\rvX < \min\setA_{n-1}}}        & for $\ffp(x)\ge0$ \\
            \sum_{n=1}^{\xN+1} \brs{1-\brp{\psp\setn{\rvX \le \fgi_n(y)}-\psp\setn{\rvX<\min\setA_{n-1}}}}  & otherwise
           \end{array}}}
      \\&= \ddy\brb{\begin{array}{>{\ds}lM}
            \sum_{n=1}^{\xN+1} \psp\setn{\rvX \le \fgi_n(y)}          & for $\ffp(x)\ge0$ \\
            \sum_{n=1}^{\xN+1} \brs{1-\psp\setn{\rvX \le \fgi_n(y)}}  & otherwise
           \end{array}}
        && \text{because $\ddy\psp\setn{\rvX<\text{a constant}}=0$}
      \\&= \brb{\begin{array}{>{\ds}lM}
            \sum_{n=1}^{\xN+1} \ddy\pcx\brs{\fgi_n(y)}         & for $\ffp(x)\ge0$ \\
            \sum_{n=1}^{\xN+1} \ddy\brs{1-\pcx\brp{\fgi_n(y)}} & otherwise
           \end{array}}
        && \text{by \prope{linearity} of $\ddy$ operator}
      \\&= \brb{\begin{array}{>{\ds}lM}
            \sum_{n=1}^{\xN+1}       \ppx\brs{\fgi_n(y)}\ddy\brs{\fgi_n(y)}   & for $\ffp(x)\ge0$ \\
            \sum_{n=1}^{\xN+1} \brs{-\ppx\brs{\fgi_n(y)}\ddy\brs{\fgi_n(y)}}  & otherwise
           \end{array}}
        && \text{\begin{tabular}[t]{@{}l}by definition of $\ppx$ \xref{def:pdf}\\and the \thme{chain rule}\end{tabular}}
      \\&= \sum_{n=1}^{\xN+1} \ppx\brp{\fgi_n(y)}\abs{\ddy\brs{\fgi_n(y)}}
      \\&= \sum_{n=1}^{\xN+1} \frac{\ppx\brp{\fgi_n(y)}}{\abs{\ffp\brp{\fgi_n(y)}}}
        && \text{by \prefp{lem:ddyffi}}
    \end{align*}

  %\item
  %  \begin{align*}
  %    &\ppy(y)
  %    \\&\eqd \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\psp\setn{y \le Y < y+\varepsilon}
  %      && \text{by def. of $\ppy$ \xref{def:pdf}}
  %    \\&= \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\psp\setn{y \le \ff(\rvX)< y+\varepsilon}
  %      && \text{by hypothesis}
  %    \\&= \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\sum_{n=1}^{\xN+1} \psp\set{y \le \ff(\rvX)< y+\varepsilon}{\rvX\in\setA_n}
  %      && \text{by \thme{sum of products} \xref{thm:psp_sop}}
  %    \\&= \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\sum_{n=1}^{\xN+1} \pPc{y \le \ff(\rvX)< y+\varepsilon}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}
  %      && \text{by def. of $\psp\setn{\setX|\setY}$ \xref{def:conP}}
  %    \\&= \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\sum_{n=1}^{\xN+1} \pPc{y \le \fg_n(\rvX)< y+\varepsilon}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}
  %      && \text{by def. of $\fg_n(x)$}
  %    \\&= \mathrlap{\lim_{\varepsilon\to0}\frac{1}{\varepsilon}\brs{\begin{array}{>{\ds}lM}
  %          \sum_{n=1}^{\xN+1} \pPc{\fgi_n(y) \le\rvX < \fgi_n(y+\varepsilon)}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n} & for $\ffp(x)\ge0$ \\
  %          \sum_{n=1}^{\xN+1} \pPc{\fgi_n(y+\varepsilon) \le\rvX < \fgi_n(y)}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n} & otherwise
  %         \end{array}}\quad\text{(by \pref{item:YfX_gn}}}
  %    \\&= \mathrlap{\lim_{\varepsilon\to0}\frac{1}{\varepsilon}\brs{\begin{array}{>{\ds}lM}
  %           \sum_{n=1}^{\xN+1} \pPc{\fgi_n(y)     \le\rvX < \fgi_n(y) + \frac{\varepsilon}{\ffp\brs{\fgi_n(y)}}}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n} & for $\ffp(x)\ge0$ \\
  %           \sum_{n=1}^{\xN+1} \pPc{\fgi_n(y) + \frac{\varepsilon}{\ffp\brs{\fgi_n(y)}} \le\rvX < \fg_n(y)}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}     & otherwise
  %         \end{array}}\quad\text{by \pref{ilem:YfX_ffp}}}
  %    \\&= \mathrlap{\lim_{\varepsilon\to0}\frac{1}{\varepsilon}\sum_{n=1}^{\xN+1} \pPc{\fgi_n(y) \le\rvX < \fgi_n(y) + \frac{\varepsilon}{\abs{\ffp\brp{\fgi_n(y)}}}}{\rvX\in\setA_n}\psp\setn{\rvX\in\setA_n}}
  %    \\&= \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\sum_{n=1}^{\xN+1} \psp\set{\fgi_n(y) \le\rvX < \fgi_n(y) + \frac{\varepsilon}{\abs{\ffp\brp{\fgi_n(y)}}}}{\rvX\in\setA_n}
  %      && \text{by def. of $\psp\setn{\setX|\setY}$ \xref{def:conP}}
  %    \\&= \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\sum_{n=1}^{\xN+1} \psp\setn{\fgi_n(y) \le\rvX < \fgi_n(y) + \frac{\varepsilon}{\abs{\ffp\brp{\fgi_n(y)}}}}
  %      && \text{by def. of \structe{partition} \xref{def:partition}}
  %    \\&= \lim_{\varepsilon\to0}\frac{1}{\varepsilon}\sum_{n=1}^{\xN+1} \frac{\varepsilon}{\abs{\ffp\brp{\fgi_n(y)}}} \ppx\brs{\fgi_n(y)}
  %      && \text{by def. of $\ppx$ \xref{def:pdf}}
  %    \\&= \sum_{n=1}^{\xN+1} \frac{\ppx\brp{\fgi_n(y)}}{\abs{\ffp\brp{\fgi_n(y)}}}
  %      && \text{by \prope{linearity} of $\sum$ operator}
  %  \end{align*}
\end{enumerate}
\end{proof}

%---------------------------------------
\begin{corollary}
\footnote{
  \citerpgc{papoulis1984}{96}{0070484686}{``Illustrations" 1},
  \citerp{papoulis}{95},
  \citerp{proakis}{29}
  }
\label{cor:YaXb}
%---------------------------------------
Let $\rvX$ and $\rvY$ be \fncte{random variable}s in $\clFrr$.
Let $a,b\in\R$.
\corbox{
  \brb{\begin{array}{FlCD}
    (1).&\rvY=a\rvX+b & and \\
    (2).&a\neq0       &
  \end{array}}
  \implies
  \brb{
  \ppy(y) = \frac{1}{\abs{a}} \ppx\brp{\frac{y-b}{a}}}
  }
\end{corollary}
\begin{proof}
%\begin{enumerate}
%  \item This follows from \prefpp{thm:YfX}:
    \begin{enumerate}
      \item \label{item:YaXb_ffp}
            Note that $\ff(x)=ax+b$ is a \prope{differentiable function} with $\xN=0$ \prope{critical point}s
            and $\ffp(x)=a$.
      \item \label{item:YaXb_ffi}
            The inverse of $\ff(x)$ is $\fg_1(y)=\ffi(y)=\frac{y-b}{a}$.
      \item It follows that
        \begin{align*}
          \ppy(y)
            &= \sum_{n=1}^{\xN+1} \frac{\ppx\brp{\fgi_n(y)}}{\abs{\ff'\brp{\fgi_n(y)}}}
            && \text{by \prefpp{thm:YfX}}
          \\&= \frac{\ppx\brp{\ffi(y)}}{\abs{\ff'\brp{\ffi(y)}}}
            && \text{because $\xN=0$}
          \\&= \frac{\ppx\brp{\ffi(y)}}{\abs{a}}
            && \text{by \pref{item:YaXb_ffp}}
          \\&= \frac{1}{\abs{a}}\ppx\brp{\frac{y-b}{a}}
            && \text{by \pref{item:YaXb_ffi}}
        \end{align*}
    \end{enumerate}

  %\item An alternative proof is as follows:
  %  \begin{align*}
  %    \ppy(y)h
  %      &=  \psp\setn{y\le Y < y+h}
  %    \\&=  \psp\setn{y\le a\rvX+b < y+h}
  %    \\&=  \psp\setn{y-b\le a\rvX < y-b+h}
  %    \\&=  \left\{\begin{array}{ll}
  %            \psp\setn{\frac{y-b}{a}\le\rvX < \frac{y-b}{a}+\frac{1}{a}h} &\forall a>0 \\
  %            \psp\setn{\frac{y-b}{a}\ge\rvX > \frac{y-b}{a}+\frac{1}{a}h} &\forall a<0
  %          \end{array}\right.
  %    \\&=  \left\{\begin{array}{ll}
  %            \psp\setn{\frac{y-b}{a}\le\rvX < \frac{y-b}{a}+\frac{1}{|a|}h}  &\forall a>0 \\
  %            \psp\setn{\frac{y-b}{a}-\frac{1}{|a|}h <\rvX \le \frac{y-b}{a}} &\forall a<0
  %          \end{array}\right.
  %    \\&=  \frac{1}{|a|}h \ppx\left(\frac{y-b}{a}\right)
  %  \\\implies
  %  \\
  %    \ppy(y)
  %      &=  \frac{1}{|a|} \ppx\left(\frac{y-b}{a}\right)
  %  \end{align*}
%\end{enumerate}
\end{proof}


\begin{figure}\color{figcolor}
\setlength{\unitlength}{0.3mm}
\thicklines
\begin{center}
%\begin{footnotesize}
\begin{picture}(350,200)(-100,-20)
  {\color{axis}%
    \put( -20,   0){\line(1,0){220}}
    \put(   0, -20){\line(0,1){120}}
    }
  \put(   0, 110){\makebox(0,0)[r]{$y$}}
  \put( 210,   0){\makebox(0,0)[r]{$x$}}
  {\color{red}
%    \qbezier(10,140)(60,10)(160,10)
    \qbezier(20,150)(30,30)(150,20)
    \put( 35, 105){\makebox(0,0)[l]{$y=\frac{1}{x}$}}
    }
  {\color{blue}% f(x)
    \put(40,80){\line(1,-1){40}} %straight line
    }
  {\color{black}% f(x)
    \qbezier[28](0,80)(20,80)(40,80)
    \qbezier[50](40,0)(40,40)(40,80)
    \qbezier[40](0,40)(40,40)(80,40)
    \qbezier[20](80,0)(80,20)(80,40)
    }
  \put(  -5,  80){\makebox(0,0)[r]{$y+h$}}
  \put(  -5,  40){\makebox(0,0)[r]{$y$}}
  \put(  40,  -5){\makebox(0,0)[t]{$\frac{1}{y+h}$}}
  \put(  80,  -5){\makebox(0,0)[t]{$\frac{1}{y}$}}
  \put( 100,  60){\makebox(0,0)[l]{$\frac{\Delta y}{\Delta x}=\left.\frac{\dy}{\dx}\right|_{x=\frac{1}{y}}=-y^2$}}
  \put(  95,  60){\vector(-1,0){35}}
  \put( 100,  40){\makebox(0,0)[l]{$\frac{1}{y}+\frac{\Delta x}{\Delta y}\Delta y = \frac{1}{y} - \frac{1}{y^2}h$}}
  \put(  95,  40){\vector(-3,-2){55}}
\end{picture}
%\end{footnotesize}
\end{center}
\caption{
  $\rvY=\frac{1}{\rvX}$
  \label{fig:Y=1/X}
  }
\end{figure}
%---------------------------------------
\begin{corollary}
\footnote{
  \citerpgc{papoulis1984}{97}{0070484686}{Example 5-10},
  \citerp{papoulis}{94}
  }
\label{cor:Yf1X}
%---------------------------------------
\corbox{
  \brb{\rvY=\frac{1}{\rvX}}
  \implies
  \brb{\ppy(y) = \begin{array}{lM}
     %                                             & for $y<0$ \\
     %0                                            & for $y=0$ \\
     \frac{1}{y^2} \ppx\left( \frac{1}{y} \right) & for $y>0$
  \end{array}}
  }
\end{corollary}
\begin{proof}
\begin{enumerate}
  \item \label{item:Yf1X_ffp}
        Note that $\ff(x)=1/x$ is a \prope{differentiable function} in $x>0$
        with $\xN=0$ \prope{critical point}s
        and $\ffp(x)=-1/x^2$.
  \item \label{item:Yf1X_ffi}
        The inverse of $\ff(x)$ is $\fg_1(y)=\ffi(y)=\frac{1}{y}$.
  \item It follows that
    \begin{align*}
      \ppy(y)
        &= \sum_{n=1}^{\xN+1} \frac{\ppx\brp{\fgi_n(y)}}{\abs{\ff'\brp{\fgi_n(y)}}}
        && \text{by \prefpp{thm:YfX}}
      \\&= \frac{\ppx\brp{\ffi(y)}}{\abs{\ff'\brp{\ffi(y)}}}
        && \text{because $\xN=0$}
      \\&= \frac{1}{\abs{-1/(1/y)^2}}\ppx\brp{\frac{1}{y}}
      \\&= \frac{1}{y^2}\ppx\brp{\frac{1}{y}}
    \end{align*}
\end{enumerate}
%\begin{enumerate}
%  \item This follows from \prefpp{thm:YfX}:
%    \begin{enumerate}
%      \item The only root of $y=\sfrac{1}{x}$ is $x_1=\sfrac{1}{y}$.
%      \item $\ff'(x) = -\frac{1}{x^2}$
%      \item Then
%        $\ds
%          \ppy(y)
%            = \sum_{n=1}^\xN \frac{\ppx(x_n)}{\abs{\ff'(x_n)}}
%            = \frac{\ppx(x_1)}{|\ff'(x_1)|}
%            = \frac{\ppx(1/y)}{|\ff'(1/y)|}
%            = \frac{\ppx(1/y)}{y^2}
%            = \frac{1}{y^2} \ppx\left( \frac{1}{y} \right)
%        $
%    \end{enumerate}
%
%%  \item Alternatively, this can be proved as follows:
%%    \begin{enumerate}
%%      \item lemma. \label{item:Yf1X}
%%        Let $h\to0$. First we show a useful relation for $\frac{1}{y+h}$.
%%        This relation is illustrated in \prefpp{fig:Y=1/X}.
%%        \begin{align*}
%%          \frac{1}{y+h}
%%            &=    y_1 + \frac{1}{m} \Delta y
%%          \\&=    \frac{1}{y} + \left.\frac{1}{dy/dx}\right|_{x=1/y} h
%%          \\&=    \frac{1}{y} - \left.x^2\right|_{x=1/y} h
%%          \\&=    \frac{1}{y} - \frac{1}{y^2} h
%%        \end{align*}
%%
%%      \item Now we prove the theorem with some help from \pref{item:Yf1X}:
%%        \begin{align*}
%%          \ppy(y)h
%%            &=    \psp\setn{y\le Y < y+h}
%%          \\&=    \psp\setn{y\le \frac{1}{\rvX} < y+h}
%%          \\&=    \psp\setn{\frac{1}{y}\ge\rvX > \frac{1}{y+h}}
%%          \\&=    \psp\setn{\frac{1}{y}\ge\rvX > \frac{1}{y}-\frac{1}{y^2}h}
%%          \\&=    \psp\setn{\frac{1}{y}-\frac{1}{y^2}h < \rvX \le \frac{1}{y} }
%%          \\&=    \frac{1}{y^2}h \ppx\left( \frac{1}{y} \right)
%%        \\\implies
%%          \ppy(y)
%%            &=    \frac{1}{y^2} \ppx\left( \frac{1}{y} \right)
%%        \end{align*}
%%    \end{enumerate}
%%\end{enumerate}
\end{proof}





\begin{figure}\color{figcolor}
\setlength{\unitlength}{0.3mm}
\thicklines
\begin{center}
\begin{footnotesize}
\begin{picture}(250,150)(-100,-20)
  \put(-100,   0){\line(1,0){200}}
  \put(   0, -20){\line(0,1){120}}
  {\color{red}
    \qbezier(-100,100)(0,-100)(100,100)
    \put( 100, 105){\makebox(0,0)[b]{$y=x^2$}}
    }
  \qbezier[8](-40,0)(-40,8)(-40,16)
  \qbezier[8](40,0)(40,8)(40,16)
  \qbezier[28](-80,0)(-80,32)(-80,64)
  \qbezier[28](80,0)(80,32)(80,64)
  \qbezier[64](-80,64)(0,64)(80,64)
  \qbezier[40](-40,16)(0,16)(40,16)
  \put(   0, 110){\makebox(0,0)[r]{$y$}}
  \put( 110,   0){\makebox(0,0)[r]{$x$}}
  \put(  -5,  64){\makebox(0,0)[r]{$y+h$}}
  \put(  -5,  16){\makebox(0,0)[r]{$y$}}
  \put( -40,  -5){\makebox(0,0)[t]{$-\sqrt{y}$}}
  \put(  40,  -5){\makebox(0,0)[t]{$\sqrt{y}$}}
  \put( -80,  -5){\makebox(0,0)[t]{$-\sqrt{y+h}$}}
  \put(  80,  -5){\makebox(0,0)[t]{$\sqrt{y+h}$}}
% \put(  80,  -5){\makebox(0,0)[t]{$\sqrt{y+h}\approx \sqrt{y} + \frac{1}{2\sqrt{y}}h$}}
  \put( 100,  40){\makebox(0,0)[l]{$\frac{\Delta y}{\Delta x}=\left.\frac{\dy}{\dx}\right|_{x=\sqrt{y}}=2\sqrt{y}$}}
  \put(  95,  40){\vector(-1,0){35}}
  \put(-100,  20){\makebox(0,0)[r]{$\sqrt{y}+\frac{\Delta x}{\Delta y}\Delta y = \sqrt{y} - \frac{1}{2\sqrt{y}}h$}}
  \put( 100,  20){\makebox(0,0)[l]{$\sqrt{y}+\frac{\Delta x}{\Delta y}\Delta y = \sqrt{y} + \frac{1}{2\sqrt{y}}h$}}
  \put( -95,  15){\vector( 1,-1){15}}
  \put(  95,  15){\vector(-1,-1){15}}
  \put(  40,  16){\line(5,6){40}}   %straight line
  \put( -40,  16){\line(-5,6){40}}   %straight line
  %{\color{green}\qbezier(40,16)(60,40)(80,64)}     %straight line
\end{picture}
\end{footnotesize}
\end{center}
\caption{
  $\rvY=rvX^2$
  \label{fig:Y=rvX^2}
  }
\end{figure}
%---------------------------------------
\begin{corollary}
\footnote{
  \citerpgc{papoulis1984}{95}{0070484686}{Example 5-9},
  \citerpgc{devroye1986}{27}{0387963057}{Example 4.4},
  \citerp{papoulis}{95},
  \citerp{proakis}{29}
  }
\label{cor:YX2}
%---------------------------------------
Let $\rvX$ and $\rvY$ be \fncte{random variable}s.
\corbox{
  \brb{\rvY=\rvX^2}
  \implies
  \brb{\ppy(y) = \frac{1}{2\sqrt{y}} \brs{\ppx(-\sqrt{y}) + \ppx( \sqrt{y})}}
  }
\end{corollary}
\begin{proof}
%\begin{enumerate}
%  \item The theorem can also be proved using \prefpp{thm:YfX}:
    \begin{enumerate}
      \item The roots of $y=x^2$ are $x_1=-\sqrt{y}$ and $x_2=+\sqrt{y}$. \label{item:YX2_roots}
      \item The derivative of $\ff(x)\eqd y=x^2$ is $\ff'(x)=2x$. \label{item:YX2_derivative}
      \item And so it follows that \ldots
        {\begin{align*}
          \ppy(y)
            &= \sum_{n=1}^\xN \frac{\ppx(x_n)}{\abs{\ff'(x_n)}}
            && \text{by \prefp{thm:YfX}}
          \\&= \frac{\ppx(x_1)}{|\ff'(x_1)|} + \frac{\ppx(x_2)}{|\ff'(x_2)|}
            && \text{by definition of $\sum$}
          \\&= \frac{\ppx(-\sqrt{y})}{|\ff'(-\sqrt{y})|} + \frac{\ppx(\sqrt{y})}{|\ff'(\sqrt{y})|}
            && \text{by \pref{item:YX2_roots}}
          \\&= \frac{\ppx(-\sqrt{y})}{2\sqrt{y}} + \frac{\ppx(\sqrt{y})}{2\sqrt{y}}
            && \text{by \pref{item:YX2_derivative}}
          \\&=    \left.\left.\frac{1}{2\sqrt{y}}\right[
                  \ppx(-\sqrt{y}) + \ppx( \sqrt{y}) \right]
            && \text{by \prope{linearity} of $+$ operation}
        \end{align*}}
    \end{enumerate}

%  \item Alternatively
%    \begin{enumerate}
%      \item Let $h\to0$.
%      \item lemma. First we show a useful relation for $\sqrt{y+h	}$.
%            This relation is illustrated in \prefpp{fig:Y=rvX^2}.
%            \begin{align*}
%              \sqrt{y+h}
%                &=    y_1 + \frac{1}{m} \Delta y
%              \\&=    \sqrt{y} + \left.\frac{1}{dy/dx}\right|_{x=\sqrt{y}} h
%              \\&=    \sqrt{y} + \left.\frac{1}{2x}\right|_{x=\sqrt{y}} h
%              \\&=    \sqrt{y} + \frac{1}{2\sqrt{y}} h
%            \end{align*}
%
%      \item Now, using the above relation, we have
%            \begin{align*}
%              \ppy(y)h
%                &= \psp\setn{y\le Y < y+h}
%              \\&= \psp\setn{y\le X^2 < y+h}
%              \\&= \psp\setn{(y\le X^2 < y+h) \land (\rvX<0)}+ \psp\setn{(y\le X^2 < y+h) \land (\rvX\ge0)}
%              \\&= \psp\setn{y\le X^2 < y+h | X<0}\psp\setn{\rvX<0} + \psp\setn{y\le X^2 < y+h | X\ge0}\psp\setn{\rvX\ge0}
%              \\&= \psp\setn{-\sqrt{y}\le\rvX < -\sqrt{y+h} | X<0  } \psp\setn{\rvX<0} +
%                   \psp\setn{+\sqrt{y}\le\rvX < +\sqrt{y+h} | X\ge0} \psp\setn{\rvX\ge0}
%              \\&= \psp\setn{-\sqrt{y}\le\rvX < -\left(\sqrt{y}+\frac{1}{2\sqrt{y}}h\right) \land X<0   } +
%                   \psp\setn{+\sqrt{y}\le\rvX <        \sqrt{y}+\frac{1}{2\sqrt{y}}h        \land X\ge0 }
%              \\&= \psp\setn{-\sqrt{y}\le\rvX < -\left(\sqrt{y}+\frac{1}{2\sqrt{y}}h\right)  } +
%                   \psp\setn{+\sqrt{y}\le\rvX <        \sqrt{y}+\frac{1}{2\sqrt{y}}h         }
%              \\&= \frac{1}{2\sqrt{y}}h\ppx(-\sqrt{y})  +
%                   \frac{1}{2\sqrt{y}}h\ppx( \sqrt{y})
%            \\\implies
%              \ppy(y)
%                &=    \left.\left.\frac{1}{2\sqrt{y}}\right[
%                       \ppx(-\sqrt{y}) + \ppx( \sqrt{y}) \right]
%            \end{align*}
%  \end{enumerate}
%\end{enumerate}
\end{proof}




\begin{figure}\color{figcolor}
\setlength{\unitlength}{0.15mm}
\thicklines
\begin{center}
\begin{footnotesize}
\begin{picture}(1000,220)(-500,-100)
  \put(-500,   0){\line(1,0){1000}}
  \put(   0, -100){\line(0,1){220}}
  \multiput(-400,0)(200,0){5}{
    {\color{red}
      \qbezier(0,0)(25,25)(50,37)
      \qbezier(50,37)(75,50)(95,100)
      \qbezier(0,0)(-25,-25)(-50,-37)
      \qbezier(-50,-37)(-75,-50)(-95,-100)
      }
    \qbezier[14](77,0)(77,32)(77,64)
    }
  \put( 100, 105){\makebox(0,0)[b]{$z=\atan\theta$}}
  \put(-400,-5){\makebox(0,0)[t]{$-2\pi$}}
  \put(-200,-5){\makebox(0,0)[t]{$- \pi$}}
  \put( 200,-5){\makebox(0,0)[t]{$  \pi$}}
  \put( 400,-5){\makebox(0,0)[t]{$ 2\pi$}}

  \put(-323,-5){\makebox(0,0)[t]{$\theta_{-2}$}}
  \put(-123,-5){\makebox(0,0)[t]{$\theta_{-1}$}}
  \put(  77,-5){\makebox(0,0)[t]{$\theta_{ 0}$}}
  \put( 277,-5){\makebox(0,0)[t]{$\theta_{ 1}$}}
  \put( 477,-5){\makebox(0,0)[t]{$\theta_{ 2}$}}

  \qbezier[130](-315,64)(77,64)(477,64)
  \put(   0, 110){\makebox(0,0)[r]{$z$}}
  \put( 520,   0){\makebox(0,0)[l]{$\theta$}}
\end{picture}
\end{footnotesize}
\end{center}
\caption{
  $\rvZ=\tan\Theta$
  \label{fig:Z=tan0}
  }
\end{figure}
%---------------------------------------
\begin{corollary}
\footnote{
  \citerpp{papoulis}{99}{100}
  }
\label{cor:ppztan}
%---------------------------------------
Let $\rvZ=\tan\Theta$. Then
\corbox{
  \brb{\rvZ=\tan\Theta}
  \quad\implies\quad
  \brb{\ppz(z) = \frac{1}{1+z^2}  \sum_{n\in\rvZ} \ppth(\atan(z)+n\pi)}
  }
\end{corollary}
\begin{proof}
%\begin{enumerate}
%  \item The theorem can also be proved using \prefpp{thm:YfX}:
    \begin{enumerate}
      \item The roots of $z=\tan\theta$ are $\set{\theta_n=\atan{z}+n\pi}{n\in\Z}$. \label{item:ppztan_roots}
      \item The derivative of $z=\tan\theta$ is  $\ff'(\theta)=\sec^2 \theta$. \label{item:ppztan_derivative}
      \item It follows that
        \begin{align*}
          \ppz(z)
            &= \sum_{n=1}^\xN \frac{\ppth(\theta_n)}{|\ff'(\theta_n)|}
          \\&= \sum_n \frac{\ppth(\atan{z}+n\pi)}{|\ff'(\atan{z}+n\pi)|}
          \\&= \sum_n \frac{\ppth(\atan{z}+n\pi)}{|\sec^2(\atan{z}+n\pi)|}
          \\&= \sum_n \cos^2(\atan{z}+n\pi)  \ppth(\atan{z}+n\pi)
          \\&= \cos^2(\atan{z}) \sum_n  \ppth(\atan{z}+n\pi)
          \\&= \frac{1}{1+z^2}  \sum_n \ppth(\atan{z}+n\pi)
        \end{align*}
    \end{enumerate}

%  \item Alternatively \ldots
%    \begin{enumerate}
%      \item Let $z=\frac{y}{x}$ and $x^2 + y^2 = r^2$.
%            \begin{align*}
%              \cos^2\atan z
%                &= \cos^2\theta
%                 = \frac{x^2}{r^2}
%                 = \frac{x^2}{x^2+y^2}
%                 = \frac{\frac{x^2}{x^2}}{\frac{x^2}{x^2}+\frac{y^2}{x^2}}
%                 = \frac{1}{1+z^2}
%            \end{align*}
%      \item Let $h\to0$.
%            \begin{align*}
%              \atan{z+h}
%                &= y_1 + \frac{1}{m} \Delta y
%              \\&= \atan{z} + \left.\frac{1}{\dz/\dth}\right|_{\theta=\atan{z}} h
%              \\&= \atan{z} + \left.\frac{1}{\sec^2\theta}\right|_{\theta=\atan{z}} h
%              \\&= \atan{z} + \left.\cos^2\theta\right|_{\theta=\atan{z}} h
%              \\&= \atan{z} + h\cos^2\atan{z}
%              \\&= \atan{z} + h\frac{1}{1+z^2}
%            \end{align*}
%
%      \item Now we prove the theorem using the above relation.
%            \begin{align*}
%              \ppz(z)h
%                &= \psp\setn{z\le Z < z+h}
%              \\&= \psp\setn{z\le \tan\Theta < z+h}
%              \\&= \sum_n \psp\setn{z\le \tan\Theta < z+h \land
%                          \pi\left(n-\frac{1}{2}\right) \le \Theta < \pi\left(n+\frac{1}{2}\right)
%                          }
%              \\&= \sum_n \psp\setn{z\le \tan\Theta < z+h \left|
%                          \pi\left(n-\frac{1}{2}\right) \le \Theta < \pi\left(n+\frac{1}{2}\right)
%                          \right.}
%                          \psp\setn{\pi\left(n-\frac{1}{2}\right) \le \Theta \pi\left(n+\frac{1}{2}\right)}
%              \\&= \sum_n \psp\setn{\atan{z}+n\pi \le \Theta < \atan(z+h)+n\pi \left|
%                          \pi\left(n-\frac{1}{2}\right) \le \Theta < \pi\left(n+\frac{1}{2}\right)
%                          \right.}
%                          \psp\setn{\pi\left(n-\frac{1}{2}\right) \le \Theta \pi\left(n+\frac{1}{2}\right)}
%              \\&= \sum_n \psp\setn{\atan{z}+n\pi \le \Theta < \atan(z+h)+n\pi \land
%                          \pi\left(n-\frac{1}{2}\right) \le \Theta < \pi\left(n+\frac{1}{2}\right)
%                          }
%              \\&= \sum_n \psp\setn{\atan{z}+n\pi \le \Theta < \atan(z+h)+n\pi }
%              \\&= \sum_n \psp\setn{\atan{z}+n\pi \le \Theta < +\atan(z)+n\pi + h\frac{1}{1+z^2} }
%              \\&= h\frac{1}{1+z^2} \sum_n \ppth(\atan{z}+n\pi)
%            \\\implies
%              \ppz(z) &=  \frac{1}{1+z^2} \sum_n \ppth(\atan{z}+n\pi)
%            \end{align*}
%  \end{enumerate}
%\end{enumerate}
\end{proof}




%=======================================
\section{Functions of two random variables}
%=======================================
%---------------------------------------
\begin{theorem}
\footnote{
  \citerpgc{papoulis1990}{160}{0137116985}{Example 5.16}
  }
\label{thm:pdfconv}
%---------------------------------------
Let $\rvX$, $\rvY$, and $\rvZ$ be \fncte{random variable}s.
Let $\conv$ be the \ope{convolution} operator \xref{def:conv}.
\thmbox{
  \brb{\begin{array}{FMD}
    (1). & $\rvZ \eqd \rvX + \rvY$ & and \\
    (2). & $\rvX$ and $\rvY$ are \prope{independent} & \xref{def:independent}
  \end{array}}
  \implies
  \brb{\ppz(z) = \ppx(z)\conv\ppy(z)}
  }
\end{theorem}
\begin{proof}
\begin{align*}
  \ppz(z)
    &\eqd \ddz\pcz(z)
    &&    \text{by definition of $\ppz$} &&\text{\xref{def:pdf}}
  \\&\eqd \ddz\psp\setn{\rvZ \le z}
    &&    \text{by definition of $\pcz$} &&\text{\xref{def:cdf}}
  \\&=    \ddz\psp\setn{\rvX+\rvY \le z}
    &&    \text{by hypothesis (1)}
  \\&=    \ddz\lim_{\varepsilon\to0}\sum_{n\in\Z} \psp\set{\rvX+\rvY \le z}{y+n\varepsilon<\rvY\le y+(n+1)\varepsilon}
    &&    \text{by \thme{sum of products}}&&\text{\xref{thm:psp_sop}}
  %\\&=    \ddz\int_y \pPc{\rvX+y \le z}{y<\rvY\le y+\varepsilon}\psp\setn{y<\rvY\le y+\varepsilon} \dy
  %  &&    \text{by definiton of $\pPc{\rvX}{\rvY}$ \xref{def:conprob}}
  \\&=    \ddz\int_{y\in\R} \pPc{\rvX+\rvY \le z}{\rvY=y}\ppy(y) \dy
    &&    \text{by definiton of $\pPc{\rvX}{\rvY}$}&&\text{\xref{def:conprob}}
  \\&=    \ddz\int_{y\in\R} \pPc{\rvX \le z-y}{\rvY=y} \ppy(y) \dy
  \\&=    \ddz\int_{y\in\R} \psp\setn{\rvX \le z-y}\ppy(y) \dy
    &&    \text{by hypothesis (2)}
  \\&\eqd \ddz\int_{y\in\R} \pcx(z-y)\ppy(y) \dy
    &&    \text{by definition of $\pcx$}&&\text{\xref{def:cdf}}
  \\&=    \int_{y\in\R} \ddz\brs{\pcx(z-y)\ppy(y)} \dy
    &&    \text{by \prope{linearity} of $\ddz$}
  \\&=    \int_{y\in\R} \brs{\ddz\pcx(z-y)}\ppy(y) \dy
    &&    \mathrlap{\text{because $y$ is fixed inside the integral}}
  \\&\eqd \int_y \ppx(z-y) \ppy(y)  \dy
    &&    \text{by definition of $\ppx$}&&\text{\xref{def:pdf}}
  \\&=    \ppx(z) \conv \ppy(z)
    &&    \text{by definition of $\conv$}&&\text{\xref{def:conv}}
\end{align*}
%
%\begin{align*}
%  \ppz(z)
%    &\eqd \lim_{\varepsilon\to0}\frac{1}{\varepsilon} \psp\setn{z \le Z < z+\varepsilon }
%    &&    \text{by definition of $\ppz$ \xref{def:pdf}}
%  \\&=    \lim_{\varepsilon\to0}\frac{1}{\varepsilon} \psp\setn{z \le X+Y < z+\varepsilon }
%    &&    \text{by definition of $\rvZ$}
%  \\&=    \lim_{\varepsilon\to0}\frac{1}{\varepsilon} \int_y \psp\setn{(z \le X+y < z+\varepsilon) \land (y\le Y<y+\varepsilon) } \dy
%    &&    \text{by \thme{sum of products} \xref{thm:psp_sop}}
%  \\&=    \lim_{\varepsilon\to0}\frac{1}{\varepsilon} \int_y \psp\setn{(z-y \le\rvX < z-y+\varepsilon) | (y\le Y<y+\varepsilon) }\psp\setn{y\le Y<y+\varepsilon} \dy
%  \\&=    \lim_{\varepsilon\to0}\frac{1}{\varepsilon} \int_y \psp\setn{(z-y \le\rvX < z-y+\varepsilon) | Y=y }\psp\setn{y\le Y<y+\varepsilon} \dy
%  \\&=    \lim_{\varepsilon\to0}\frac{1}{\varepsilon} \int_y \psp\setn{(z-y \le\rvX < z-y+\varepsilon)}\psp\setn{y\le Y<y+\varepsilon} \dy
%    &&    \text{by \prope{independence} hypothesis}
%  \\&\eqd \int_y \ppx(z-y) \ppy(y)  \dy
%    &&    \text{by definition of $\ppx$ \xref{def:pdf}}
%  \\&=    \ppx(z) \conv \ppy(z)
%    &&    \text{by definition of $\conv$ \xref{def:conv}}
%\end{align*}
\end{proof}

\begin{figure}
  \centering%
  \Huge%
  \begin{tabular}{c>{\Huge}c c>{\Huge}c l}%
    \tboxc{\includegraphics{../common/math/graphics/pdfs/pdf_fairdie_blue.pdf}} &\tbox{+}&%
    \tboxc{\includegraphics{../common/math/graphics/pdfs/pdf_fairdie_red.pdf}}  &\tbox{=}&%
    \tboxc{\includegraphics{../common/math/graphics/pdfs/pdf_dicesum_bluered.pdf}}%
    \\
    \tboxc{\includegraphics{../common/math/graphics/pdfs/n0.pdf}}               &\tbox{+}&%
    \tboxc{\includegraphics{../common/math/graphics/pdfs/n0.pdf}}               &\tbox{=}&%
    \tboxc{\includegraphics{../common/math/graphics/pdfs/n1.pdf}}%
    \\
    \tboxc{\includegraphics{../common/math/graphics/pdfs/n0.pdf}}               &\tbox{+}&%
    \tboxc{\includegraphics{../common/math/graphics/pdfs/n1.pdf}}               &\tbox{=}&%
    \tboxc{\includegraphics{../common/math/graphics/pdfs/n2.pdf}}%
  \end{tabular}
  \caption{\opb{Sum} of random variables yields \opb{convolution} of pdfs \xref{thm:pdfconv}}
\end{figure}

%---------------------------------------
\begin{theorem}
\label{thm:x1x2->y1y2}
%---------------------------------------
Let
\begin{liste}
  \item $\rvX_1$ and $\rvX_2$ be random variables with joint distribution
        $\ppx[\rvX_1,\rvX_2](x_1,x_2)$
  \item $\rvY_1=\ff_1(x_1,x_2)$ and $\rvY_2=\ff_2(x_1,x_2)$
\end{liste}
Then the joint distribution of $\rvY_1$ and $\rvY_2$ is
\thmbox{
  \ppx[Y_1,Y_2](y_1,y_2)
    = \frac{\ppx[\rvX_1,\rvX_2](x_1,x_2)}{|J(x_1,x_2)|}
    = \frac{\ppx[\rvX_1,\rvX_2](x_1,x_2)}{
        \left|\begin{array}{cc}
          \pderiv{\ff_1}{x_1} & \pderiv{\ff_1}{x_2}   \\
          \pderiv{\ff_2}{x_1} & \pderiv{\ff_2}{x_2}
        \end{array}\right|
        }
    = \frac{\ppx[\rvX_1,\rvX_2](x_1,x_2)}{
        \pderiv{\ff_1}{x_1}\pderiv{\ff_2}{x_2} -
        \pderiv{\ff_1}{x_2}\pderiv{\ff_2}{x_1}
        }
  }
\end{theorem}

%---------------------------------------
\begin{proposition}
\label{prop:XY->RT}
%---------------------------------------
Let $\rvX$ and $\rvY$ be random variables with joint distribution
$\ppxy(x,y)$ and
\[ R^2 \eqd X^2 + Y^2 \hspace{10ex} \Theta \eqd \atan\frac{\rvY}{\rvX}. \]
Then
\propbox{
  \ppx[R,\Theta](r,\theta)
    =  r\;\ppxy(r\cos\theta,r\sin\theta)
  }
\end{proposition}
\begin{proof}
\begin{align*}
  \ppx[R,\Theta](r,\theta)
    &= \frac{\ppxy(x,y)}{|J(x,y)|}
     =  \frac{\ppxy(x,y)}{
        \left|\begin{array}{cc}
          \pderiv{R}{x}      & \pderiv{R}{y}   \\
          \pderiv{\theta}{x} & \pderiv{\theta}{y}
        \end{array}\right|
        }
     =  \frac{\ppxy(x,y)}{
        \left|\begin{array}{cc}
          \frac{ x}{\sqrt{x^2+y^2}}  & \frac{y}{\sqrt{x^2+y^2}}   \\
          \frac{-y}{x^2+y^2}         & \frac{x}{x^2+y^2}
        \end{array}\right|
        }
  \\&= \frac{\ppxy(x,y)}{
         \frac{x}{\sqrt{x^2+y^2}}\frac{x}{x^2+y^2}  -
         \frac{y}{\sqrt{x^2+y^2}}\frac{-y}{x^2+y^2}
       }
  \\&= \frac{\ppxy(x,y)}{
         \frac{x^2+y^2}{(x^2+y^2)^{3/2}}
       }
  \\&= \ppxy(x,y)\frac{(x^2+y^2)^{3/2}}{x^2+y^2}
  \\&= \ppxy(r\cos\theta,r\sin\theta)\frac{r^3}{r^2}
  \\&= r\;\ppxy(r\cos\theta,r\sin\theta)
\end{align*}
\end{proof}


%---------------------------------------
\begin{proposition}
\label{prop:XY->RT_n}
%---------------------------------------
Let $\rvX\sim\pN{0}{\sigma^2}$ and $\rvY\sim\pN{0}{\sigma^2}$ be
independent random variables and
\\\indentx$R^2 \eqd X^2 + Y^2 \hspace{10ex} \Theta \eqd \atan\frac{\rvY}{\rvX}.$\\
Then
\propbox{\begin{array}{FMrcl}
  1. & $R$ and $\Theta$ are independent with joint distribution
     & \ppx[R,\Theta](r,\theta) &=& \ppr(r)\ppth(\theta)
\\
  2. & $R$ has Rayleigh distribution
     & \ppr(r)  &=& \frac{r}{\sigma^2}\exp{\frac{r^2}{-2\sigma^2}}
\\
  3. & $\Theta$ has uniform distribution
     & \ppth(\theta) &=& \frac{1}{2\pi}
\end{array}}
\end{proposition}
\begin{proof}
\begin{align*}
  \ppx[R,\Theta](r,\theta)
    &= r\;\ppxy(r\cos\theta,r\sin\theta)
    && \text{by \prefpp{prop:XY->RT}}
  \\&= r\;\ppx(r\cos\theta) \; \ppy(r\sin\theta)
    && \text{by independence hypothesis}
  \\&= r\;
       \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\frac{(r\cos\theta-0)^2}{-2\sigma^2}}
       \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\frac{(r\sin\theta-0)^2}{-2\sigma^2}}
  \\&= \frac{1}{2\pi\sigma^2}\;r\;
       \exp{\frac{r^2(\cos^2\theta + \sin^2\theta)}{-2\sigma^2}}
  \\&= \frac{1}{2\pi\sigma^2}\;r\;
       \exp{\frac{r^2}{-2\sigma^2}}
  \\&= \left[\frac{1}{2\pi}\right]
       \left[\frac{r}{\sigma^2}\exp{\frac{r^2}{-2\sigma^2}}\right]
\end{align*}
\end{proof}


%---------------------------------------
\begin{proposition}
%---------------------------------------
Let $\rvX$ and $\rvY$ be \fncte{random variable}s
with covariance $\pvarxy$ on a
\structe{probability space} $\ps$.
\propbox{
  \brb{\begin{array}{FMD}
      (A).&$\rvX$ is \prope{Gaussian} with $\pN{\pmeanx}{\pvarx}$ & and
    \\(B).&$\rvX$ is \prope{Gaussian} with $\pN{\pmeany}{\pvary}$ & and
    \\(C).&$\pvarxy=\cov{\rvX}{\rvY}$
  \end{array}}
  \implies
  \brb{\psp\setn{\rvX>\rvY} = \pQ\brp{\frac{-\pmeanx + \pmeany}{\pvarx+\pvary-2\pvarxy}}}
  }
\end{proposition}
\begin{proof}
Because $\rvX$ and $\rvY$ are jointly Gaussian,
their linear combination $\rvZ=rvX-\rvY$ is also Gaussian.
A Gaussian distribution is completely defined by its mean and variance.
So, to determine the distribution of $\rvZ$,
we just have to determine the mean and variance of $\rvZ$.
\begin{align*}
  \pE Z
    &= \pE\rvX - \pE Y
  \\&= \pmeanx - \pmeany
\\
\\
  \var Z
    &= \pE Z^2 - (\pE Z)^2
  \\&= \pE (\rvX-\rvY)^2 - (\pE\rvX - \pE Y)^2
  \\&= \pE (\rvX^2-2XY+Y^2) - [(\pE\rvX)^2 -2\pE\rvX \pE Y + (\pE Y)^2 ]
  \\&= [\pE X^2- (\pE\rvX)^2]  + [Y^2- (\pE Y)^2] - 2[\pE XY - \pE\rvX \pE Y]
  \\&= \var\rvX + \var Y - 2\cov{\rvX}{\rvY}
  \\&\eqd \pvarx + \pvary -2\pvarxy
\\
\\
  \psp\setn{\rvX>\rvY}
    &= \psp\setn{\rvX-\rvY>0}
  \\&= \psp\setn{Z>0}
  \\&= \left.\pQ\left(\frac{z-\pE Z}{\var Z} \right)\right|_{z=0}
  \\&= \pQ\left(\frac{0-\pmeanx+\pmeany}{\pvarx+\pvary-2\pvarxy} \right)
\end{align*}
\end{proof}

\begin{figure}
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    \includegraphics{../common/math/graphics/pdfs/n0.pdf}&\includegraphics{../common/math/graphics/pdfs/n1.pdf}&\includegraphics{../common/math/graphics/pdfs/n2.pdf}\\
    pdf of $\rvX_1$                  &pdf of $\rvY\eqd\rvX_1+\rvX_2$   &pdf of $\rvY\eqd\rvX_1+\rvX_2+\rvX_3$\\
    \hline
    \mc{2}{|c|}{\includegraphics{../common/math/graphics/pdfs/n3.pdf}}&\includegraphics{../common/math/graphics/pdfs/n4.pdf}\\
    \mc{2}{|c|}{pdf of $\rvY\eqd\rvX_1+\rvX_2+\rvX_3+\rvX_4$}&pdf of $\rvY\eqd\rvX_1+\rvX_2+\rvX_3+\rvX_4+\rvX_5$\\
    \hline
  \end{tabular}
  \caption{\label{fig:pdf_uniform_sums}
           The distributions of sums of independent uniformly distributed random variables
           \xref{ex:pdf_uniform_sums}}
\end{figure}
%---------------------------------------
\begin{example}
\label{ex:pdf_uniform_sums}
%---------------------------------------
Let $\seqn{\rvX_1, \rvX_2, \rvX_3, \ldots}$ be a \fncte{sequence}
of \prope{independent} \xref{def:independent}
\prope{uniformly distributed} random variables.
Let $\ppx[\xN](x)$ be the \fncte{probability density function} of
$\rvY\eqd\sum_{n=1}^{\xN}\rvX_n$.
Some of these distributions are illustrated in \prefpp{fig:pdf_uniform_sums}.
Note that the distributions of the sequence $\seqn{\ppx[1],\ppx[2],\ppx[3],\ldots}$
are all \fncte{B-spline}s\ifsxref{spline}{def:Bspline} and all form a
\prope{partition of unity}\ifsxref{partuni}{def:pun}.
\end{example}